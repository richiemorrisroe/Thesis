
\section{Introduction}

Expectancies are considered to be at the core of the placebo response~\cite{Montgomery1997}. However, currently they are assessed using very simple methods which fail to capture the multidimensional nature and changes over time in these important constructs~\cite{Stone2005}. The most typical method of measuring treatment-related expectancies involves a one item measure ``How much better do you expect to feel after this treatment'', which is answered typically on an eleven point scale~\cite{morton2009reproducibility,martin2011implicit}.  These expectancy measures normally have a correlation with placebo response of approximately 0.3,  which equates to only 10\% of the variance in response to placebo~\cite{Whalley2008}.

\subsection{Current Expectancy Measurement}
\label{sec:curr-expect-meas}

The issues surrounding current expectancy measurement have been discussed in Chapter \ref{cha:literature-review}, especially Section \ref{sec:expectancies}, and the purpose of this portion of the research was to develop and test a more detailed measure of treatment expectancies which could then be used in the experimental portion of the research. 

A review of expectancy studies showed that of 16 studies, only two shared a common expectancy question \cite{myers2008patient}. This suggests that there is a need for a standardised measure of patient expectancies in the study of placebo effects and expectancy effects more generally. 

This chapter describes an adaptation of the Credibility/Expectancy Questionnaire~\cite{Devilly2000} to measure treatment expectancies in a student sample, and reports on its psychometric properties and correlation with other measures across two samples taken from the University population of staff and students. 

The CEQ was chosen as its design lends itself to adaptation to different forms of treatment, which means that if the adaptation proves valid and reliable, then it can easily be used in other studies. 
Additionally, the CEQ was found to have both cognitive and emotional factors by the authors in the paper introducing the technique~\cite{Devilly2000}. These two factors have been shown by a systematic review to be important factors in response to placebo \cite{Blasi2001}. This theoretical link strengthened the argument for the use of this measure. 

The CEQ was altered for this study, as this cross-sectional study did not administer any treatments to the sample of participants. Instead, participants were asked to imagine that they had been suffering from pain, and that a doctor had recommended a particular treatment and were then asked to rate the credibility of a number of different methods for reducing their pain (described further in Section \ref{sec:measures-1}). 

In this sense, what was measured were the self-reported treatment expectancies of the sample(s). These expectancies are relevant both because they may relate to the placebo response to treatments of this kind, and additionally because they may shape the choice of treatment and the likelihood of responding to a particular treatment~\cite{Bausell2005,Benedetti2005}. 

Finally, as this thesis aimed to develop and test an implicit measure to assist in the prediction of placebo, the use of a good self-report scale was important in that it allows for the incremental validity of any implicit measure to be assessed. The CEQ was used as a base as this set of questions has been shown to have validity in related areas, and this meant that it was a less risky process to follow when testing a new measure. 





Current or former use of the treatments measured was not a requirement for the completion of the measure, but this is typical for research in placebo, and indeed, clinical trials more generally~\cite{Kirsch1985,Kirsch1997}. The CEQ has been used in a family therapy setting for children with conduct disorder \cite{Nock2007}, in the assessment of relational therapy for Vietnam war veterans and their spouses \cite{Devilly2002} and in the treatment of PTSD \cite{Devilly2008}. It has not been used in any non-clinical samples, and this is its first adaptation for the study of treatment expectancies. 

%% While expectancies are considered the prime factor in response to placebo, there is some evidence that they are not the best predictors in all situations, and that there may be components of expectancies which are not tapped by current measures \cite{Hyland2007,Geers2005,Geers2005a}. 


\subsection{Beliefs About Treatment}
\label{sec:beli-about-treatm}

One facet of recent research into both placebo and complementary and alternative medicine (CAM) has been some awareness that perceived treatment assignment may be as influential in outcomes as observed treatment assignment. In a re-analysis of four large RCT's into acupuncture analgesia, Bausell found that while actual assignment to treatment (verum acupuncture) was not significantly associated with improved outcomes, beliefs about having received the verum treatment were significantly associated with better outcomes~\cite{Linde2007}. 

Additionally, in another study investigating the impact of acupuncture analgesia on recovering from dental pain following surgery, a similar effect was observed~\cite{Bausell2005}. This suggests that beliefs about treatment assignment are as impactful as is treatment assigment itself~\cite{Benedetti2005}. The relevance to this work is that these studies have shown that belief in receiving a real treatment is associated with greater improvement, along with the studies in placebo which have demonstrated that belief in the veracity of a substance can have profound treatment effects is that by measuring treatment related expectancies more precisely it may become possible to predict which (if any) of a set of treatments a patient will respond to best. 

\subsection{Links to theory}
\label{sec:links-theory}

There are a number of theoretical perspectives around how expectancies relate to placebo effects. The most prevalent in the field is the response expectancy perspective of Kirsch \cite{Kirsch1985,Kirsch1997} which argues that expectancies are directly responsible for observed placebo responses, and that all other variables are mediated by them. Kirsch's theory draws from some of Albert Bandura's work on self-efficacy \cite{Bandura1977}, but is quite distinct in that response expectancies are regarded as a seperate type. However, for others in the field \cite{Crow1999}. Crow {\it et al} take a somewhat different approach to expectancies, breaking them down into specific kinds of process expectancy (those expectancies developed by patients themselves) and positive and negative outcome expectancies which are either created or enhanced by the health provider. 

For the purposes of this thesis, and in line with the theory around placebo discussed in Chapter \ref{cha:methodolgy}, especially Section \ref{sec:towards-an-embodied}, treatment expectancies are regarded as outcome expectancies formed around particular sets of treatments which are then either enhanced or denigrated by subsequent learning. Essentially, expectancies are valid for a particular point in time, and are more reflective of state, and are amenable to change through either manipulations \cite{kirsch1988double} or through experience \cite{Stewart-Williams2004a}. Indeed, this perspective is entirely compatible with the position of Stewart-Williams that conditioning is a means of creating new expectancies. Curucially, for my theory, expectancies are regarded as having physiological impact which shapes the experience of a given treatment, which then impacts further response to a particular treatment or treatments in general. 

\subsection{Pain Treatments}
\label{sec:pain-treatments}

In general, treatments for pain are avalable in multiple different forms. Pills are commonly available as an over-the-counter supplement, creams are available for muscle pain, and injections of morphine or other painkillers are provided in a health-care setting. In one study, the most common reason for talking some form of medication was headache (9\%, N=2590 in a US sample) suggesting that these forms of treatment are routinely used~\cite{kaufman2002recent}. Another recent randomised survey of California residents determined that the point prevalance of some form of chronic pain condition in the general population was 49\% (47.0\%-51.0\%, N=3243), which would seem to suggest that the majority of the population suffers at least some pain once per month~\cite{ohayon2010chronic}. These findings would seem to suggest that pain-related treatment expectancies are important to an understanding of pain treatment and the experience of pain more generally.
This is another benefit which a useful measure for these extremely common treatment-related expectancies would convey. 

Complementary and alternative methodologies are sometimes used to treat pain. In some cross-sectional research, 23\% of patients with chronic pain reported using CAM in the previous twelve months \cite{mceachrane2006use}. In this study, CAM use was associated with more education and higher income. In another study of primary care participants undergoing treatment with opioids, 44\% of the sample (N=908) reported using at least one CAM treatment in the past twelve months. CAM use was associated with age, gender, pain severity and income. This study also found that over half of the sample reported some benefits from these treatments. 

For these reasons, both conventional and alternative treatments were used in this study. Additionally, it was thought that there might be some useful information conveyed by the relative ordering of conventional and alternative treatment expectancies, both within and between participants. 

\subsection{Aims and Objectives}
\label{sec:aims-objectives}

The overall aim of this study was to develop and test a measure of treatment expectancies in a pain context which could then be used in the experimental study. To this end, the following was done:

\begin{itemize}
\item The reliability \& general psychometric structure (Study 1) of the adapted questionnaire was tested using factor analysis and IRT;

\item The validity of the original factor structure was assessed (Study 1);

\item The best  factor structure from Study 1 was replicated on a sub-sample of the Study 2 data

\item The remainder of the data from Study 2 was then examined to assess if an exploratory analysis provided different results from Study 1;

\item The convergent validity of the new measure was assessed using the BMQ (Study Two);

\item The impact of demographic (age, gender, self-reported health, income and experience with the treatments concerned) variables on the newly developed measure (Study 2) was assessed.


\end{itemize}


\section{Methodology}
\label{sec:methodology}

\section{Design}
\label{sec:design}

This portion of the research was designed in the following fashion. In the first sample (N=299), the measure was tested for reliability and to ensure that the factor structure from the previous research replicated in this new setting, and with some changes made. 

The second sample (N=1329) was conducted to validate the factor structure from the first study, and to assess convergent validity through the use of the BMQ.  This study included two more forms of alternative treatment (Homeopathy and Reiki) to assess if a common factor structure could also be found for the alternative treatments. Additionally, the second sample collected demographic statistics around income, health and familiarity with all of the painkilling treatments used in the major instrument, to assess if these would have the impacts observed in previous research. 

This design had the advantage of both providing evidence for reliability of the instrument across Studies One and Two, and also providing independent evidence for the validity of the predicted factor structure in Study Two. The second, larger study  provided links to important potential moderators of the treatment expectancies and assessed convergent validity using the BMQ. 


\subsection{Participants}
\label{sec:participant}

The mean age of the participants in Study 1 was  22.61, the median Age was 21 and the range of reported ages was 10-56, which suggests some data entry errors on the part of the participants. The sample was 68.8\% female, and 83.4\% consisted of undergraduate students. 

The sample size collected for Study Two was 1329, however, only 556 completed all questions. The analysis was carried out on those participants who had provided data for all questions. Of the participants who filled out all questions, 71.5\% were female (n=396), 82.4\% were undergraduates, and the mean age was 22.96 (SD=6.3). 


\subsection{Measures}
\label{sec:measures-1}

The Treatment Credibility Questionnaire was adapated from Devilly and Borkovec's CEQ, as described above.This measure has six questions. The scale was developed to assess expectancies around psychological therapies. In the original form, the measure has four questions (Set I) and another set of two questions (Set II) \cite{Devilly2000}. Questions 4 and 6 were scored on an 11 point scale, while the other questions were scored on a nine point scale.    A number of changes were made to this instrument for use in this research. Firstly, the scale was changed to a 1-5 scale, to simplify the scoring and standardise it. Secondly, the six questions in each condition were prefaced by a statement that read: You have been suffering pain for a number of days. You go to the doctor, and he/she suggests you try X;where X is one of Pills, Creams, Injections or Aucpuncture in Study One, or Pills, Creams, Injections, Acupuncture, Homeopathy and Reiki in Study Two.  

The questions were as follows:


\begin{enumerate}
	\item How logical does the therapy offered to you seem?
	\item How successful do you think this treatment will be in reducing your symptoms?
 	\item How confident would you be in recommending this treatment to a friend?
	\item How much improvement in your symptoms do you think will occur?
	\item How much do you really \textit{feel} that therapy will help you to reduce your symptoms?
	\item How much improvement in your symptoms do you really \textit{feel} will occur?
\end{enumerate}

Of these, the first three questions were found to cluster together (using principal components analysis) in a credibility factor, while the second three questions were found to make up an expectancy factor \cite{Devilly2000}.  Note that this was despite their arbitrary division into Set I and II, and was replicated across all three samples 

\paragraph{Beliefs About Medicine Questionnaire}

Additionally, the Beliefs about Medicine Questionnaire (BAM) was administered to all participants in  Sample Two. This is an instrument developed to assess the beliefs of chronic pain patients regarding their medicines~\cite{Horne1999}.  The BAM is an eight item measure which has been found in previous research to have two factors, and which was developed using principal components analysis~\cite{Horne1999}. Only the General sub-scale was used for this research, as the Specific sub-scale was not appropriate for the non-clinical sample used in this research, which is a decision that has also been taken by other researchers~\cite{maardby2007beliefs}.

This instrument was included in order to validate the TCQ by means of correlations with this similar measure. The BMQ has been extensively used in clinical research, and has been shown to predict adherence to medication in  chronic pain,depression and with general pharmacy patients in Sweden~\cite{Horne1999,brown2005beliefs,maardby2007beliefs}. Specifically, Maardby {\it et al\/} found that the General-Harm sub-scale of the questionnaire showed a significant relationship to adherence in the overall pharmacy-using population. This would seem to indicate that the measure (at least the General part) is useful with non-clinical populations. 

\subsection{Sampling}

The sampling for the Treatment Credibility Questionnaire was conducted in two rounds, as the instrument was developed using one sample, and then confirmed and revised with another. The first sample was sent to a random subset of students at the University in February 2010 (N=2500), to which 299 students responded (RR=12\%). This data was analysed over the next two months, and following this, a revised version of the questionnaire was sent to a random sample of both staff and students at the University (N=10000), to which 1329 people responded (RR=13.3\%). 

\subsection{Analysis}

Study One was treated as an overall training and development sample (most appropriate given that the measure was changed as a result of these methods), and the results tested on a subset of Study Two. 

%% All data analysis was preceded by fitting a multiple imputation model where necessary, and was split into 4 parts as described above under the section Analysis for Health, Optimism and Mindfulness.

Data for Sample Two was split into four parts of approximately 300 observations each, in line with the procedure described in Chapter~\ref{cha:methodology}. 

Firstly, the data was checked for errors in entry or recording using summary functions and plots. Following this, the question responses were recoded according to the instructions for use. Following this, the summary scores were calculated. Next, summary statistics and characteristics of the data were reported. %% Next, the data was tested for normality using a Shapiro-Wilks test. 
Following this, a correlation matrix for the data was calculated and analysed.

Simple reliability analyses were carried out on the scales themselves. Following this, parallel analysis, the MAP criterion and the scree plot were used to estimate the number of factors which could be extracted from the data. Further analyses were carried out in line with the methods described in Chapter \ref{cha:methodology}, Section \ref{sec:psych-analys-meth}, in line with the aims and objectives laid out in Section \ref{sec:aims-objectives}. 



\section{Study One - Results}

As descibred above, the aim of this Study was to ensure that the altered measure was valid and that instruments correlated with each other in the expected fashion. 


\subsection{Demographic Statistics}


<<packagesanddata, echo=FALSE, results=hide>>=
require(cacheSweave)
require(ggplot2)
require(plyr)
require(reshape2)
require(lmtest)
require(psych)
require(xtable)
require(mokken)
require(eRm)
require(ltm)
require(xtable)
require(OpenMx)
require(MASS)
require(reshape2)
require(glmnet)
source("func.R")
require(gridExtra)
require(stargazer)
require(caret)
tcq1<-read.csv("CSV TCQ030410updatedJan11.csv")
@ 







The first step was to look at the scores on the response variables regarding the different forms of treatment. 

In Table \ref{tab:tcq1sumtotals} the summary statistics for the mean credibility scores for each of the four treatment options are shown. It can be seen that credibility of analgesic creams was lowest, even lower than that of acupuncture. Note that the minimum score of zero was from participants who only completed some of the questions. 

<<totalscreate, echo=FALSE, results=hide, cache=TRUE>>=
totals <- na.omit(tcq1[,c("PillTot", "CreamTot", "InjTot", "AcuTot")])
totals2 <- totals/6
@


<<totalsummary, echo=FALSE, results=tex>>=
sum.totals<-apademotables(totals2)
xtab.totals<-xtable(sum.totals, caption="Summary Statistics, Total Credibility Scores", label="tab:tcq1sumtotals")
print(xtab.totals)
@ 





Next, the differences in credibility totals between Genders will be examined. 
<<gendercred, echo=FALSE, results=hide, cache=TRUE>>=
gendpill <- ggplot(na.omit(tcq1), aes(y=PillTot, x=Gender))+geom_boxplot()
gendcream <- ggplot(na.omit(tcq1), aes(y=CreamTot, x=Gender))+geom_boxplot()
gendinj <- ggplot(na.omit(tcq1), aes(y=InjTot, x=Gender))+geom_boxplot()
gendacu <- ggplot(na.omit(tcq1), aes(y=AcuTot, x=Gender))+geom_boxplot()
@ 

%% \begin{figure}
<<gendpill, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE, eval=FALSE>>=
print(arrangeGrob(gendpill, gendcream, gendinj, gendacu))
@   
%%   \caption{Gender Differences in Credibility  Scores, TCQ1}
%%   \label{fig:gendcredpill}
%% \end{figure}



There were no significant differences in median Pill scores that can be attributed to the Gender of the respondents. The variability is larger within the male responses, a pattern which was repeated for all of the first three credibility totals.

However, the acupuncture credibility scores showed a different pattern. The mean credibility totals are very different for females and males.  A Kruskall Wallis examined whether this visual difference was backed up with a formal analysis. The results tended towards significance (p=0.09).
Again, the pattern of larger variability in the responses of men is apparent.   


<<collegeplots, echo=FALSE, results=hide, cache=TRUE>>=
collpill <- ggplot(na.omit(tcq1), aes(y=PillTot, x=College))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collcream <- ggplot(na.omit(tcq1), aes(y=CreamTot, x=College))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collinj <- ggplot(na.omit(tcq1), aes(y=InjTot, x=College))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collacu <- ggplot(na.omit(tcq1), aes(y=AcuTot, x=College))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
@ 

%% \begin{figure}
<<collpill, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE, eval=FALSE>>=
print(arrangeGrob(collpill, collcream, collinj, collacu))+theme(axis.text.x=element_text(angle=45, hjust=1))
@   
%%   \caption{Treatment Credibility Scores by College of Study}
%%   \label{fig:collpill}
%% \end{figure}


There were differences in the crediblity scores of various treatments across the colleges of study. These differences were only significant for the Cream ($p=0.0158$) and Injection ($p=0.0168$) credibility scores. 

\section{Psychometric Analyses}
\label{sec:pysch-analys}



\subsection{Reliability Analysis}

%Reliability is an extremely important part of any measurement instrument, given that if we cannot rely on the instrument giving us similar answers on different equations, it is of no use in our studies.
The reliability of this scale was assessed. The method used was Cronbachs $\alpha$ which is the most commonly used measure of reliability in psychological research. %% Of course, the extent to which people give the same responses at different time points also needs to be assessed, but that will be examined after the factor structure and other methodological issues have been assessed. 

This analysis was performed on the sample, and the mean alpha was equal to 0.9, which is well above the threshold used for survey research (0.7) and would, on the basis of this sample, qualify as a clinical instrument, for which the threshold is 0.9. This reliability analysis did not suggest that any of the items should be removed from the scale. 

<<scalemake, echo=FALSE, results=hide, cache=TRUE>>=
Pill.g <- grep("Pill[1-6]", x=names(tcq1))
Cream.g <- grep("Cream[1-6]", x=names(tcq1))
Inj.g <- grep("Inj[1-6]", x=names(tcq1))
Acu.g <- grep("Acu[1-6]", x=names(tcq1))
Pillall <- tcq1[,Pill.g]
Creamall <- tcq1[,Cream.g]
Injall <- tcq1[,Inj.g]
Acuall <- tcq1[,Acu.g]
tcqall <- as.data.frame(cbind(Pillall, Creamall, Injall, Acuall))
rel.tcq <- psych:::alpha(na.omit(tcqall))
@ 




<<reltcq2, echo=FALSE, results=hide>>=
print(xtable(rel.tcq[["item.stats"]], caption="Item reliability Statistics for the TCQ 1", label="tab:tcq1rellong"))
@ 





\section{Factor Analysis}


There were two aims of this factor analysis on Study One. The first was to examine if the predicted factor structure from the development of the scale held. This was that there would be three expectancy and three credibility questions. This analysis was carried out on all four methods of treatment individually. The next step, following this analysis, was to examine the intra-treatment factor structure. 

<<faindividual, echo=FALSE, results=hide>>=
pill.fa <- fa(r=na.omit(Pillall), nfactors=2, rotate="oblimin")
cream.fa <- fa(r=na.omit(Creamall), nfactors=2, rotate="oblimin")
inj.fa <- fa(r=na.omit(Injall), nfactors=2, rotate="oblimin")
acu.fa <- fa(r=na.omit(Acuall), nfactors=2, rotate="oblimin")
@ 

Interestingly enough, the proposed factor structure from earlier work replicated for the Pill credibility items, but not for the others. There was a two factor structure for the Injection credibility items, but the first factor carried all of the items except for item 3. For Cream credibility scores and Injection credibility scores only one factor was found from both a parallel analysis and from fitting a two factor model.  All of these models had excellent fit indices, with high NNFI (approximately 0.95), and so can be regarded as fitting the data relatively well. Possible explanations for this finding are examined in the Discussion. 



The next step in the analysis  was an assessment of the number of factors suggested by both the parallel analysis and MAP criterion for the entire scale. The results of the parallel analysis and scree plot suggested four factors. The MAP criterion suggested that six factors should be extracted. Both of these factor solutions will be created and examined based on fit indices and interpretability below. 



<<tcqfact4, echo=FALSE, results=tex>>=
tcq.fact.4<-fa(na.omit(tcqall), 4, rotate='oblimin', fm="pa")
print(FactorXtab(tcq.fact.4,names=c("Acupuncture", "Cream", "Inj", "Pills"), label="tab:tcq1fact4", caption="Four Factor Solution, TCQ 1 Oblimin rotation"))
@ 

<<factorloadings4, echo=FALSE, results=verbatim, eval=FALSE>>=
print(ExtractLoadings(tcq.fact.4))
@ 


<<factorcor4, echo=FALSE, results=hide>>=
print(FactorCor(tcq.fact.4, label="tab:tcq1fact4cor", caption="Four Factor TCQ correlations"))
@ 




As can be seen from Table \ref{tab:tcq1fact4}  the four factor structure is extremely interpretable, with each group of six questions loading highly on its own factor. This fits with the expectations prior to the research. 


The Acupuncture factor does not correlate highly with the other three factors, but they do correlate reasonably well with one another. This  makes clear that the distinction between the western and alternative treatment modalities was apparent to the participants. 



This four factor solution explains 74\% of the variance, which is extremely high for a psychological self report scale. %% \footnote{though typically the proportion of variance explained is higher when a scale is developed, and falls on new samples}. 



Next, the six factor solution was examined for interpretability, and the results are shown in Table \ref{tab:tcq1fact6}. The loadings on Factors 5 and 6 (tentatively titled Credibility and Expectancy, respectively) are clustered around questions 1 and 3 (for credibility) and 2 and 4 (for expectancy). Note that the loadings are not particularly high for the Acupuncture questions, reinforcing the notion that these factors are measuring matters common to the conventional treatments. 
As can be seen in Table \ref{tab:tcq1fact6} the four factors from the original solution still have the highest loadings, but there are a number of lower loadings on the fifth and sixth factors.

<<tcqfact6, echo=FALSE, results=tex>>=
tcq.fact.6<-fa(na.omit(tcqall), 6, rotate='promax', fm="pa")
print(FactorXtab(tcq.fact.6,  names=c("Acu", "Cream", "Inj", "Pill", "Cred", "Exp"), label="tab:tcq1fact6", caption="Six Factor Solution, TCQ 1, Oblimin Rotation"))
@ 


<<tcq6cor, echo=FALSE, results=hide>>=
print(FactorCor(tcq.fact.6, label="tab:tcq1fact6cor",caption="TCQ Six Factor Solution Correlations"))
@ 





<<fitindices,echo=FALSE, results=tex, eval=FALSE>>=
fit4 <- FitIndices(tcq.fact.4)
fit5 <- FitIndices(tcq.fact.5)
fit6 <- FitIndices(tcq.fact.6)
fit.tcq1 <- as.data.frame(cbind(fit4, fit5, fit6))
fittcq1.m <- melt(fit.tcq1)
names(fittcq1.m)[1] <- "Fit Index"
print(xtable(fittcq1.m, caption="Fit Indices, TCQ 1", label="tab:tcq1modelcomp"), scalebox=0.75)
@ 

\section{Confirmatory Factor Analyses}
\label{sec:conf-fact-analys}

<<tcq4sem, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
Tcq4model <- mxModel(name="TCQ4", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Pills", to=pills), 
                      mxPath(from="Creams", to=creams),
                      mxPath(from="Injections", to=inj),
                      mxPath(from="Acupuncture", to=Acu),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                      mxData(observed=cov(na.omit(tcqall)), type="cov", numObs=264)
                      )
tcq4fit <- mxRun(Tcq4model)
tcq4summ <- summary(tcq4fit)
@ 




<<tcq6sem, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Fifth", "Sixth")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
fifth <- c("Pill1", "Pill3","Cream1", "Cream3","Inj1", "Inj3")
sixth <- c("Pill2", "Pill4","Inj2", "Inj4")
Tcq6model <- mxModel(name="TCQ6", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Pills", to=pills), 
                      mxPath(from="Creams", to=creams),
                      mxPath(from="Injections", to=inj),
                      mxPath(from="Acupuncture", to=Acu),
                     mxPath(from="Fifth", to=fifth),
                     mxPath(from="Sixth", to=sixth), 
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                      mxData(observed=cov(na.omit(tcqall)), type="cov", numObs=264))
tcq6fit <- mxRun(Tcq6model)
tcq6summ <- summary(tcq6fit)
@ 



<<tcq1semcompare, echo=FALSE, results=tex>>=
print(xtable(mxCompare(base=tcq4fit, comp=c(tcq6fit)), label="tab:tcq1modelcomp", caption="CFA on TCQ Models, Sample One"))
@ 



As can be seen in Table \ref{tab:tcq1modelcomp}, the six factor model appears to fit the data much better, which is unexpected. Possible explanations are discussed below. 




\section{Item Response Theory Analyses}


<<tcqcheckassumptions, echo=FALSE, results=hide, cache=TRUE>>=
tcq.scales <- aisp(na.omit(tcqall))
print(xtable(tcq.scales, label="tab:tcq1aisp", caption="Item Selection Procedure Results for TCQ1"))
@ 

An IRT based item-selection procedure showed that  the overall scale appears to divide into two scales, one for the conventional items and another for the acupuncture items. Therefore, these two sets of items will be analysed seperately. Pill2 was the only item which did not meet the assumptions of the model in that it violated the item ordering assumption (assumption of monotonicity). Therefore, this item was removed from the scale before further analyses. 



<<tcqitemord, echo=FALSE, results=hide, cache=TRUE>>=
convtcq <- tcqall[,with(tcqall, grep("Pill|Cream|Inj", x=names(tcqall)))]
convtcq <- convtcq[,with(convtcq, grep("Pill2", x=names(convtcq), invert=TRUE))]
tcqalt <- tcqall[,with(tcqall, grep("Acu", x=names(tcqall)))]
tcqconv.item.ord <- check.iio(na.omit(convtcq))
tcqalt.item.ord <- check.iio(na.omit(tcqalt))
tcqconv.monotonicity <- check.monotonicity(na.omit(convtcq))
tcqalt.monotonicity <- check.monotonicity(na.omit(tcqalt))
@ 



The alternative TCQ (i.e. the Acupuncture items) showed no violations of the item ordering or monotonicity assumptions, and so no items were removed. 







<<tcqconvpcm, echo=FALSE, results=hide, cache=TRUE>>=
tcqconv.pcm.rasch<-gpcm(convtcq, constraint="rasch")
tcqcoef <- coef(tcqconv.pcm.rasch)
## tcqconv.pcm.fscores.rasch <- factor.scores(tcqconv.pcm.rasch)
## tcqconv.pcm.absest.rasch <- getIRTestimates(tcqconv.pcm.fscores.rasch)
@ 







The next step was to fit a series of graded response models. 

<<tcqconvgrmconstrained, echo=FALSE, results=hide, cache=TRUE>>=
tcqconv.grm.1pl <- grm(convtcq, constrained=TRUE)
tcqconv.grm1.coef <- coef(tcqconv.grm.1pl)

## tcqconv.grm.fscores.1pl <- factor.scores(tcqconv.grm.1pl)
## tcqconv.grm.absest <- getIRTestimates(tcqconv.grm.fscores.1pl)
@ 

<<tcqconvgrm1plprint, echo=FALSE, results=tex>>=
print(xtable(tcqconv.grm1.coef, label="tab:tcq1convgrm1pl", caption="Coefficients for the TCQ 1 Conventional Scale, One Parameter Graded Response Model"))
@ 
Table \ref{tab:tcq1convgrm1pl}  shows the fit of the one parameter GRM. Note that the Cream credibility items are the most difficult, which fits with the lower mean credibility score on this variable observed in Table~\ref{tab:tcq1sumtotals}. The next step taken is to examine the fit of a more flexible model (a two parameter GRM, coefficients not shown), and assess whether or not this represents a useful improvement over the model above.

<<tcqconvgrm2, echo=FALSE, results=tex, cache=TRUE>>=
tcqconv.grm.2pl <- grm(convtcq, constrained=FALSE)
tcqconv.grm2.coef <- coef(tcqconv.grm.2pl)

@ 
<<tcqconvgrm2plprint, echo=FALSE, results=hide>>=
print(xtable(tcqconv.grm2.coef, label="tab:tcq1convgrm2pl", caption="Coefficients for TCQ 1 Conventional One Parameter Graded Response Model"))
@ 
<<tcqgrmcomp, echo=FALSE, results=hide, cache=TRUE>>=
grm.comp <- anova(tcqconv.grm.1pl, tcqconv.grm.2pl)
@ 
The result of this model comparison exercise showed that the 1 parameter model was a significantly better fit than the 2 parameter model ($p\le 0.001$). Next, the fit of the alternative TCQ (i.e. the acupuncture items) was examined using a series of graded response models.  

<<tcqaltpcm, echo=FALSE, results=hide, cache=TRUE>>=
tcqalt.pcm.rasch <- gpcm(tcqalt, constraint="rasch")
tcqaltcoef <- coef(tcqalt.pcm.rasch)

## tcqalt.pcm.fscores.rasch <- factor.scores(tcqalt.pcm.rasch)
## tcqalt.pcm.absest <- getIRTestimates(tcqalt.pcm.fscores.rasch)
@ 


<<tcqaltgpcmraschprint, echo=FALSE, results=hide, >>=
print(xtable(tcqaltcoef, label="tab:tcq1altgpcmrasch", caption="Coefficients for TCQ 1 Alternative Scale, Rasch Generalised Partial Credit Model"))
@ 
%% Unlike the partial credit model formed from the conventional items, the scale composed of the acupuncture items shows no clear violations of monotonicity (Table \ref{tab:tcq1altgpcmrasch}), even when a simple Rasch model is fitted. Next, more complex versions of the partial credit model are fitted to examine if they add useful predictive power to the model. 

<<tcqaltpcm1pl, echo=FALSE, results=hide, eval=FALSE, cache=TRUE>>=
tcqalt.pcm.1pl <- gpcm(tcqalt, constraint="1PL")
tcqaltcoef.1pl <- coef(tcqalt.pcm.1pl)

## tcqalt.pcm.fscores <- factor.scores(tcqalt.pcm.1pl)
## tcqalt.pcm.absest <- getIRTestimates(tcqalt.pcm.fscores)
@ 
<<tcqaltgpcm1plprint, echo=FALSE, results=hide, eval=FALSE>>=
print(xtable(tcqaltcoef.1pl, label="tab:tcq1altgpcm1pl", caption="Coefficients for TCQ1 Alternative, One Parameter Generalised Partial Credit Model"))
@ 
%% The examination of the more complex model with a discrimination parameter estimated from the data (Table \ref{tab:tcq1altgpcm1pl}) shows that the acupuncture items can perhaps be modelled best with a much higher discrimination rather than higher ability estimates. An ANOVA confirms that the 1 parameter model is a significantly better fit than the Rasch model fitted before ($p\le 0.001$). 

%% Next, a two parameter model was fitted to this data. 

<<tcqaltpcm2pl, echo=FALSE, results=hide, cache=TRUE>>=
tcqalt.pcm.2pl <- gpcm(tcqalt, constraint="gpcm")
tcqaltcoef.2pl <- coef(tcqalt.pcm.2pl)

@ 
<<tcqaltgpcm2plprint, echo=FALSE, results=hide>>=
print(xtable(tcqaltcoef.2pl, label="tab:tcq1altgpcm2pl", caption="Coefficients for TCQ1 Alternative Scale, Two Parameter Graded Response Model"))
@ 


%% The two parameter model (shown in Table \ref{tab:tcq1altgpcm2pl}) has some interesting features compared to the one parameter model. Firstly, the discrimination parameter of Items 1 and 3 have significantly decreased compared to the one parameter model. The discrimination parameter for Acu 2 has lowered slightly. The discrimination of the other three items has increased substantially. An ANOVA between the two models shows that the model is a significant improvement on the one parameter model ($p\le 0.001$). 

Two graded response models were fit to the the alternative TCQ questions.

<<tcqaltgrm1, echo=FALSE, results=tex, cache=TRUE>>=
tcqalt.grm.constrained <- grm(tcqalt, constrained=TRUE)
tcqalt.grm1.coef <- coef(tcqalt.grm.constrained)
@ 
<<tcaltgrm1plprint, echo=FALSE, results=tex>>=
print(xtable(tcqalt.grm1.coef, label="tab:tcq1altgrm1pl", caption="Coefficients for TCQ 1 Alternative Scale, One parameter Graded Response Model"))
@ 
The model described in Table \ref{tab:tcq1altgrm1pl} has the following features. The discrimination parameter is quite low, and the parameter estimates are  closely distributed around zero.

<<tcqaltgrm2, echo=FALSE, results=tex, cache=TRUE>>=
tcqalt.grm2 <- grm(tcqalt)
tcqalt.grm2.coef <- coef(tcqalt.grm2)

## tcqalt.grm2.fscores <- factor.scores(tcqalt.grm2)
## tcqalt.grm2.absest <- getIRTestimates(tcqalt.grm2.fscores)
@ 
<<tcqaltgrm2plprint, echo=FALSE, results=tex>>=
print(xtable(tcqalt.grm2.coef, label="tab:tcq1altgrm2pl", caption="Coefficient Estimates for TCQ 1 Alternative Scale, Two Parameter Graded Response Model"))
@ 
The model shown in Table \ref{tab:tcq1altgrm2pl} has a much lower estimate of the discrimination of the individual items, counterbalanced by higher ability estimates for all of the item difficulty parameters. 


%% \section{Regression Analyses}
%% \label{sec:regression-analyses}

%% In this section, the totals for each of the treatment modalities are examined to determine if any of the demographic variables can account for them. Firstly, a linear regression was run on the Pilltotal variable using the demographics as predictors.

%% <<pilltotreg1, echo=FALSE, results=tex>>=
%% pillLm1 <- lm((PillTot)~CreamTot+InjTot+AcuTot+Gender+College+UGPG+Year, data=tcq1)
%% print(xtable(summary(pillLm1), caption="Coefficient for Linear Regression on Pill Credibility Scores, TCQ1", label="tab:tcq1pilllmsum"))
%% @ 

%% As can be seen from Table \ref{tab:tcq1pilllmsum}, there were no only Cream and Injection credibility scores were predictors of Pill Credibility scores from amongst the variables collected in Study One. 

%% Next, we examine the relationship of cream credibility variables to others in the sample.

%% <<creamlm,echo=FALSE, results=tex>>=
%% creamlm <- lm(CreamTot~PillTot+InjTot+AcuTot+Gender+College+UGPG, data=tcq1)
%% print(xtable(summary(creamlm), caption="Cream Credibility Linear Regression Results",label="tab:creamlm"))
%% @ 

%% As can be seen from the model in Table \ref{tab:creamlm}, there appears to only be a relationship with cream credibility for the other credibility scores. Surprisingly, the relationship between Cream credibility and Acupuncture credibility is positive, a pattern which was also seen in the raw correlations and suggests that participants in study one were responding in the same fashion due to overall response characteristics rather than a considered examination of each treatment in isolation. 

%% Next, we examine the relationship between Injection Credibility scores and the other variables in the sample.

%% <<injlm, echo=FALSE, results=tex>>=
%% injlm <- lm(InjTot~PillTot+CreamTot+AcuTot+Gender+College+UGPG, data=tcq1)
%% print(xtable(summary(injlm), caption="Injection Credibility Totals Regression, Study One", label="tab:injlm1"))
%% @ 

%% As can be seen from Table \ref{tab:injlm1}, a similar pattern as was seen for the Cream credibility scores emerges, except that Acupuncture now has a negative coefficient (which is much smaller than those for Pill or Cream credibility). 

%% Finally, we examine the relationship between Acupuncture credibility and other variables in the sample. 

%% <<acutotlm, echo=FALSE, results=tex>>=
%% acutotlm <- lm(AcuTot~PillTot+CreamTot+InjTot+Gender+College+UGPG, data=tcq1)
%% print(xtable(summary(acutotlm), caption="Acupuncture Credibility Linear Regression, Study One", label="tab:acutotlm1"))
%% @ 

%% The pattern of results was a little different when acupuncture credibility total was used as the response variable. Cream Credibility was extremely significant, injection credibility was marginally significant, while Pill credibility was not significant. Note the negative coefficient on Injections, which suggests that these treatments were regarded as useful by different subsets of participants. 

%%not sure if necessary, maybe redo them stepwise with lasso/ridge solutions. 

\section{Confirmatory Analyses}
\label{sec:conf-analys}

<<tcq2importandsplit, echo=FALSE, results=hide>>=
tcq2 <- read.csv("tcq2.csv")
@ 




<<scalemake2, echo=FALSE, results=hide>>=
Pillall <- tcq2[,grep("Pill[1-6]", x=names(tcq2))]
Creamall <- tcq2[,grep("Cream[1-6]", x=names(tcq2))]
Injall <- tcq2[,grep("Inj[1-6]", x=names(tcq2))]
Acuall <- tcq2[,grep("Acu[1-6]", x=names(tcq2))]
Homall <- tcq2[,grep("Hom[1-6]", x=names(tcq2))]
Reiall <- tcq2[,grep("Rei[1-6]", x=names(tcq2))]
Bamall <- tcq2[,grep("BAM[1-18]", x=names(tcq2))]
tcq2[,"Pilltot"] <- apply(Pillall, 1, mean, na.rm=TRUE)
tcq2[,"Creamtot"] <- apply(Creamall, 1, mean, na.rm=TRUE)
tcq2[,"Injtot"] <- apply(Injall, 1, mean, na.rm=TRUE)
tcq2[,"Acutot"] <- apply(Acuall, 1, mean, na.rm=TRUE)
tcq2[,"Homtot"] <- apply(Homall, 1, mean, na.rm=TRUE)
tcq2[,"Reitot"] <- apply(Reiall, 1, mean, na.rm=TRUE)
tcq2[,"Bamtot"] <- apply(Bamall, 1, mean, na.rm=TRUE)
tcqtotals <- with(tcq2, as.data.frame(cbind(Pilltot, Creamtot, Injtot, Acutot, Homtot, Reitot, Bamtot)))
@ 

<<expconvaltcalc, echo=FALSE, results=hide, cache=TRUE>>=
tcq2[,"ConvMean"] <- with(tcq2, (Pilltot+Creamtot+Injtot)/3)
tcq2[,"AltMean"] <- with(tcq2, (Acutot+Homtot+Reitot)/3)
tcq2[,"Expconv"] <- with(tcq2, (ExpPill+ExpCream+ExpInj)/3)
tcq2[,"Expalt"] <- with(tcq2, (ExpAcu+ExpHom+ExpRei)/3)
@ 
<<subsamplestcq2, echo=FALSE, results=hide, cache=TRUE>>=
set.seed(52)
tcq2.ind <- sample(1:1329, 1329, replace=FALSE)
tcq2.ind.a <-tcq2.ind[1:310]
tcq2.ind.b <-tcq2.ind[311:620]
tcq2.ind.c <-tcq2.ind[621:930]
tcq2.ind.d <- tcq2.ind[931:length(tcq2.ind)]
tcq2a <- tcq2[tcq2.ind.a,]
tcq2b <- tcq2[tcq2.ind.b,]
tcq2c <- tcq2[tcq2.ind.c,]
tcq2d <- tcq2[tcq2.ind.d,]
Pill.g <- grep("Pill[1-6]", x=names(tcq2a))
Cream.g <- grep("Cream[1-6]", x=names(tcq2a))
Inj.g <- grep("Inj[1-6]", x=names(tcq2a))
Acu.g <- grep("Acu[1-6]", x=names(tcq2a))
Hom.g <- grep("Hom[1-6]", x=names(tcq2a))
Rei.g <- grep("Rei[1-6]", x=names(tcq2a))
Pillall.a <- tcq2a[,Pill.g]
Creamall.a <- tcq2a[,Cream.g]
Injall.a <- tcq2a[,Inj.g]
Acuall.a <- tcq2a[,Acu.g]
Homall.a <- tcq2a[,Hom.g]
Reiall.a <- tcq2a[,Rei.g]
Bamall.a <- tcq2a[,grep("BAM[1-18]", x=names(tcq2a))]
tcq2.1 <- as.data.frame(cbind(Pillall.a, Creamall.a, Injall.a, Acuall.a))
tcqfull.a <- as.data.frame(cbind(Pillall.a, Creamall.a, Injall.a,
 Acuall.a, Homall.a, Reiall.a))
@ 

As in previous analyses (see Chapter \ref{cha:health-for-thesis}), the second sample was much larger than the first, and therefore was split into a number of equal parts. In this case, the second sample (consisting of student and staff responses) was split into four equal sub-samples(A-D). The first of these (hereafter denoted as A), was then  used as a test sample for the models developed on the data from Sample 1. 

\section{Confirmatory Factor Analysis}
\label{sec:conf-fact-analys-1}

<<tcq4sem2a, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
Tcq4model2 <- mxModel(name="TCQ42", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Pills", to=pills), 
                      mxPath(from="Creams", to=creams),
                      mxPath(from="Injections", to=inj),
                      mxPath(from="Acupuncture", to=Acu),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                      mxData(observed=cov(na.omit(tcq2.1)), type="cov", numObs=310)
                      )
tcq4fit2 <- mxRun(Tcq4model2)
tcq4summ2 <- summary(tcq4fit2)
@ 


<<tcq5sem2, echo=FALSE, results=hide, eval=FALSE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Fifth")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
fifth <- c("Pill4", "Pill5", "Pill6", "Cream5", "Cream6", "Inj6")
Tcq5model2 <- mxModel(name="TCQ52", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Pills", to=pills), 
                      mxPath(from="Creams", to=creams),
                      mxPath(from="Injections", to=inj),
                      mxPath(from="Acupuncture", to=Acu),
                     mxPath(from="Fifth", to=fifth),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                      mxData(observed=cov(na.omit(tcqall)), type="cov", numObs=310))
tcq5fit2 <- mxRun(Tcq5model2)
tcq5summ2 <- summary(tcq5fit2)
@ 

<<tcq6sem2, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Fifth", "Sixth")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
fifth <- c("Pill1", "Pill3","Cream1", "Cream3","Inj1", "Inj3")
sixth <- c("Pill2", "Pill4","Inj2", "Inj4")
Tcq6model2 <- mxModel(name="TCQ62", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Pills", to=pills), 
                      mxPath(from="Creams", to=creams),
                      mxPath(from="Injections", to=inj),
                      mxPath(from="Acupuncture", to=Acu),
                     mxPath(from="Fifth", to=fifth),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                      mxData(observed=cov(na.omit(tcq2.1)), type="cov", numObs=310))
tcq6fit2 <- mxRun(Tcq6model2)
tcq6summ2 <- summary(tcq6fit2)
@ 

<<tcq2testsemcomp, echo=FALSE, results=tex>>=
tcq2.1.comp <- mxCompare(tcq4fit2, comparison=c(tcq6fit2))
print(xtable(tcq2.1.comp, caption="Comparison of Four and Six Factor Models for the TCQ1 on Sample Two", label="tab:tcq2testsemcomp"))
@ 

As can be seen from Table \ref{tab:tcq2testsemcomp} the six model appears to fit the data best, even on this unseen data-set. This is somewhat unexpected, especially given the compelling reasons to believe in a four factor model. Further explanations are given in the Discussion (Section \ref{sec:study-1})




%add confirmatory IRT  analyses

%% \subsection{Confirmatory Regression Analyses}
%% \label{sec:conf-regr-analys}


%% Given that the models developed on the first data set are useful, then they should generalise to the new data. Examining this supposition is the purpose of this section.

%% Firstly, the Pill credibility model was replicated on a subset of the new data. 

%% <<pilllm2a, echo=FALSE, results=tex>>=
%% pilllm2a <- lm(Pilltot~Creamtot+Injtot+Acutot+Gender+College+UGPG, data=tcq2a)
%% print(xtable(summary(pilllm2a), caption="Replication of Pill Credibility Model from Study One on a subsample from Study 2", label="tab:pilllm2a"))
%% @ 

%% As can be seen from Table \ref{tab:pilllm2a}, the significant variables from the old model were still significant, and additionally there was a small effect of Acupuncture credibility and gender on the overall Pill Credibility scores. 

%% Next, the original model on cream credibility scores was examined. 

%% <<creamlm2a, echo=FALSE, results=tex>>=
%% creamlm2a <- lm(Creamtot~Pilltot+Injtot+Acutot+Gender+College+UGPG, data=tcq2a)
%% print(xtable(summary(creamlm2a), caption="Regression of Cream Credibility Scores Model from Study One on a subsample of Study Two Data", label="tab:creamlm2a"))
%% @ 

%% As can be seen from Table \ref{tab:creamlm2a}, a similar pattern  as was seen from the Study One data emerges from this regression model. Note that the positive coefficient for Acupuncture remains in this data, and is again significant. This suggests that cream and acupuncture painkilling treatments are somehow linked together in the minds of participants in both studies. This could be due to the fact that they are not as widely used as pills and injections, and so possess less face validity to the participants studied. 

%% Next, we examine the Injection Credibility model developed on the first sample. 

%% <<injlm2a, echo=FALSE, results=tex>>=
%% injlm2a <- lm(Injtot~Pilltot+Creamtot+Acutot+Gender+College+UGPG, data=tcq2a)
%% print(xtable(summary(injlm2a), caption="Regression of Injection Credibility Score Model from Study One on subsample from Study Two", label="tab:injlm2a"))
%% @ 

%% As can bee seen from Table \ref{tab:injlm2a}, the results of this same model on Study Two data were in line with those from Study One. That being said, both Gender Coefficients are significant in Study Two, while they were not in Study One. This is interesting as it represents a larger effect being seen on an equivalent instrument. 

%% Finally, the Acupuncture credibility model from Study One was examined. 

%% <<acutotlm2a, echo=FALSE, results=tex>>=
%% acutotlm2a <- lm(Acutot~Pilltot+Creamtot+Injtot+Gender+College+UGPG, data=tcq2a)
%% acutot2a.xtab <- xtable(summary(acutotlm2a), caption="Acupuncture Credibility Model from Study One replicated on a subsample from Study Two", label="tab:acutotlm2a")
%% print(acutot2a.xtab)
%% @ 

%% Table \ref{tab:acutotlm2a} shows that the model for Acupuncture credibility is quite different on the Study Two data. Firstly, the coefficient for Injection is positive, unlike in the previous data, and the coefficients for College and Gender are significant. This would seem to suggest that the representation of the acupuncture credibility questions were quite different between the two samples, with a stronger effect of demographic questions in sample two. 

\subsection{Confirmatory IRT Analyses}
\label{sec:conf-irt-analys}


The first step in examining the predictive power of the IRT models is to score the current subsample of the Study Two data (Split A) using the prior models. Then, the same model can be fit on this data alone, and the error of estimation between the two processes can be calculated. Essentially, the root mean square error of approximation (RMSEA) was used to assess the usefulness of each of the models. 

Firstly, the Conventional TCQ was assessed. 

<<tcqconvpcmraschtest, echo=FALSE, results=hide, cache=TRUE>>=
tcq2a.conv <- tcq2.1[,c(1,3:18)]
## pcm.rasch.done <- testIRTModels(tcqconv.pcm.rasch, tcq2a.conv.full, gpcmconstraint="rasch", grmconstraint=NULL)



@ 


<<tcqconvpcm1pltest, echo=FALSE, eval=FALSE, results=hide, cache=TRUE>>=
pcm.1pl.done <- testIRTModels(tcqconv.pcm.1pl, tcq2a.conv, gpcmconstraint="1PL", grmconstraint=NULL)
@ 

<<tcqconvpcmgpcmtest, echo=FALSE, eval=FALSE, results=hide, cache=TRUE>>=
pcm.gpcm.done <- testIRTModels(tcqconv.pcm.gpcm, tcq2a.conv, gpcmconstraint="gpcm", grmconstraint=NULL)
@ 

<<pcmmodcomp, echo=FALSE, results=hide, cache=TRUE, eval=FALSE>>=
pcm.mod.comp <- rbind(pcm.rasch.done, pcm.1pl.done, pcm.gpcm.done)
rownames(pcm.mod.comp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")


@ 
<<pcmmodcompprint, echo=FALSE, results=hide, eval=FALSE>>=
pcm.mod.comp.xtab <- xtable(pcm.mod.comp, caption="Comparison of Performance of IRT PCM Models on Study Two Data", label="tab:pcmmodcomp")
print(pcm.mod.comp.xtab)
@ 
%% As can be seen from Table \ref{tab:pcmmodcomp}, the one parameter Partial Credit Model appears to fit better in that it has a lower square root of the sum of the squared errors, and the predicted scores and actual scores correlate higher than those for the rasch model. However, despite these fit indices an argument can be made for the Rasch model in terms of simplicity (even though a complexity parameter was added to the error term to account for this possibility). 

%% Next, the same process is repeated for the graded response models. 

<<grmtest, echo=FALSE, results=tex, cache=TRUE>>=
grm1pl.done <- testIRTModels(tcqconv.grm.1pl, tcq2a.conv, grmconstraint=TRUE)
grm2pl.done <- testIRTModels(tcqconv.grm.2pl, tcq2a.conv, grmconstraint=FALSE)
grm.modcomp <- rbind(grm1pl.done, grm2pl.done)
rownames(grm.modcomp) <- c("One Parameter GRM", "Two Parameter GRM")

@ 
<<grmmodcompprint, echo=FALSE, results=tex>>=
grm.modcomp.xtab <- xtable(grm.modcomp, caption="Comparison of One and Two Parameter Graded Response Models, Split 2A", label="tab:grmmodcomp")
print(grm.modcomp.xtab)
@ 
As shown in Table \ref{tab:grmmodcomp}, the one parameter model performed better on the unseen data than did the two parameter model (unlike the analysis using likelihoods which picked the more complicated model). 


\section{Conclusions \& Next Steps}
\label{sec:study-1}


A number of issues have become clear from this first study validating the Treatment Credibility Questionnaire. 

Firstly, the measure appeared to be quite reliable, and ther were some interesting findings with respect to the measure. All of the treatments showed average levels of credibility, ranked from injections, pills, acupuncture and cream credibility scores. There was a pattern of greater variability in the responses of men to the questionnaire. This could be the result of less experience or from a wider range of beliefs in the population. If it is due to less experience, then it would be expected to see less variability in the responses of those individuals with more experience of these treatments. This theory was tested in Study Two. 


With respect to the factor structure, the results of Horne \cite{Horne1999} have not been confirmed in this adaptation, except for one of the measures. Pill credibility score showed the same two factor structure as did the CEQ in earlier work, but none of the other three treatment forms did. Indeed, the other three treatments showed a relatively clear one factor structure, though the results of a parallel analysis suggested that a two factor structure might be more appropriate for the Injection credibility scores. 

It is important to consider what may be the reasons for the difference. One potential explanation is that this factor structure was obtained because of greater experience with painkilling treatments in pill form. If this is the case, then greater levels of experience with a painkilling treatment should correlate with the presence of this factor structure. Another possibility is that this simply due to chance, in which case this finding should not replicate in the next study. 


With regards to the overall psychometric structure ,the measure appears to show a strong pattern of one factor per treatment modality, but a six factor model fitted the training and test data better, suggesting that there are some higher-order correlations between some of the factors, which could probably be better accounted for using a hierarchical factor model.  

Secondly, an item response theory analysis has suggested that while the Pills, Cream and Injection questions can be conceptualised with one latent trait, this does not appear to work for acupuncture. This would seem to suggest that ratings of complementary and western medicine are somewhat independent. The second version of this survey added two more sections on complementary therapies, Homeopathy and Reiki, in order to both balance the kinds of treatments, and to examine whether the assumption of bi-dimensionality would hold in another student and UCC staff sample. 

 Very few demographic variables were collected in this survey. This limited what could be done with the ability estimates, and their relation to other factors. Therefore, for the second sample, more demographics were added.  A question on experience with each of the treatments involved would seem like a useful check on what percentage of the respondents have experiential knowledge of these methods would prove useful. Given the cost of CAM and its unavailability to those of lower incomes, a question on income would also be useful, and also the results of prior research noted in the Introduction. 


In addition, the General sub-scale of the Beliefs about Medicines Questionnaire was appended to V2 of the survey, in order to assess the extent to which the two instruments correlate (or fail to). This is a preliminary attempt to assess construct validity, which of course is but a prelude towards testing the instrument with clinical samples and in experimental settings.


\section{Study Two - Results}

Given the results of Study 1, this study added two more Complementary and Alternative Medicine (CAM) methodologies to the questionnaire, to determine if a higher order factor structure could be found which represented conventional and complementary methodologies.
The hypotheses were as follows: 

\begin{itemize}
\item The TCQ V2.0 will have six factors, one for each treatment modality, along with two higher level factors, one for each of Conventional and Alternative treatments;

\item The BAM will have two factors;

\item The BAM will correlate negatively with the Pills, Cream and Injection totals, and positively with the Acupuncture, Homeopathy and Reiki totals;
\item   The TCQ will not fit an item response theory model well, and will need to be divided into TCQ Conventional (Pills, Creams, Injections) and a TCQ Alternative (Acupuncture, Homeopathy and Reiki) in order to meet the assumptions of the model(s);

%% \item Income will correlate postively with experience of CAM methodologies;

\item Experience with a particular treatment will be correlated with higher ratings of its credibility. 
\end{itemize}



\subsection{Results}
\subsubsection{Descriptive Statistics}



<<tcq2demo, echo=FALSE, results=tex>>=
itemnames <- paste(rep(c("Pill", "Cream", "Inj", "Acu", "Hom", "Rei"), each=6), rep(1:6, times=6), sep="")
tcq2.demo <- tcq2[,2:17]
tcq2.demo.full <- na.omit(tcq2[,2:17])
tcq2.demo1 <- tcq2.demo[,1:5]
tcq2.demo2 <- tcq2.demo[,6:10]
tcq2.demo3 <- tcq2.demo[,11:16]
tcq2.sum1 <- summary(tcq2.demo1)

stargazer(tcq2.demo1, tcq2.demo2, tcq2.demo3, summary=TRUE, title="TCQ2 Summary Statistics", label="tab:tcq2sumstats")
@ 



As can be seen from the second sub-table of Table \ref{tab:tcq2sumstats} , many respondents stopped answering questions throughout the demographic variables. The reasons for this are unknown, but are probably not related to the design in any substantial way. The median age is 22, which shows that most of the sample was made up of students.

The Health variable is quite skewed, as most respondents rated their health as very good as good, as can be seen from the mean and the median. 
The mean level of experience with a particular treatment was highest for pills and steadily declined for all of the other treatments. 

The sample was 69.17\% female, with 45 respondents not specifying their gender. 

The next step in the analysis is visualisation of data using scatterplot matrices and conditioning plots. Figure \ref{fig:tcq2pairs}, the correlations between the scale totals can be seen. Notable are the high correlations between each of the conventional and alternative treatment methodologies, and their moderate correlations (in opposite directions) with the BMQ. Given the sample size, all correlations were significant at the $p \le 0.001$ level. 
@ 

\begin{figure}
	\centering
<<tcq2pairs, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
sink("tmp.txt")
pairs.panels(tcqtotals)
sink(NULL)
@ 
	\caption{Scatterplot Matrix, TCQ 2}
	\label{fig:tcq2pairs}
\end{figure}



%% As can be seen from Figure \ref{fig:tcq2pairs}, the predicted relationship appear to be apparent. The high inter-correlations between the first three sub-scales of the TCQ and the last three are immediately apparent, and there is no evidence of nonlinearity in any of the relationships. 


Interestingly enough, it can be seen from Figure \ref{fig:tcq2pairs} that the Beliefs About Medicine Questionnaire totals seem normally distributed, which is unexpected  (Micceri et al, 1989). The histograms for the alternative treatments are also quite interesting, given that they appear to have a number of peaks with very little in between. This may reflect the polarised nature of the attitudes towards these treatments. It may be (for example) that those involved with medicine tend to rate them very low, while those involved in the liberal arts tend to rate them quite highly. These kinds of differences will be teased apart in analyses below. 

The sample scores showed some significant differences attributable to Gender. The cream, acupuncture, homeopathy and reiki totals were significantly different in the sample, as was the Beliefs About Medicine scale total. 


%% \begin{figure}
<<credgender, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE, eval=FALSE>>=
gendPill <- ggplot(na.omit(tcq2), aes(y=Pilltot, x=Gender))+geom_boxplot()
gendcream <- ggplot(na.omit(tcq2), aes(y=Creamtot, x=Gender))+geom_boxplot()
gendInj <- ggplot(na.omit(tcq2), aes(y=Injtot, x=Gender))+geom_boxplot()
gendAcu <- ggplot(na.omit(tcq2), aes(y=Acutot, x=Gender))+geom_boxplot()
gendHom <- ggplot(na.omit(tcq2), aes(y=Homtot, x=Gender))+geom_boxplot()
gendRei <- ggplot(na.omit(tcq2), aes(y=Reitot, x=Gender))+geom_boxplot()
print(arrangeGrob(gendPill, gendcream, gendInj, gendAcu, gendHom, gendRei))
@   
%%   \caption{Credibility Scores by Gender, Sample Two}
%%   \label{fig:tcq2credgend}
%% \end{figure}

\begin{figure}
<<collcredplot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
collpill <- ggplot(tcq2, aes(x=College, y=Pilltot))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collCream <- ggplot(tcq2, aes(x=College, y=Creamtot))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collInj <- ggplot(tcq2, aes(x=College, y=Injtot))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collAcu <- ggplot(tcq2, aes(x=College, y=Acutot))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collHom <- ggplot(tcq2, aes(x=College, y=Homtot))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collRei <- ggplot(tcq2, aes(x=College, y=Reitot))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
print(arrangeGrob(collpill, collCream, collInj, collAcu, collHom, collRei ))
@   
  \caption{Credibility Scores by College}
  \label{fig:tcq2collcred}
\end{figure}



As can be seen from Figure~\ref{fig:tcq2collcred}, there were significant differences between the credibility totals in each college for the three conventional treatment modalities. This appears to be due to higher credibility totals amongst those respondents whose primary affiliation was with the College of Medicine and Health. %% The Beliefs about Medicine difference makes sense as the questions are quite negative towards medicines, and it would be expected that many Medicine and Health students would disagree with them, given their perspective.

Next the range of experience scores with each of the treatment was examined. 

<<expdf, echo=FALSE, results=tex>>=
expdf <- tcq2[,c("Age", "Gender", "ExpPill", "ExpCream", "ExpInj", "ExpAcu", "ExpHom", "ExpRei")]
expdf.gend <- ddply(na.omit(expdf), .(Gender), summarise, Pill=mean(ExpPill, na.rm=TRUE),Cream=mean(ExpCream, na.rm=TRUE),Inj=mean(ExpInj, na.rm=TRUE),Acu=mean(ExpAcu, na.rm=TRUE),Hom=mean(ExpHom, na.rm=TRUE),Rei=mean(ExpRei, na.rm=TRUE))
gend.m <- melt(expdf.gend)
expdf.gend[,"Gender"] <- with(expdf.gend, as.factor(gsub("^$", "Not Reported", x=Gender)))
print(xtable(expdf.gend, label="tab:experiencegend", caption="Experience with painkilling treatments by Gender"))
@

As can be seen from Table \ref{tab:experiencegend} females reported a higher level of pill credibility, along with lower levels of cream and injection credibility, and slightly higher levels of Homeopathy and Reiki credibility. 

Next, the response to the Income and Health questions were assessed. 

<<inc, echo=FALSE, results=tex>>=
inctab <- with(tcq2, table(Income))
dimnames(inctab) <- list(c("Less than 20K", "20K to 40K", "40K to 60K", "60 to 80K", "80K+"))
print(xtable(inctab, label="tab:incomelevels", caption="Income Levels for Study two"))
@ 

As can be seen from Table \ref{tab:incomelevels}, the majority of participants reported earning less than 20,000 euros per year. This is unsurprising, as the majority of respondents were students. 

Finally, the levels of General Health reported were investigated. 

<<healthtab, echo=FALSE, results=tex>>=
healthtab <- with(tcq2, table(Health))
dimnames(healthtab) <- list(c("Very Poor", "Somewhat Poor", "Average", "Somewhat Good", "Very Good"))
print(xtable(healthtab, label="tab:healthlevels", caption="Self Report Health levels, Study Two"))
@ 

As can be seen from Table \ref{tab:healthlevels}, the majority of participants tended to report their health as either Somewhat Good or Very Good, which is not particularly surprising, given the non-clinical nature of the sample. 

Following these investigations of the descriptive qualities of the data, the next stage of the analysis is to examine the inter-correlations and latent structure behind the data through the use of factor analysis. 

<<semsplits, echo=FALSE, results=hide, cache=TRUE>>=
tcq2nota <- tcq2[-tcq2.ind.a,]
tcq2notb <- tcq2[-tcq2.ind.b,]
tcq2notc <- tcq2[-tcq2.ind.c,]
tcq2notd <- tcq2[-tcq2.ind.d,]
tcqall2nota <- tcq2nota[,17:52]
tcqall2notb <- tcq2notb[,17:52]
tcqall2notc <- tcq2notc[,17:52]
tcqall2notd <- tcq2notd[,17:52]
bamnotA <- tcq2nota[,53:70]
bamnotB <- tcq2notb[,53:70]
bamnotC <- tcq2notc[,53:70]
bamnotD <- tcq2notd[,53:70]
@ 



\section{Treatment Credibility Questionnaire, Version 2}


Splits B,C and D were used for this analysis, given the use of Split A as a testing set for the Sample One data (in Section \ref{sec:conf-analys}). 

Parallel analysis and the scree plot suggest that five factors seems most optimal for this instrument. However, the MAP criterion disagrees, suggesting that seven factors might be more appropriate. To determine which of these criteria is correct, the five,  six and seven factor solutions will be examined for interpretability and then subjected to CFA on the other splits of the data. This procedure was repeated for each of the other splits, and the coefficient of the most successful models were averaged and are repprted here. 



\subsection{Five Factor Solutions}
\label{sec:five-factor-solution}


The five factor  solution (not shown) explained 79\% of the variance in Split B and 81\% in Split C and all of the communalities were extremely high. It was not suggested by any of the factor prediction methods in Split D. 


<<tcq2bscalesplit, echo=FALSE, results=hide, cache=TRUE>>=
tcqall2b <- tcq2b[,17:52]
bamall2b <- tcq2b[,53:70]
@ 


<<tcq2bsplitscales, echo=FALSE, results=hide, cache=TRUE>>=
tcq2b.conv <- tcqall2b[,1:18]
tcq2b.alt <- tcqall2b[,19:36]
@ 

<<tcq2cscalesplit, echo=FALSE, results=hide, cache=TRUE>>=
tcqall2c <- tcq2c[,17:52]
bamall2c <- tcq2c[,53:70]
@ 

<<tcq2dsplitscales, echo=FALSE, results=hide, cache=TRUE>>=
tcq2d.conv <- tcqall2d[,1:18]
tcq2d.alt <- tcqall2d[,19:36]
@ 

<<tcq2afact5, echo=FALSE, results=hide>>=
tcq2b.fact.5 <- fa(na.omit(tcqall2b), nfactors=5, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2b.fact.5, names=c("Pill&Inj", "Cream", "Rei", "Hom", "Acu"),  label="tab:tcq2afact5",caption="Five factor Solution, TCQ 2 (Split B), Oblimin Rotation"))
@ 


<<tcq2cfact5, echo=FALSE, results=hide>>=
tcq2c.fact.5 <- fa(na.omit(tcqall2c), nfactors=5, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2c.fact.5, names=c("PillInj", "Hom", "Rei", "Cream", "Acu"), label="tab:tcq2cfact5",caption="Five factor Solution, TCQ 2 (Split C), Oblimin Rotation"))
@ 

<<average5factsolution, echo=FALSE, results=tex>>=
tcq2b5.coeff <- FactorCoeff(tcq2b.fact.5, names=c("Pillinj", "Hom", "Rei", "Cream", "Acu"))
tcq2c5.coeff <- FactorCoeff(tcq2c.fact.5, names=c("Pillinj", "Hom", "Rei", "Cream", "Acu"))
rownames(tcq2.fact5.av) <- itemnames
tcq2.fact5.av <-  (tcq2b5.coeff+tcq2c5.coeff)/2
print(xtable(tcq2.fact5.av, label="tab:tcq2fact5average", caption="Averaged Five Factor Solution over Splits B and C"))

@ 



Typically, the five factor solution merged the Pill credibility and Injection credibility items together, and this pattern was repeated across both splits. 

The factor structure for Split B is given below, and the results for Split C were very similar. 

PA2: ``Pill1'', ``Pill2'', ``Pill3'', ``Pill4'', ``Pill5'', ``Pill6'', ``Inj1'',  ``Inj2'',  ``Inj3'', ``Inj4'',  ``Inj5'  ``Inj6''. This factor consists of the Pill and Injection items, and can therefore best be termed Pills and Injections.

PA1: ``Hom1'', ``Hom2'', ``Hom3'', ``Hom4'', ``Hom5'', ``Hom6''. This factor maps exactly to the Homeopathy items, and is therefore given that name.

PA5: ``Rei1'', ``Rei2'', ``Rei3'', ``Rei4'', ``Rei5'', ``Rei6''. Again, this factor maps exactly to the Reiki items and is named after them.

PA4: ``Cream1'', ``Cream2'', ``Cream3'', ``Cream4'', ``Cream5'', ``Cream6''. PA4 maps to the Cream items and so retains that name. 

PA3: ``Acu1'', ``Acu2'', ``Acu3'', ``Acu4'', ``Acu5'', ``Acu6''. PA3 maps to the acupuncture items and so is termed Acupuncture. 

The Pills/Injections factor correlated highly with the Cream factor (as would be expected), while the Alternative factors correlate quite well with one another also. Of particular note is Acupuncture, which appears to occupy a middle ground between the other alternative methods and the conventional ones, as least as evinced by these correlation structures. 

<<tcq2cfactorcor5, echo=FALSE, results=hide>>=
print(FactorCor(tcq2c.fact.5,label="tab:tcq2cfactorcor5", caption="Factor Correlations, TCQ 2 Five Factor Solution, Split C"))
@ 



\subsection{Six Factor Solutions}
\label{sec:six-factor-solution}



<<tcq2bfact6, echo=FALSE, results=hide>>=
tcq2b.fact.6 <- fa(na.omit(tcqall2b), nfactors=6, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2b.fact.6, names=c("Rei", "Hom", "Acu", "Cream", "Inj", "Pill"),label="tab:tcq2bfact6",caption="Six factor Solution, TCQ 2, Oblimin Rotation"))
@ 


%% As can be seen from Table \ref{tab:tcq2bfact6}
The six factor structure fits the predicted one extremely well. The six factors map exactly to the six treatment modalities. PA5 equates to Reiki, PA1 to Homeopathy, PA4 to Acupuncture, PA3 to Cream, PA2 to Injections and PA6 equates to Pills. One small exception to this was that Pill1 loaded slightly onto the Reiki factor. However, in light of its strong loading on other factors, this was disregarded %% \footnote{it is perhaps interesting that this strange loading also occurred in other factor solutions}.  

%% Below can be seen the correlations between factors, in Table \ref{tab:tcq2b6factorcor} . 


<<tcq2bfactorcor, echo=FALSE, results=hide>>=
print(FactorCor(tcq2b.fact.6,label="tab:tcq2b6factorcor",caption="Factor Correlations, Six Factor Solution TCQ 2B"))
@ 





The proportion of variance explained by the six factor solution is equal to 84\% which is an extremely high amount, arguing for the usefulness of this solution. 

The correlations between factors are very similar to those between the total scores, which is perhaps unsurprising as both are linear combinations of the scores on each questions. Nonetheless, this gives supporting evidence in favour of the utility of this solution. 

<<tcq2cfact6, echo=FALSE, results=hide>>=
tcq2c.fact.6 <- fa(na.omit(tcqall2c), nfactors=6, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2c.fact.6,names=c("Hom", "Rei", "Acu", "Cream", "Inj", "Pill"), label="tab:tcq2cfact6",caption="Six factor Solution, TCQ 2, Split C,  Oblimin Rotation"))
@ 


Again, %% as can be seen in Table \ref{tab:tcq2cfact6}
the six factors map exactly to the six forms of treatment, rendering an interpretation of the resulting factor solution rather superflous. 


<<tcq2cfactorcor, echo=FALSE, results=hide>>=
print(FactorCor(tcq2c.fact.6,label="tab:tcq2c6factorcorr",caption="Factor Correlations, Six Factor Solution TCQ 2, Split C"))
@ 

Acupuncture again shows correlations with the conventional factors, but homeopathy does also in this particular solution. This solution explained 83\% of the variance, which is consistent with the other splits and factor solutions examined so far. 

\paragraph{Six Factor Solution}
\label{sec:six-factor-solution}



<<tcq2dfact6, echo=FALSE, results=hide>>=
tcq2d.fact.6 <- fa(na.omit(tcqall2d), nfactors=6, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2d.fact.6, names=c("Reiki", "Hom", "Acu", "Cream", "Inj", "Pill"), label="tab:tcq2dfact6",caption="Six factor Solution, TCQ 2(Split D), Oblimin Rotation"))
@ 


As per all previous splits, the six factor solution mapped all six treatment modalities to the six factors%% , as is clearly shown in Table \ref{tab:tcq2dfact6}
. This solution explained 81\% of the variance. 


<<tcq2dfactorcor, echo=FALSE, results=hide>>=
print(FactorCor(tcq2d.fact.6,label="tab:tcq2dfactorcor",caption="Factor Correlations, Six Factor Solution TCQ 2 (Split D)"))
@ 


Similiarly to the results in other splits, the three conventional treatment factors and the three alternative factors correlated with each other but tended not to correlate highly with the factors of the opposite modality. 

\paragraph{Seven Factor Solutions}
\label{sec:seven-fact-solut}



<<tcq2bfact7, echo=FALSE, results=tex>>=
tcq2b.fact.7 <- fa(na.omit(tcqall2b), nfactors=7, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2b.fact.7, names=c("Hom", "Rei", "Acu", "Cream","Inj", "Pill", "Cred"), label="tab:tcq2bfact7",caption="Seven Factor Solution, TCQ 2B, Oblimin Rotation"))
@ 


The seven factor solution shown in Table \ref{tab:tcq2bfact7} explained 86\% of the variance in the sample, and the items were assigned to factors as follows.

PA1: ``Hom1'', ``Hom2'', ``Hom3'', ``Hom4'', ``Hom5'', ``Hom6''. This factor clearly maps to the Homeopathy questions, and is therefore termed as Homeoapathy.

PA5: ``Pill1'', ``Rei1'',  ``Rei2'',  ``Rei3'',  ``Rei4'',  ``Rei5'',  ``Rei6''. Again, apart from a small loading of Pill1 on this factor, it maps exactly to the Reiki questions, and thus will be termed Reiki. 

PA4: ``Acu1'', ``Acu2'', ``Acu3'', ``Acu4'', ``Acu5'', ``Acu6''. This factor maps exactly to the Acupuncture questions, and will be termed thusly.

PA3: ``Cream1'', ``Cream2'', ``Cream3'', ``Cream4'', ``Cream5'', ``Cream6''. Again, this factor is an exact map to the Cream questions and thus is termed Creams.

PA2: ``Inj1'', ``Inj2'', ``Inj3'', ``Inj4'', ``Inj5'', ``Inj6''. These items are all Injection items, and so this factor gets that name. 

PA6: ``Pill1'', ``Pill2'', ``Pill3'', ``Pill4'', ``Pill5'', ``Pill6''. This factor maps to all of the pill items, and is thus called Pills. 

PA7: ``Pill3'',  ``Cream3'', ``Inj1'',   ``Inj3'' . This factor is a little strange, as it only takes some of the questions from the conventional factors. It does take the confidence question from all three conventional methodologies, and thus can be termed confidence in conventional treatments. 


%% The correlations between the factors are reported in Table \ref{tab:tcq2b7factorcorr}.

<<tcq2b7factorcorr, echo=FALSE, results=hide>>=
print(FactorCor(tcq2b.fact.7,label="tab:tcq2b7factorcorr", caption="Factor Correlations, TCQ2B, Seven factor Solution"))
@ 

<<tcq2cfact7, echo=FALSE, results=tex>>=
tcq2c.fact.7 <- fa(na.omit(tcqall2c), nfactors=7, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2c.fact.7, names=c("Hom", "Rei", "Acu", "Cream", "Inj", "Pill", "Cred"), label="tab:tcq2cfact7",caption="Seven Factor Solution, TCQ 2, Split C,  Oblimin Rotation"))
@ 

Table \ref{tab:tcq2cfact7} shows the seven factor solution structure for Split C. 


Again, the factors mostly break down into the six forms of treatment.

PA1: ``Hom1'', ``Hom2'', ``Hom3'', ``Hom4'', ``Hom5'', ``Hom6''. This factor represents the homeopathy items and retains that name. 

PA5: ``Rei1'', ``Rei2'', ``Rei3'', ``Rei4'', ``Rei5'', ``Rei6''. This is the Reiki items factor. 

PA3: ``Acu1'', ``Acu2'', ``Acu3'', ``Acu4'', ``Acu5'', ``Acu6''. This is the Acupuncture items factor. 

PA4: ``Cream1'', ``Cream2'', ``Cream3'', ``Cream4'', ``Cream5'', ``Cream6''. This is the Cream factor. 

PA2: ``Inj1'', ``Inj2'', ``Inj3'', ``Inj4'', ``Inj5'', ``Inj6''. This is the Injections factor. 

PA6: ``Pill1'', ``Pill2'', ``Pill3'', ``Pill4'', ``Pill5'', ``Pill6''. This is the Pills factor. 

PA7: ``Pill3'', ``Inj1'',  ``Inj3'' . This factor has supplementary loadings for some of the Pill and Injection items, most notably the confidence in the treatment items, so this can best be termed Confidence in Treatment Factor. 

%% The correlations between the factors are reported in Table \ref{tab:tcq2c7factorcorr}.

<<tcq2c7factorcorr, echo=FALSE, results=hide>>=
print(FactorCor(tcq2c.fact.7,label="tab:tcq2c7factorcorr", caption="Factor Correlations, Seven Factor Solution, TCQ 2, Split C"))
@ 

The seven factor solution %% (Table \ref{tab:tcq2c7factorcorr}
shows high intercorrelations between each of the conventional forms of treatment and each of the alternative forms of treatment but does not show any real correlations between them (except for Acupuncture). 



\subsection{Seven Factor Solutions}
\label{sec:seven-fact-solut}



<<tcq2dfact7, echo=FALSE, results=tex>>=
tcq2d.fact.7 <- fa(na.omit(tcqall2d), nfactors=7, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2d.fact.7, names=c("Reiki", "Hom", "Acu", "Cream", "Inj", "Pill", "Cred"), label="tab:tcq2dfact7",caption="Seven Factor Solution, TCQ 2, Oblimin Rotation (Split D)"))
@ 

The details of the seven factor solution for this split are shown in Table \ref{tab:tcq2dfact7}. 

This solution explained 84\% of the variance, an amount which was in line with that observed in other splits. 

PA1: ``Rei1'', ``Rei2'', ``Rei3'', ``Rei4'', ``Rei5'', ``Rei6''. These items map exactly to the Reiki questions, and so this factor will be termed Reiki. 

PA5: ``Hom1'', ``Hom2'', ``Hom3'', ``Hom4'', ``Hom5'', ``Hom6''. This factor will be termed Homeopathy. 

PA4: ``Acu1'', ``Acu2'', ``Acu3'', ``Acu4'', ``Acu5'', ``Acu6''. This factor will be termed Acupuncture. 

PA2: ``Cream1'', ``Cream2'', ``Cream3'', ``Cream4'', ``Cream5'', ``Cream6''. This factor will be termed Creams.

PA3: ``Inj1'', ``Inj2'', ``Inj3'', ``Inj4'', ``Inj5'', ``Inj6''. This factor will be termed Injections.

PA6: ``Pill1'', ``Pill2'', ``Pill3'', ``Pill4'', ``Pill5'', ``Pill6''. This factor will be termed Pills. 

PA7: ``Pill3'',  ``Cream3'', ``Inj3'' This factor has emerged in the other splits also, and again will be termed Confidence in Conventional Treatment.



<<tcq2d7factorcorr, echo=FALSE, results=hide>>=
print(FactorCor(tcq2d.fact.7,label="tab:tcq2d7factorcorr", caption="Factor Correlations, Seven Factor Solution, TCQ 2, Split D"))
@ 

<<tcq2bfitindices, echo=FALSE, results=tex, cache=TRUE, eval=FALSE>>=
tcq2bFit5 <- FitIndices(tcq2b.fact.5)
tcq2bFit6 <- FitIndices(tcq2b.fact.6)
tcq2bFit7 <- FitIndices(tcq2b.fact.7)
tcq2bfit <- as.data.frame(cbind(tcq2bFit5, tcq2bFit6, tcq2bFit7))
tcq2bfit.m <- melt(tcq2bfit)
names(tcq2bfit.m) <- "Fit Index"
print(xtable(tcq2bfit,caption="Fit Indices, TCQ 2 (Split B)", label="tab:tcq2bfit"))
@ 

\subsection{Split B CFA}
\label{sec:split-b-cfa}

<<tcq5notbSem, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
pillinj.cols <- c(pillitems.cols, Injitems.cols)
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills & Injections", "Creams", "Acupuncture", "Homeopathy", "Reiki")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
pillinj <- c(pills, inj)
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
Tcq5modelnotB <- mxModel(name="TCQ5notB", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills & Injections", to=pillinj), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notb)), type="cov", numObs=450))
tcq5fit.notB <- mxRun(Tcq5modelnotB)
tcq5summ.notB <- summary(tcq5fit.notB)
@ 


<<tcq6notbSem, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
Tcq6modelnotB <- mxModel(name="TCQ6notB", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notb)), type="cov", numObs=460))
tcq6fit.notB <- mxRun(Tcq6modelnotB)
tcq6summ.notB <- summary(tcq6fit.notB)
@ 

<<tcq7notBsem, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Confidence in Conventional Treatments")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
confconv <- c("Pill3", "Cream3", "Inj1", "Inj3")
Tcq7modelnotB <- mxModel(name="TCQ7notB", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Confidence in Conventional Treatments", to=confconv),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notb)), type="cov", numObs=460))
tcq7fit.notB <- mxRun(Tcq7modelnotB)
tcq7summ.notB <- summary(tcq7fit.notB)
@ 

<<tcq2notBsemcompare, echo=FALSE, results=tex>>=
tcq2.notB.semcompare <- mxCompare(tcq5fit.notB,c(tcq6fit.notB, tcq7fit.notB))
print(xtable(tcq2.notB.semcompare, label="tab:tcq2notBsemcompare", caption="TCQ 2 Factor Solutions From Split B, Tested Against Splits A, C and D"), scalebox=0.8)
@ 

It can be seen from Table \ref{tab:tcq2notBsemcompare} that the seven factor model from Split B provided a better fit to the out of sample data than did the six factor model. However, the difference in likelihood was not large (unlike in Sample One), and given that the seventh factor had only one factor loading on it, the six factor model should be preferred in this case. 

\subsection{IRT Analyses, Split B}
\label{sec:irt-analyses}



Again, the first step is to examine whether or not the TCQ should be split into separate scales, then check the that the assumptions are met for each of these scales. 

<<tcq2baisp, echo=FALSE, results=hide>>=
tcq2b.aisp <- aisp(na.omit(tcqall2b))
print(xtable(tcq2b.aisp, label="tab:tcq2baisp", caption="Item Selection Procedure for TCQ 2, Split B"))
@ 

The scales split along alternative and conventional lines, as in Split A. All further analyses will be carried out on the seperate scales. 



%% The first step in the examination of the TCQ conventional in split B is to check the IIO assumption. 

<<tcq2bcheckiio, echo=FALSE, results=hide>>=
tcq2b.conv.iio <- check.iio(na.omit(tcq2b.conv))
print(xtable(tcq2b.conv.iio$violations, label="tab:tcq2bcheckiio", caption="Item Ordering Assumption Check, TCQ 2 Conventional, Split B"))
@ 

There were no violations of either the monotonicity or item ordering assumptions for the conventional items in this split. 
This process of repeating assumptions is then repeated for the alternative question TCQ for Split B. There were no violations of the invariant item ordering assumption in this split, or violations of the monotonicity assumption. 

<<tcq2bconvcheckmono, echo=FALSE, results=hide>>=
tcq2b.conv.mono <- check.monotonicity(na.omit(tcq2b.conv))
print(xtable(summary(tcq2b.conv.mono), label="tab:tcq2bconvcheckmono", caption="Monotonicity Check, TCQ2 Conventional (Split B)"))
@ 





<<tcq2baltcheckiio, echo=FALSE, results=hide>>=
tcq2b.alt.iio <- check.iio(na.omit(tcq2b.alt))
print(xtable(tcq2b.alt.iio[["violations"]], label="tab:tcq2baltcheckiio", caption="Item Ordering Check TCQ2 Alternative (Split B)"))
@ 

<<tcq2baltcheckmono, echo=FALSE, results=hide>>=
tcq2b.alt.mono <- check.monotonicity(na.omit(tcq2b.alt))
print(xtable(summary(tcq2b.alt.mono), label="tab:tcq2baltcheckmono", caption="Monotonicity Check for TCQ 2, Alternative (Split B)"))
@ 



%% Next, a series of partial credit models were fit and checked for violations of the assumptions. 

<<tcq2bconvgpcm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2b.conv.gpcm.rasch <- gpcm(tcq2b.conv, constraint="rasch")
tcq2b.conv.gpcm.1PL <- gpcm(tcq2b.conv, constraint="1PL")
tcq2b.conv.gpcm.gpcm <- gpcm(tcq2b.conv, constraint="gpcm")
@ 

%% \begin{figure}
<<tcq2bconvgpcmraschplot, echo=FALSE, pdf=TRUE, png=TRUE, eps=TRUE, eval=FALSE>>=
gpcm.rasch.plot <- ggplotGRM(tcq2b.conv.gpcm.rasch)
print(gpcm.rasch.plot)
@   
%%   \caption{Item Parameter Plot for TCQ2B Conventional GPCM Rasch}
%%   \label{fig:tcq2bconvgpcmrasch}
%% \end{figure}

 %% Figure \ref{fig:tcq2bconvgpcmrasch} shows the fit of the Rasch generalised partial credit model. Note that the model estimates the thresholds to be almost identical for categories two and three, which is surprising but not necessarily fatal to the fit of the model. 

%% \begin{figure}
<<tcq2bconvgpcm1PLplot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
gpcm.1PL.plot <- ggplotGRM(tcq2b.conv.gpcm.1PL)
print(gpcm.1PL.plot)
@   
%%   \caption{Item Parameter Plot for TCQ2B Conventional GPCM}
%%   \label{fig:tcq2bconvgpcm1PLplot}
%% \end{figure}

%% Next, the fit of the one parameter GPCM was examined using an Item Parameter Plot (Figure \ref{fig:tcq2bconvgpcm1PLplot}). 
%% It can be seen that there are failures of the monotonicity assumption for Inj6, Inj2, Inj5, Inj1, Cream6, Cream5, Cream4, Cream2, Cream1, Pill6, Pill5, Pill4, Pill3, Pill2 and Pill1. In fact, most of the 2 and 3 thresholds are reversed, demonstrating that this model is not a good fit for the data. 


%% \begin{figure}
<<tcq2bconvgpcmgpcmplot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
gpcm.gpcm.plot <- ggplotGRM(tcq2b.conv.gpcm.gpcm)
print(gpcm.gpcm.plot)
@   
%%   \caption{Item Position Plot for Two Parameter GPCM (Split B)}
%%   \label{fig:tcq2bconvgpcm2plplot}
%% \end{figure}

%% As shown in Figure \ref{fig:tcq2bconvgpcm2plplot}, there are some failures of monotonicity here. Inj6, In5, Inj4, Inj3, Inj2, Inj1, Cream2, Cream1, Pill6, Pill5, Pill4, Pill3, Pill2 and Pill1. 

<<tcq2bconvpcmraschprint, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2b.conv.gpcm.rasch), caption="Coefficient Estimates, TCQ2 Conventional, Split B for Rasch Partial Credit Model", label="tab:tcq2bpcmrasch"))
@ 

%% As can be seen from Table \ref{tab:tcq2bpcmrasch}, the issues with category three are apparent again with this split, suggesting that it was being used as a default response choice by many of the participants. Again, the cream items have the highest thresholds, while the Injection items have the lowest. 

%% Next, we examine the coefficients for a one parameter PCM. 

<<tcq2bconvpcm1plprint, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2b.conv.gpcm.1PL), caption="Coefficient Estimates, TCQ2 Conventional, Split B for One Parameter Partial Credit Model", label="tab:tcq2bpcm1pl"))
@ 

%% Table \ref{tab:tcq2bpcm1pl} shows a similar pattern to the Rasch model, with the discrimination parameter having increased somewhat while the item thresholds have decreased somewhat. Again, the category three pattern is clearly apparent. 

%% Finally, the ability estimates and discrimination parameters for the two parameter model were examined. 

<<tcq2bconvpcm2plprint, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2b.conv.gpcm.gpcm), caption="Coefficient Estimates, TCQ2 Conventional, Split B for Two Parameter Partial Credit Model", label="tab:tcq2bpcm2pl"))
@ 

%% Table \ref{tab:tcq2bpcm2pl} shows the fit estimates for the two parameter model. As can be seen, the cream items have the highest estimated discrimination parameters, while those for the injection items have lowered considerably. 

%% As none of the partial credit model fitted the items, the next step was to examine the fit of the one and two parameter graded response models. 

<<tcq2bconvgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2b.conv.grm.1pl <- grm(tcq2b.conv, constrained=TRUE)
tcq2b.conv.grm.2pl <- grm(tcq2b.conv, constrained=FALSE)
@ 


%% \begin{figure}
<<tcq2bconvgrm1plot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2convgrm1plot <- ggplotGRM(tcq2b.conv.grm.1pl)
print(tcq2convgrm1plot)
@   
%%   \caption{Item Parameter Plot for TCQ Conventional 1 parameter Graded Response Model (Split B)}
%%   \label{fig:tcq2bconvgrm1plot}
%% \end{figure}


%% As shown in Figure \ref{fig:tcq2bconvgrm1plot}, there were no violations 
%% of monotonicity for the one parameter GRM. 

<<tcq2bconvgrm1plsumm, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2b.conv.grm.1pl), label="tab:tcq2bconvgrm1plsumm", caption="Coefficients for TCQ 2 Conventional (Split B), One parameter Graded Response Model"))
@ 

Table \ref{tab:tcq2bconvgrm1plsumm} shows that the cream items were the least endorsed, especially the highest response category. The estimated discrimination parameter is also quite high, at 2.08. This is probably due to a number of difficult items (the cream ones probably) dragging up the estimated discrimination parameter. 

%% \begin{figure}
<<tcq2bconvgrm2plot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2convgrm2plot <- ggplotGRM(tcq2b.conv.grm.2pl)
print(tcq2convgrm2plot)
@   
%%   \caption{Item Parameter Plot for TCQ Conventional 2 parameter Graded Response Model (Split B)}
%%   \label{fig:tcq2bconvgrm2plot}
%% \end{figure}


%% As can be seen from Figure \ref{fig:tcq2bconvgrm2plot}, there were no violations of monotonicity for the two parameter GRM. 

<<tcq2bconv2plgrmsum, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2b.conv.grm.2pl), label="tab:tcq2bconv2plgrmsum", caption="Coefficients for TCQ 2 Conventional (Split B) Two Parameter Graded Response Model"))
@ 

In the two parameter model (not shown), the discrimination parameters have lowered for most of the items, with the exception of Pill4, Pill5 and Pill6, where they have significantly increased. This is surprising, as the Cream items have much higher difficulty, but lower discrimination between different ability levels. 

Finally, the predictive power of each of the models was assessed. 

<<tcq2bmodtest, echo=FALSE, results=tex, cache=TRUE>>=
tcqconv.notb <- tcq2notb[,17:34]
tcq2b.pcm.rasch.done <- testIRTModels(tcq2b.conv.gpcm.rasch, tcqconv.notb, gpcmconstraint="rasch", grmconstraint=NULL)
tcq2b.pcm.1pl.done <- testIRTModels(tcq2b.conv.gpcm.1PL, tcqconv.notb, gpcmconstraint="1PL", grmconstraint=NULL)
tcq2b.pcm.gpcm.done <- testIRTModels(tcq2b.conv.gpcm.gpcm, tcqconv.notb, gpcmconstraint="gpcm", grmconstraint=NULL)
tcq2b.pcm.modcomp <- rbind(tcq2b.pcm.rasch.done, tcq2b.pcm.1pl.done, tcq2b.pcm.gpcm.done)

@ 
<<tcq2bpcmmodcompprint, echo=FALSE, results=hide>>=
tcq2b.pcm.modcomp.xtab <- xtable(tcq2b.pcm.modcomp, caption="Comparison of Splt B TCQ Conventional Scale Partial Credit Models on Splits A, C and D", label="tab:tcq2bpcmmodcomp")
print(tcq2b.pcm.modcomp.xtab)
@ 
%% As can be seen from Table \ref{tab:tcq2bpcmmodcomp}, the one parameter PCM model performed best on the unseen data, suggesting that the minimal flexibility allowed by the discrimination parameter was enough for an effective model. 

%% Next, this process is repeated for the graded response models. 

<<tcq2bgrmtest, echo=FALSE, results=hide, cache=TRUE>>=
tcq2b.grm.1pl.done <- testIRTModels(tcq2b.conv.grm.1pl, tcqconv.notb, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2b.grm.2pl.done <- testIRTModels(tcq2b.conv.grm.2pl, tcqconv.notb, gpcmconstraint=NULL, grmconstraint=FALSE)
tcq2b.grm.modcomp <- rbind(tcq2b.grm.1pl.done, tcq2b.grm.2pl.done)
rownames(tcq2b.grm.modcomp) <- c("One Parameter", "Two Parameter")

@ 
<<tcq2bgrmmodcomp, echo=FALSE, results=tex>>=
tcq2b.grm.modcomp.xtab <- xtable(tcq2b.grm.modcomp, caption="Performance of TCQ Conventional Graded Response Models from Split B, tested on Splits A, C and D", label="tab:tcq2bgrmmodcomp")
print(tcq2b.grm.modcomp.xtab)
@ 

As shown in Table \ref{tab:tcq2bgrmmodcomp}, the one parameter Graded Response Model provided the best performance on unseen data. 

Next, the same model fitting and testing procedure was applied to the Alternative Scale for Split B. 

<<tcq2baltpcm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2b.alt.gpcm.rasch <- gpcm(tcq2b.alt, constraint="rasch")
tcq2b.alt.gpcm.1PL <- gpcm(tcq2b.alt, constraint="1PL")
tcq2b.alt.gpcm.gpcm <- gpcm(tcq2b.alt, constraint="gpcm")
@ 

<<tcq2baltpcmraschprint, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2b.alt.gpcm.rasch), caption="Coefficient Estimates for Rasch Partial Credit Model, Split B, TCQ Conventional", label="tab:tcq2baltpcmrasch"))
@ 

%% Table \ref{tab:tcq2baltpcmrasch} shows that similarly to the pattern seen in Split A, the Homeopathy and Reiki items possessed much higher thresholds than did the acupuncture items, but all three had higher thresholds than did the conventional items. 

%% Next, the coefficients for the one parameter PCM are examined. 

<<tcq2baltpcm1plprint, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2b.alt.gpcm.1PL), caption="Coefficient Estimates for One Parameter Partial Credit Model, Split B, TCQ Conventional", label="tab:tcq2baltpcm1pl"))
@ 

%% Table \ref{tab:tcq2baltpcm1pl} shows that the discrimination parameter has increased by quite a large amount, while the abilities have lowered to compensate for this change. 

%% Finally, the estimated two parameter PCM was examined. 

<<tcq2baltpcm2plprint, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2b.alt.gpcm.gpcm), caption="Coefficient Estimates for Two Parameter Partial Credit Model, Split B, TCQ Conventional", label="tab:tcq2baltpcmgpcm"))
@

%% Table \ref{tab:tcq2baltpcmgpcm} shows the estimated coefficients for the two parameter model. It can be seen that the estimated discrimination parameters are much less extreme than those from Split A, and that for this split, the Homeopathy items are the most discriminating, but nonetheless the relationships between the Acupuncture items and the Homeopathy and Reiki items appears to be quite similar. 


<<tcq2baltgrmtest, echo=FALSE, results=hide, cache=TRUE>>=
tcq2notb.alt.irt <- tcq2notb[,35:52]
tcq2b.alt.gpcm.rasch.done <- testIRTModels(tcq2b.alt.gpcm.rasch, tcq2notb.alt.irt, gpcmconstraint="rasch", grmconstraint=NULL)
tcq2b.alt.gpcm.1pl.done <- testIRTModels(tcq2b.alt.gpcm.1PL, tcq2notb.alt.irt, gpcmconstraint="1PL", grmconstraint=NULL)
tcq2b.alt.gpcm.gpcm.done <- testIRTModels(tcq2b.alt.gpcm.gpcm, tcq2notb.alt.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
tcq2b.alt.gpcm.modcomp <- rbind( tcq2b.alt.gpcm.rasch.done,tcq2b.alt.gpcm.1pl.done, tcq2b.alt.gpcm.gpcm.done)
rownames(tcq2b.alt.gpcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")

@ 
<<tcq2baltpcmmodcompprint, echo=FALSE, results=hide>>=
print(xtable(tcq2b.alt.gpcm.modcomp, caption="Performance of Split B TCQ Alternative Partial Credit Models on Splits B, C and D", label="tab:tcq2baltgpcmmodcomp"))
@ 
%% As can be seen from Table \ref{tab:tcq2baltgpcmmodcomp}, the one parameter PCM provided the best fit to the unseen data. 


To do this, two graded response models were fit to the data. 

<<tcq2baltgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2b.alt.grm.1pl <- grm(tcq2b.alt, constrained=TRUE)
tcq2b.alt.grm.2pl <- grm(tcq2b.alt, constrained=FALSE)
@ 
<<tcq2baltgrm1pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2b.alt.grm.1pl), label="tab:tcq2bconv1plgrmsum", caption="Coefficients for TCQ 2 Conventional (Split B) One Parameter Graded Response Model"))
@


In Table \ref{tab:tcq2bconv1plgrmsum} are shown the coefficient estimates for the one parameter alternative scale graded response model for split B.

It can be seen that the ability estimates are extremely low, while the discrimination parameter is far higher than was seen in Split A. 

<<tcq2baltgrm2pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2b.alt.grm.2pl), label="tab:tcq2bconv2plgrmsum", caption="Coefficients for TCQ 2 Conventional (Split B) Two Parameter Graded Response Model"))
@

Table \ref{tab:tcq2bconv2plgrmsum} shows the corresponding coefficient estimates for the two parameter GRM. It can be seen that the discrimination parameter has lowered significantly, while the ability estimates have risen to counter balance this.

Next, each of these models performance was assessed on unseen data. 

<<tcq2baltgrmtest, echo=FALSE, results=tex, cache=TRUE>>=
tcq2notb.alt.irt <- tcq2notb[,35:52]
tcq2b.alt.grm.1pl.done <- testIRTModels(tcq2b.alt.grm.1pl, tcq2notb.alt.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2b.alt.grm.2pl.done <- testIRTModels(tcq2b.alt.grm.2pl, tcq2notb.alt.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2b.alt.grm.modcomp <- rbind(tcq2b.alt.grm.1pl.done, tcq2b.alt.grm.2pl.done)
rownames(tcq2b.alt.grm.modcomp) <- c("One Parameter GRM", "Two Parameter GRM")

@ 
<<tcq2baltgrmmodcomp, echo=FALSE, results=tex>>=
print(xtable(tcq2b.alt.grm.modcomp, caption="Performance of Split B TCQ Alternative Graded Response Model on Splits B, C and D", label="tab:tcq2baltgrmmodcomp"))
@ 
As shown in Table \ref{tab:tcq2baltgrmmodcomp}, the two parameter model provided a better approximation to the unseen data. 




\subsection{TCQ, Split C}
\label{sec:tcq-split-c}






\paragraph{Five Factor Solution}
\label{sec:five-factor-solution}




\paragraph{Six Factor Solution}
\label{sec:six-factor-solution}









<<tcq2cfitindices, echo=FALSE, results=tex, cache=TRUE, eval=FALSE>>=
tcq2cFit5 <- FitIndices(tcq2c.fact.5)
tcq2cFit6 <- FitIndices(tcq2c.fact.6)
tcq2cFit7 <- FitIndices(tcq2c.fact.7)
tcq2cfit <- as.data.frame(cbind(tcq2cFit5, tcq2cFit6, tcq2cFit7))
tcq2cfit.m <- melt(tcq2cfit)
names(tcq2cfit.m)[1] <- "Fit Index"
print(xtable(tcq2cfit.m,caption="Fit Indices, TCQ 2 (Split C)", label="tab:tcq2cfit"))
@ 


%% It can be seen from Table \ref{tab:tcq2cfit} that the NNFI increases across all factor solutions, but is still quite low for an acceptable factor structure. The BIC performs likewise, reaching its lowest value for the seven factor solution. The RMSEA are uniformly poor, but again appear to be best for the seven factor solution. 


\subsection{Split C CFA}
\label{sec:split-c-cfa}

Next, the fit of the models developed on Split C will be tested on Splits A, B and D. 

<<tcq5notcSem, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
pillinj.cols <- c(pillitems.cols, Injitems.cols)
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills & Injections", "Creams", "Acupuncture", "Homeopathy", "Reiki")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
pillinj <- c(pills, inj)
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
Tcq5modelnotC <- mxModel(name="TCQ5notC", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills & Injections", to=pillinj), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notc)), type="cov", numObs=452))
tcq5fit.notC <- mxRun(Tcq5modelnotC)
tcq5summ.notC <- summary(tcq5fit.notC)
@ 


<<tcq6notcSem, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
Tcq6modelnotC <- mxModel(name="TCQ6notC", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notc)), type="cov", numObs=460))
tcq6fit.notC <- mxRun(Tcq6modelnotC)
tcq6summ.notC <- summary(tcq6fit.notC)
@ 

<<tcq7notCsem, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Confidence in Conventional Treatments")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
confconv <- c("Pill3", "Inj1", "Inj3")
Tcq7modelnotC <- mxModel(name="TCQ7notC", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Confidence in Conventional Treatments", to=confconv),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notc)), type="cov", numObs=460))
tcq7fit.notC <- mxRun(Tcq7modelnotC)
tcq7summ.notC <- summary(tcq7fit.notC)
@ 

<<tcq2notCsemcompare, echo=FALSE, results=tex>>=
tcq2.notC.semcompare <- mxCompare(tcq5fit.notC,c(tcq6fit.notC, tcq7fit.notC))
print(xtable(tcq2.notC.semcompare, label="tab:tcq2notCsemcompare", caption="TCQ Models from Split C tested against Splits A, B and D"), scalebox=0.8)
@ 

It can be seen from Table \ref{tab:tcq2notCsemcompare} that the seven factor model from Split C provided a better fit to the out of sample data than did the 5 or 6 factor model. 

\subsection{IRT Analyses, Split C}
\label{sec:irt-analyses-split}



<<tcq2caisp, echo=FALSE, results=hide>>=
tcq2c.aisp <- aisp(na.omit(tcqall2c))
print(xtable(tcq2c.aisp, label="tab:tcq2caisp", caption="Item Selection Procedure Results, TCQ 2, Split C"))
@ 

The item-splitting procedure suggests that there are two scales, one for conventional items and another for alternative items, as was seen in the previous two splits. The assumption checking will therefore be carried out on each scale seperately. There were no violations of the item ordering or monotonicity assumptions in this split. 

<<tcq2csplitscales, echo=FALSE, results=hide, cache=TRUE>>=
tcq2c.conv <- tcqall2c[,1:18]
tcq2c.alt <- tcqall2c[,19:36]
@ 



<<tcq2ccheckiio, echo=FALSE, results=hide>>=
tcq2c.conv.iio <- check.iio(na.omit(tcq2c.conv))
print(xtable(tcq2c.conv.iio$violations, label="tab:tcq2ccheckiio", caption="Item Ordering Assumption Check, TCQ2 Conventional, Split C"))
@ 




<<tcq2cconvcheckmono, echo=FALSE, results=hide>>=
tcq2c.conv.mono <- check.monotonicity(na.omit(tcq2c.conv))
print(xtable(summary(tcq2c.conv.mono), label="tab:tcq2cconvcheckmono", caption="Monotonicity Check, TCQ 2 Conventional, Split C"))
@ 

%% Next, the monotonicity assumption was examined. Table \ref{tab:tcq2cconvcheckmono} shows that there were no violations of monotonicity in this sample. 

%% Next, the number of guttman errors for the TCQ conventional items were calculated and plotted. 

%% \begin{figure}
<<tcq2cconvguttman, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2c.conv.gutt <- check.errors(na.omit(tcq2c.conv))
tcq2c.conv.gutt.plot <- ggplot(as.data.frame(tcq2c.conv.gutt), aes(x=tcq2c.conv.gutt))+geom_histogram(binwidth=5)
print(tcq2c.conv.gutt.plot)
@   
%%   \caption{Histogram of Guttman errors for TCQ conventional items, Split C}
%%   \label{fig:tcq2cconvguttplot}
%% \end{figure}

%% The plot shown in Figure \ref{fig:tcq2cconvguttplot} is interesting. It can be seen that the majority of participants have very few guttman errors, but there are quite a few participants who have an extremely high level of scaling errors, suggesting that they were not engaging with the questions in a coherent manner. These participants may need to be removed in order to estimate accurate measures of person ability and item difficulty. 

Next, the assumptions of IRT were checked for the TCQ alternative items in this split. 

<<tcq2caltcheckiio, echo=FALSE, results=hide>>=
tcq2c.alt.iio <- check.iio(na.omit(tcq2c.alt))
print(xtable(tcq2c.alt.iio$violations, label="tab:tcq2caltcheckiio", caption="Item Ordering Assumption Check, TCQ2 Alternative, Split C"))
@ 

There were no violations of the invariant item ordering or monotonicity assumptions in this split for the alternative items. 


<<tcq2caltcheckmono, echo=FALSE, results=hide>>=
tcq2c.alt.mono <- check.monotonicity(na.omit(tcq2c.alt))
print(xtable(summary(tcq2c.alt.mono), label="tab:tcq2caltcheckmono", caption="Monotonicity Check, TCQ2 Alternative, Split C"))
@ 

%% Next, the monotonicity assumption was examined. Table \ref{tab:tcq2caltcheckmono} shows that there were no violations of the monotonicity assumption for the alternative items in this split. 

%% The next step in the analysis procedure was to fit a series of generalised partial credit models to the data (Rasch, one parameter and two parameter). The results are shown below. 

<<tcq2cconvgpcm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2c.conv.gpcm.rasch <- gpcm(tcq2c.conv, constraint="rasch")
tcq2c.conv.gpcm.1PL <- gpcm(tcq2c.conv, constraint="1PL")
tcq2c.conv.gpcm.gpcm <- gpcm(tcq2c.conv, constraint="gpcm")
@ 

%% \begin{figure}
<<tcq2cconvgpcmraschplot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2c.conv.gpcm.rasch.plot <- ggplotGRM(tcq2c.conv.gpcm.rasch)
print(tcq2c.conv.gpcm.rasch.plot)
@   
%%   \caption{Item Parameter Plot for TCQ2C Conventional GPCM Rasch}
%%   \label{fig:tcq2cconvgpcmrasch}
%% \end{figure}

%% Figure \ref{fig:tcq2cconvgpcmrasch} shows that the PCM again shows non-monotonically increasing parameter estimates, which is allowable in a PCM. This may mean that category 3 could be collapsed into the two adjacent categories. 

<<tcq2cgpcmraschprint, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2c.conv.gpcm.rasch), label="tab:tcq2cconvgpcmrasch", caption="Coefficient Estimates for Split C TCQ, Conventional Items, Partial Credit Rasch Model"))
@ 

%% The coefficient estimates for the Rasch PCM on the conventional items can be seen in Table \ref{tab:tcq2cconvgpcmrasch}. It can be seen that the pill items appear to have the lowest estimated threshold for category 1, while the injection items have the lowest threshold for category five. As has happened before, the cream items are regarded as the most difficult to endorse, and category 3 estimates appear to show that this catgory is being used as the base response, when participants have little to no opinion. 

%% \begin{figure}
<<tcq2cconvgpcm1PLplot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2c.conv.gpcm.1PL.plot <- ggplotGRM(tcq2c.conv.gpcm.1PL)
print(tcq2c.conv.gpcm.1PL.plot)
@   
%%   \caption{Item Parameter Plot for TCQ2C Conventional GPCM}
%%   \label{fig:tcq2cconvgpcm1PLplot}
%% \end{figure}

%% Again, as can clearly be seen from Figure \ref{fig:tcq2cconvgpcm1PLplot}, the monotonicity assumption was not met for this model. 

<<tcq2cconvgpcm1pl, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2c.conv.gpcm.1PL), label="tab:tcq2cconvgpcm1pl", caption="Coefficient Estimates for TCQ Conventional One Parameter PCM, Split C"))
@ 

%% Table \ref{tab:tcq2cconvgpcm1pl} shows the estimated coefficients for the one parameter PCM. The discrimination parameter has risen, but the majority of items retain the rank order from the Rasch estimated model. 



%% \begin{figure}
<<tcq2cconvgpcmgpcmplot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2c.conv.gpcm.gpcm.plot <- ggplotGRM(tcq2c.conv.gpcm.gpcm)
print(tcq2c.conv.gpcm.gpcm.plot)
@   
%%   \caption{Item Position Plot for Two Parameter GPCM (Split B)}
%%   \label{fig:tcq2cconvgpcm2plplot}
%% \end{figure}


%% Figure \ref{fig:tcq2cconvgpcm2plplot} shows that like the simpler models, the two parameter generalised partial credit model does not fit the data particularly well. 

<<tcq2cconvgpcmgpcm, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2c.conv.gpcm.gpcm), label="tab:tcq2cconvgpcmgpcm", caption="Coefficient Estimates for TCQ Conventional, Two Parameter PCM, Split C"))
@ 

%% Table \ref{tab:tcq2cconvgpcmgpmcm} shows the estimated coefficients for the two parameter model. It can be seen that the Cream items have traded off some difficulty and gained higher estimated discrimination parameters, while some of the injection and pill items actually have discrimination parameters lower than one, suggesting that they are less directly informative about the differences between participants of low and high ability. 

<<tcq2cconvgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2c.conv.grm.1pl <- grm(tcq2c.conv, constrained=TRUE)
tcq2c.conv.grm.2pl <- grm(tcq2c.conv, constrained=FALSE)
@ 

Next, the fit of one and two parameter graded response models (GRM) was examined. 

%% \begin{figure}
<<tcq2cconvgrm1plot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2c.convgrm1plot <- ggplotGRM(tcq2c.conv.grm.1pl)
print(tcq2c.convgrm1plot)
@   
%%   \caption{Item Parameter Plot for TCQ Conventional 1 parameter Graded Response Model (Split B)}
%%   \label{fig:tcq2cconvgrm1plot}
%% \end{figure}

%% Figure \ref{fig:tcq2cconvgrm1plot} shows that, in contrast to the partial credit models, the one parameter model provides a good fit to this scale. 

<<tcq2cconvgrm1plsumm, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2c.conv.grm.1pl), label="tab:tcq2cconvgrm1plsumm", caption="Coefficients for TCQ 2 Conventional (Split C), One Parameter Graded Response Model"))
@ 

In Table \ref{tab:tcq2cconvgrm1plsumm} the estimated thresholds for the one parameter graded response model are shown. It can be seen that the Cream items are perceived as the most difficult, and that the discrimination parameter (the slope) is estimated at 2.083. This is an average parameter estimated for the whole scale, and based on the results of the previous splits, we would expect to see the discrimination parameters increase for the Cream items and decrease for the Pill and Injection items. 


%% \begin{figure}
<<tcq2cconvgrm2plot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2convgrm2plot <- ggplotGRM(tcq2c.conv.grm.2pl)
print(tcq2convgrm2plot)
@   
%%   \caption{Item Parameter Plot for TCQ Conventional 2 parameter Graded Response Model (Split B)}
%%   \label{fig:tcq2cconvgrm2plot}
%% \end{figure}


%% Firstly, the fit of the two parameter graded response model was examined graphically, as shown in Figure \ref{fig:tcq2cconvgrm2plot}. This figure demonstrates that there are no obvious violations of monotonicity, and the coefficients are the next focus of attention.


<<tcq2cconv2plgrmsum, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2c.conv.grm.2pl), label="tab:tcq2cconv2plgrmsum", caption="Coefficients for TCQ 2 Split C Two Parameter Graded Response Model"))
@ 

The Two Parameter model for this split (not shown) shows that Pill 5 and Pill6 appear to have been the questions with the most discriminative power. The estimated thresholds have not changed that much, the Cream items still have the highest threshold estimates. 

Next, an ANOVA likelihood ratio test was carried out between the two models to determine which one fitted the data better. 

<<tcq2cconvanova, echo=FALSE, results=hide, cache=TRUE>>=
tcq2c.conv.anova <- anova(tcq2c.conv.grm.1pl, tcq2c.conv.grm.2pl)
@ 

The results of the ANOVA showed that the two parameter model fit the data significantly better than the one parameter model ($p\le 0.001$). In addition, the AIC and BIC measures (which penalise for extra parameters) agreed with the LR test, unlike in previous splits. Therefore, provisionally, it appears that the two parameter model provides the best fit to the data. 

Next, the performance of the IRT models was assessed on unseen data. 

<<tcq2cconvpcmtest, echo=FALSE, results=tex, cache=TRUE>>=
tcq2notc.conv <- tcq2notc[,17:34]
tcq2c.conv.pcm.rasch.done <- testIRTModels(tcq2c.conv.gpcm.rasch, tcq2notc.conv, gpcmconstraint="rasch", grmconstraint=NULL)
tcq2c.conv.pcm.1pl.done <- testIRTModels(tcq2c.conv.gpcm.1PL, tcq2notc.conv, gpcmconstraint="1PL", grmconstraint=NULL)
tcq2c.conv.pcm.gpcm.done <- testIRTModels(tcq2c.conv.gpcm.rasch, tcq2notc.conv, gpcmconstraint="gpcm", grmconstraint=NULL)
tcq2c.conv.pcm.modcomp <- rbind(tcq2c.conv.pcm.rasch.done, tcq2c.conv.pcm.1pl.done, tcq2c.conv.pcm.gpcm.done)
rownames(tcq2c.conv.pcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")
 
@ 
<<tcq2cconvpcmmodcompprint, echo=FALSE, results=hide>>=
tcq2c.conv.pcm.modcomp.xtab <- xtable(tcq2c.conv.pcm.modcomp, caption="Performance of IRT Models TCQ Conventional (Split C), on Splits A, B and D", label="tab:tcq2cconvpcmmodcomp")
print(tcq2c.conv.pcm.modcomp.xtab)                           
@ 
%% From Table \ref{tab:tcq2cconvpcmmodcomp}, it can be seen that the one parameter partial credit model was the best performing on unseen data. 

The same procedure was repeated for the graded response models for the TCQ conventional scale developed in this split. 

<<tcq2cconvgrmtest, echo=FALSE, results=tex, cache=TRUE>>=
tcq2c.conv.grm.1pl.done <- testIRTModels(tcq2c.conv.grm.1pl, tcq2notc.conv, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2c.conv.grm.2pl.done <- testIRTModels(tcq2c.conv.grm.2pl, tcq2notc.conv, gpcmconstraint=NULL, grmconstraint=FALSE)
tcq2c.conv.grm.modcomp <- rbind(tcq2c.conv.grm.1pl.done, tcq2c.conv.grm.2pl.done)
rownames(tcq2c.conv.grm.modcomp) <- c("One Paramter GRM", "Two Parameter GRM")

@ 
<<tcq2cconvgrmmodcomp, echo=FALSE, results=tex>>=
tcq2c.conv.grm.modcomp.xtab <- xtable(tcq2c.conv.grm.modcomp, caption="Performance of TCQ Conventional Graded Response Models (Split C) on Splits A, B and D", label="tab:tcq2convgrmmodcomp")
print(tcq2c.conv.grm.modcomp.xtab)
@ 
As can be seen from Table \ref{tab:tcq2convgrmmodcomp}, the one parameter Graded Response Model performed best on the unseen data. 

<<tca2caltpcm, echo=FALSE, results=tex, cache=TRUE>>=
tcq2c.alt.pcm.rasch <- gpcm(tcq2c.alt, constraint="rasch")
tcq2c.alt.pcm.1PL <- gpcm(tcq2c.alt, constraint="1PL")
tcq2c.alt.pcm.gpcm <- gpcm(tcq2c.alt, constraint="gpcm")
@ 

<<tcq2caltgpcmrasch, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2c.alt.pcm.rasch), label="tab:tcq2caltgpcmrasch", caption="Coefficient Estimates for TCQ Alternative Rasch PCM, Split C"))
@ 

%% Table \ref{tab:tcq2caltgpcmrasch} shows the estimated coefficients for the alternative scale in this split. It can be seen that all of the items have higher thresholds than those for the conventional scale, and that the Acupuncture items have somewhat lower thresholds than do the Homeopathy and Reiki items. 

%% Next, a one parameter PCM was examined on this scale. 

<<tcq2caltgpcm1pl, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2c.alt.pcm.1PL), label="tab:tcq2caltgpcm1pl", caption="Coefficient Estimates for TCQ Alternative, One Parameter PCM, Split C"))
@ 

%% Table \ref{tab:tcq2caltgpcm1pl} shows the estimated coefficients for this model. It can be seen that the discrimination parameter has risen substantially, suggesting that the alternative items are good at distinguishing between high and low ability participants. The relative thresholds of all three sets of items have remained stable, however. 

%% Finally, a two parameter PCM was fit to this scale. 

<<tcq2caltgpcmgpcm, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2c.alt.pcm.gpcm), label="tab:tcq2caltgpcmgpcm", caption="Coefficient Estimates for TCQ Alternative, Two Parameter PCM, Split C"))
@ 

%% Table \ref{tab:tcq2caltgpcmgpcm} shows the estimated parameters for the two parameter scale. It can be seen that the Homeopathy items are the most dicriminating, although the Reiki items have higher category four thresholds. This would seem to suggest that these items would be the most useful for discriminating between high and low ability participants. 

<<tcq2caltpcmmodcomp, echo=FALSE, results=tex, cache=TRUE>>=
tcq2notc.alt <- tcq2notc[,35:52]
tcq2c.alt.pcm.rasch.done <- testIRTModels(tcq2c.alt.pcm.rasch, tcq2notc.alt, gpcmconstraint="rasch", grmconstraint=NULL)
tcq2c.alt.pcm.1pl.done <- testIRTModels(tcq2c.alt.pcm.1PL, tcq2notc.alt, gpcmconstraint="1PL", grmconstraint=NULL)
tcq2c.alt.pcm.pcm.done <- testIRTModels(tcq2c.alt.pcm.rasch, tcq2notc.alt, gpcmconstraint="gpcm", grmconstraint=NULL)
tcq2c.alt.pcm.modcomp <- rbind(tcq2c.alt.pcm.rasch.done, tcq2c.alt.pcm.1pl.done, tcq2c.alt.pcm.pcm.done)
rownames(tcq2c.alt.pcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")

@ 
<<tcq2caltpcmmodcompprint, echo=FALSE, results=hide>>=
tcq2c.alt.pcm.modcomp.xtab <- xtable(tcq2c.alt.pcm.modcomp, caption="Performance of IRT Models TCQ Conventional (Split C), on Splits A, B and D", label="tab:tcq2caltpcmmodcomp")
print(tcq2c.alt.pcm.modcomp.xtab)                            

@ 
%% As can be seen from Table \ref{tab:tcq2caltpcmmodcomp}, the Rasch PCM provided the best fit on unseen data, though there was not much different between the Rasch and the one parameter model. 

Next, two graded response models were fit to the data. 

<<tcq2caltgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2c.alt.grm.1pl <- grm(tcq2c.alt, constrained=TRUE)
tcq2c.alt.grm.2pl <- grm(tcq2c.alt, constrained=FALSE)
@ 

<<tcq2caltgrm1pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2c.alt.grm.1pl), caption="Coefficients of TCQ Alternative (Split C) One Parameter Graded Response Model", label="tab:tcq2caltgrm1pl"))
@ 

As can be seen in Table \ref{tab:tcq2caltgrm1pl}, there are no obvious problems with this solution, as before the homeopathy and reiki questions tend to have higher ability estimates.



<<tcq2caltgrm2pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2c.alt.grm.2pl), caption="Coefficients of TCQ Alternative (Split C) Two Parameter Graded Response Model", label="tab:tcq2caltgrm2pl"))
@ 

Table \ref{tab:tcq2caltgrm2pl} shows that the pattern of other splits is confirmed in that the discrimination parameters of the acupuncture items lowers, while that of the other sets of items rises, with a corresponding tradeoff in estimated difficulty parameters. 

Finally for this model, we examine its performance on unseen data. 

<<tcq2cgrmmodtest, echo=FALSE, results=tex, cache=TRUE>>=
tcq2notc.alt.irt <- tcq2notc[,35:52]
tcq2c.alt.grm.1pl.done <- testIRTModels(tcq2c.alt.grm.1pl, tcq2notc.alt.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2c.alt.grm.2pl.done <- testIRTModels(tcq2c.alt.grm.2pl, tcq2notc.alt.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2c.alt.grm.modcomp <- rbind(tcq2c.alt.grm.1pl.done, tcq2c.alt.grm.2pl.done)

@ 
<<tcq2caltgrmmodcomprint, echo=FALSE, results=tex>>=
print(xtable(tcq2c.alt.grm.modcomp, caption="Performance of Split C TCQ Alternative Graded Response Models, tested on Splits A, B and D", label="tab:tcq2caltgrmmodcomp"))
@ 
As can be seen from Table \ref{tab:tcq2caltgrmmodcomp}, the two parameter model provides a better fit to the unseen data. 






\subsection{Split D}
\label{sec:split-d}



<<tcq2dscalesplit, echo=FALSE, results=hide, cache=TRUE>>=
tcqall2d <- tcq2d[,17:52]
bamall2d <- tcq2d[,53:70]
@ 

In this Split, the parallel analysis criterion suggested six factors while the MAP criterion suggested seven. Following previous practice, these two solutions were reported and examined for adequacy of fit and interpretability. 





<<tcq2dfitindices, echo=FALSE, results=tex, cache=TRUE, eval=FALSE>>=
tcq2dFit6 <- FitIndices(tcq2d.fact.6)
tcq2dFit7 <- FitIndices(tcq2d.fact.7)
tcq2dfit <- as.data.frame(cbind( tcq2dFit6, tcq2dFit7))
tcq2dfit.m <- melt(tcq2dfit)
names(tcq2dfit.m)[1] <- "Fit Index"
print(xtable(tcq2dfit.m,caption="Fit Indices, TCQ 2 (Split D)",label="tab:tcq2dfit"))
@ 


%% From Table \ref{tab:tcq2dfit}, the same pattern  as has been seen in previous splits emerges in that the NNFI increases while  the BIC decreases along with the RMSEA. 

\subsection{Split D CFA}
\label{sec:split-d-cfa}


Next, the fit of the models developed on Split C will be tested on Splits A, B and D. Firstly, the TCQ factor structures will be compared. 

<<tcq6notdSem, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
Tcq6modelnotD <- mxModel(name="TCQ6notD", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notd)), type="cov", numObs=460))
tcq6fit.notD <- mxRun(Tcq6modelnotD)
tcq6summ.notD <- summary(tcq6fit.notD)
@ 

<<tcq7notDsem, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Confidence in Conventional Treatments")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
confconv <- c("Pill3", "Cream3", "Inj3")
Tcq7modelnotD <- mxModel(name="TCQ7notD", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Confidence in Conventional Treatments", to=confconv),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notd)), type="cov", numObs=460))
tcq7fit.notD <- mxRun(Tcq7modelnotD)
tcq7summ.notD <- summary(tcq7fit.notD)
@ 

<<tcq2notDsemcompare, echo=FALSE, results=tex>>=
tcq2.notD.semcompare <- mxCompare(tcq6fit.notD, tcq7fit.notD)
print(xtable(tcq2.notD.semcompare, label="tab:tcq2notDsemcompare", caption="TCQ 2 Models built on Split D, tested against Splits A, B and C"), scalebox=0.8)
@ 

It can be seen from Table \ref{tab:tcq2notDsemcompare} that the seven factor model from Split D provided a better fit to the out of sample data than did the 6 factor model. 

Next, the fourth and final split was examined. Again, the first step is to examine the Treatment Credibility Questionnaire and assess how many scales the items break down into.

<<tcq2daisp, echo=FALSE, results=hide>>=
tcq2d.aisp <- aisp(na.omit(tcqall2d))
print(xtable(tcq2d.aisp, label="tab:tcq2daisp", caption="Item Selection Procedure Results, TCQ 2 Split D"))
@ 

Similarly to the first three splits, the TCQ splits along the conventional/alternative distinction. Therefore, the items will be split into conventional and alternative scales and all analyses carried out seperately. 



The first task to examine the TCQ conventional items and assess whether or not they meet the assumptions required for IRT modelling. All of the items in the TCQ conventional scale met the IIO (independently ordered observations) and monotonicity (non decreasing parameter estimates) assumptions.

<<tcq2dcheckiio, echo=FALSE, results=hide>>=
tcq2d.conv.iio <- check.iio(na.omit(tcq2d.conv))
print(xtable(tcq2d.conv.iio$violations, label="tab:tcq2dcheckiio", caption="Item Ordering Assumption Check, TCQ2 Conventional, Split D"))
@ 




<<tcq2dconvcheckmono, echo=FALSE, results=hide>>=
tcq2d.conv.mono <- check.monotonicity(na.omit(tcq2d.conv))
print(xtable(summary(tcq2d.conv.mono), label="tab:tcq2dconvcheckmono", caption="Monotonicity Check, TCQ 2 Conventional Split D"))
@ 

%% As can be seen from Table \ref{tab:tcq2dconvcheckmono}, all of the items in the conventional scale met this assumption. 
%% Next, the scale was checked for guttman scaling errors, and these were plotted. 

%% \begin{figure}
<<tcq2dconvguttman, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2d.conv.gutt <- check.errors(na.omit(tcq2d.conv))
tcq2d.conv.gutt.plot <- ggplot(as.data.frame(tcq2d.conv.gutt), aes(x=tcq2d.conv.gutt))+geom_histogram(binwidth=2)
print(tcq2d.conv.gutt.plot)
@   
%%   \caption{Histogram of Guttman errors for TCQ conventional items, Split D}
%%   \label{fig:tcq2dconvguttplot}
%% \end{figure}

%% As shown in Figure \ref{fig:tcq2dconvguttplot}, the majority of participants had no guttman errors, but there were some participants who made an extremely large number of scaling errors. %% This worry
%% ing feature of this split will be examined further when person and item fit indices are assessed in the context of parametric IRT modelling.


Next, the assumptions were checked for the alternative items, and there were no volations for either the IIO or monotonicity assumptions. 

<<tcq2daltcheckiio, echo=FALSE, results=hide>>=
tcq2d.alt.iio <- check.iio(na.omit(tcq2d.alt))
print(xtable(tcq2d.alt.iio$violations, label="tab:tcq2daltcheckiio", caption="Item Ordering Assumption Check, TCQ 2 Alternative, Split D"))
@ 

%% As can be seen from Table \ref{tab:tcq2daltcheckiio}, there were no violations of the IIO assumption for the alternative items. 

%% Next, the monotonicity assumption was examined for the alternative scale.


<<tcq2daltcheckmono, echo=FALSE, results=hide>>=
tcq2d.alt.mono <- check.monotonicity(na.omit(tcq2d.alt))
print(xtable(summary(tcq2d.alt.mono), label="tab:tcq2daltcheckmono", caption="Monotonicity Check, TCQ 2 Alternative, Split D"))
@ 

%% As shown in Table \ref{tab:tcq2daltcheckmono}, there were no violations of the monotonicity assumption, and the itemH coefficients are quite high, which suggests that this is a well-devised scale. 


<<tcq2dconvgpcm, echo=FALSE, results=hide>>=
tcq2d.conv.gpcm.rasch <- gpcm(tcq2d.conv, constraint="rasch")
tcq2d.conv.gpcm.1PL <- gpcm(tcq2d.conv, constraint="1PL")
tcq2d.conv.gpcm.gpcm <- gpcm(tcq2d.conv, constraint="gpcm")
@ 

%% \begin{figure}
<<tcq2dconvgpcmraschplot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2d.conv.gpcm.rasch.plot <- ggplotGRM(tcq2d.conv.gpcm.rasch)
print(tcq2d.conv.gpcm.rasch.plot)
@   
%%   \caption{Item Parameter Plot for TCQ2D Conventional GPCM Rasch}
%%   \label{fig:tcq2dconvgpcmrasch}
%% \end{figure}

%% The next step was to examine the fit of three partial credit models, and in Figure \ref{fig:tcq2dconvgpcmrasch}, it can be seen that there are problems with category 3 responses in this split also. 

<<tcq2dconvgpcmraschprint, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2d.conv.gpcm.rasch), label="tab:tcq2dgpcmrasch", caption="Coefficient Estimates for TCQ Conventional Items, Rasch PCM, Split D"))
@ 

%% Table \ref{tab:tcq2dgpcmrasch} shows the estimated coefficients for the Rasch PCM for the conventional items in this split. Again, a similar pattern as was seen in other splits emerges, where the Pill items have the lowest threshold for category 1, while the injection items are the easiest to endorse at the category 4 level. Again, the difficulties of the cream items, especially at the higher level, is apparent. 

%% \begin{figure}
<<tcq2dconvgpcm1PLplot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2d.conv.gpcm.1PL.plot <- ggplotGRM(tcq2d.conv.gpcm.1PL)
print(tcq2d.conv.gpcm.1PL.plot)
@   
%%   \caption{Item Parameter Plot for TCQ2D Conventional GPCM}
%%   \label{fig:tcq2dconvgpcm1PLplot}
%% \end{figure}

%% Next, the fit of a one parameter PCM (one discrimination parameter estimated from the data) is examined (see Figure \ref{fig:tcq2dconvgpcm1PLplot}). 

<<tcq2dgpcm1plprint, echo=FALSE, results=hide>>=
print(xtable(  coef(tcq2d.conv.gpcm.1PL), label="tab:tcq2dconvgpcm1pl", caption="Coefficient Estimates for TCQ Conventional, One Parameter PCM, Split D"))
@ 


%% Table \ref{tab:tcq2dconvgpcm1pl} shows the estimated coefficients for this model. It can be seen that the discrimination parameter has risen, although the relative difficulties of the items have stayed the same, much like in the previous split. 


%% \begin{figure}
<<tcq2dconvgpcmgpcmplot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2d.conv.gpcm.gpcm.plot <- ggplotGRM(tcq2d.conv.gpcm.gpcm)
print(tcq2d.conv.gpcm.gpcm.plot)
@   
%%   \caption{Item Position Plot for Two Parameter GPCM (Split D)}
%%   \label{fig:tcq2dconvgpcm2plplot}
%% \end{figure}

%% Finally, the fit of a two parameter PCM is shown in Figure \ref{fig:tcq2dconvgpcm2plplot}. 


<<tcq2dconvgpcmgpcmprint, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2d.conv.gpcm.gpcm), label="tab:tcq2dconvgpcmgpcm", caption="Coefficient Estimates for Two Parameter PCM, TCQ Conventional, Split D"))
@ 

%% Table \ref{tab:tcq2dconvgpcmgpcm} shows the estimated coefficients for the two parameter model. It can be seen that the discrimination parameters for the pill and injection items have lowered, while those for the cream items have increased substantially, suggesting that these items are good for dividing the sample into low and high ability participants. 

%% The next step was to examine the fit of one and two parameter Graded Response Models (GRM). 

<<tcq2dconvgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2d.conv.grm.1pl <- grm(tcq2d.conv, constrained=TRUE)
tcq2d.conv.grm.2pl <- grm(tcq2d.conv, constrained=FALSE)
@ 



%% \begin{figure}
<<tcq2dconvgrm1plot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2d.convgrm1plot <- ggplotGRM(tcq2d.conv.grm.1pl)
print(tcq2d.convgrm1plot)
@   
%%   \caption{Item Parameter Plot for TCQ Conventional 1 parameter Graded Response Model (Split D)}
%%   \label{fig:tcq2dconvgrm1plot}
%% \end{figure}

%% From Figure \ref{fig:tcq2dconvgrm1plot} it can be seen that there are no obvious violations of model assumptions for the one parameter GRM. 


<<tcq2dconvgrm1plsumm, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2d.conv.grm.1pl), label="tab:tcq2dconvgrm1plsumm", caption="Coefficients for TCQ Conventional, Split D, One Parameter Graded Response Model"))
@ 

Table \ref{tab:tcq2dconvgrm1plsumm} shows the coefficient estimates for the one parameter GRM. It can be seen that there are no violations of monotonicity, and that the discrimination parameter is estimated as being 2.064. The Cream items appear to be the least endorsed at higher levels (reflected in their higher thresholds at Category 4), while the Injection items appear to be the easiest to endorse, which fits with their higher credibility as an analgesic treatment. 


%% \begin{figure}
<<tcq2dconvgrm2plot, echo=FALSE, eval=FALSE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2donvgrm2plot <- ggplotGRM(tcq2d.conv.grm.2pl)
print(tcq2donvgrm2plot)
@   
%%   \caption{Item Parameter Plot for TCQ Conventional 2 parameter Graded Response Model (Split D)}
%%   \label{fig:tcq2dconvgrm2plot}
%% \end{figure}


%% Figure \ref{fig:tcq2dconvgrm2plot} shows the estimated thresholds for the conventional items under the Graded Response Model. This plot shows that there are no non-monotonic thresholds, and suggests that this model is appropriately applied to this data. 

<<tcq2dconv2plgrmsum, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2d.conv.grm.2pl), label="tab:tcq2dconv2plgrmsum", caption="Coefficients for TCQ2 Conventional Scale (Split D), Two Parameter Graded Response Model"))
@ 

The two parameter model (not shown) indicated that the Cream items have the highest discrimination parameters while the Injection items have the lowest. Item 3 has the highest ability threshold across all treatments, probably because this item asks about confidence that the treatment will completely eliminate the symptoms. 

<<tcq2dconvanova, echo=FALSE, results=hide, cache=TRUE>>=
tcq2d.conv.anova <- anova(tcq2d.conv.grm.1pl, tcq2d.conv.grm.2pl)
@ 

Finally, an ANOVA was carried out between the two graded response models, and this showed that there was no significant difference between the two models ($p=.593$), and the BIC and AIC were lower for the one parameter model, indicating better fit. 

%% Next, the performance of the models on unseen data is assessed. First, the performance of the partial credit models was examined for the conventional treatment credibility scale. 

<<tcq2dconvpcmmodtest, echo=FALSE, results=tex, cache=TRUE>>=
tcq2notd.irt <- tcq2notd[,17:34]
tcq2d.conv.gpcm.rasch.done <- testIRTModels(tcq2d.conv.gpcm.rasch, tcq2notd.irt, gpcmconstraint="rasch", grmconstraint=NULL)
tcq2d.conv.gpcm.1PL.done <- testIRTModels(tcq2d.conv.gpcm.1PL, tcq2notd.irt, gpcmconstraint="1PL", grmconstraint=NULL)
tcq2d.conv.gpcm.gpcm.done <- testIRTModels(tcq2d.conv.gpcm.gpcm, tcq2notd.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
tcq2d.conv.pcm.modcomp <- rbind(tcq2d.conv.gpcm.rasch.done, tcq2d.conv.gpcm.1PL.done, tcq2d.conv.gpcm.gpcm.done)
rownames(tcq2d.conv.pcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")

@ 
<<tcq2dconvgpcmmodcompprint, echo=FALSE, results=hide>>=
tcq2d.conv.gpcm.done.xtab <- xtable(tcq2d.conv.pcm.modcomp, caption="Performance of Split D Conventional TCQ Scale on Splits A, B and C", label="tab:tcq2dpcmmodcomp")
print(tcq2d.conv.gpcm.done.xtab)
@ 

%% As can be seen from Table \ref{tab:tcq2dpcmmodcomp}, the best performing model on unseen data was the one parameter PCM.

Two graded response models were fit to the data, in line with previous splits. 

<<tcq2dgrmmodcomp, echo=FALSE, results=hide, cache=TRUE>>=
tcq2d.conv.grm.1pl.done <- testIRTModels(tcq2d.conv.grm.1pl, tcq2notd.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2d.conv.grm.2pl.done <- testIRTModels(tcq2d.conv.grm.2pl, tcq2notd.irt, gpcmconstraint=NULL, grmconstraint=FALSE)
tcq2d.conv.grm.modcomp <- rbind(tcq2d.conv.grm.1pl.done, tcq2d.conv.grm.2pl.done)
rownames(tcq2d.conv.grm.modcomp) <- c("One Parameter GRM", "Two Parameter GRM")

@ 
<<tcq2dgrmmodcomp, echo=FALSE, results=tex>>=
print(xtable(tcq2d.conv.grm.modcomp, caption="Performance of Split D TCQ Conventional Graded Response Models on Splits A, B and C", label="tab:tcq2dconvgrmmodcomp"))
@

As can be seen from Table \ref{tab:tcq2dconvgrmmodcomp}, the one parameter Graded Response Model appears to provide the best fit to the unseen data. 



<<tca2daltpcm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2d.alt.pcm.rasch <- gpcm(tcq2d.alt, constraint="rasch")
tcq2d.alt.pcm.1PL <- gpcm(tcq2d.alt, constraint="1PL")
tcq2d.alt.pcm.gpcm <- gpcm(tcq2d.alt, constraint="gpcm")
@ 

<<tcq2daltpcmraschprint, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2d.alt.pcm.rasch), label="tab:tcq2daltpcmrasch", caption="Coefficient Estimates for TCQ Alternative, Rasch PCM, Split D"))
@ 

%% Table \ref{tab:tcq2daltpcmrasch} shows the estimated coefficients for the TCQ Alternative Rasch Partial Credit Model. It can be seen that the alternative items have much higher estimated thresholds than do the conventional items, with Acupuncture items being slightly easier to endorse than either Homeopathy or Reiki items. 

%% Next, a one parameter model was fit to this scale.

<<tcq2daltpcm1plprint, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2d.alt.pcm.1PL), label="tab:tcq2daltpcm1pl", caption="Coefficient Estimates, TCQ Alternative, One Parameter PCM, Split D"))
@ 

%% Table \ref{tab:tcq2daltpcm1pl} shows the estimated coefficients for this model. It can be seen that the discrimination parameter has risen quite signigicantly, while leave the relative ordering of the item sets much the same as it was in the Rasch model. 

%% Finally, a two parameter PCM was fit to this scale.

<<tcq2daltpcmgpcmprint, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2d.alt.pcm.gpcm), label="tab:tcq2daltpcm2pl", caption="Coefficient Estimates, TCQ Alternative, Two Parameter PCM, Split D"))
@ 

%% Table~\ref{tab:tcq2daltpcm2pl} shows the estimated coefficients for the two parameter PCM. It can be seen that the Homeopathy and Reiki items have extremelty high discrimination parameters, while those for the Acupuncture items have lowered. Note that the Reiki items have much higher discrimination parameters in this split, unlike Split C. 

<<tcq2daltpcmmodcomp, echo=FALSE, results=tex, cache=TRUE>>=
tcq2notd.irt <- tcq2notd[,35:52]
tcq2d.alt.gpcm.rasch.done <- testIRTModels(tcq2d.alt.pcm.rasch, tcq2notd.irt, gpcmconstraint="rasch", grmconstraint=NULL)
tcq2d.alt.gpcm.1PL.done <- testIRTModels(tcq2d.alt.pcm.1PL, tcq2notd.irt, gpcmconstraint="1PL", grmconstraint=NULL)
tcq2d.alt.gpcm.gpcm.done <- testIRTModels(tcq2d.alt.pcm.gpcm, tcq2notd.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
tcq2d.alt.pcm.modcomp <- rbind(tcq2d.alt.gpcm.rasch.done, tcq2d.alt.gpcm.1PL.done, tcq2d.alt.gpcm.gpcm.done)
rownames(tcq2d.alt.pcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")

@ 

<<tcq2daltpcmmocompprint, echo=FALSE, results=hide>>=
tcq2d.alt.gpcm.done.xtab <- xtable(tcq2d.alt.pcm.modcomp, caption="Performance of Split D Alternative TCQ Scale on Splits A, B and C", label="tab:tcq2daltpcmmodcomp")
print(tcq2d.alt.gpcm.done.xtab)
@ 
%% As can be seen from Table \ref{tab:tcq2daltpcmmodcomp}, the Rasch PCM provided the best performance on the unseen data. 

Next, two graded response models were fit to the alternative scale in this split. 

<<tcq2daltgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2d.alt.grm.1pl <- grm(tcq2d.alt, constrained=TRUE)
tcq2d.alt.grm.2pl <- grm(tcq2d.alt, constrained=FALSE)
@ 

<<tcq2daltgrm1pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2d.alt.grm.1pl), caption="Coefficients of TCQ Alternative (Split D) One Parameter Graded Response Model", label="tab:tcq2daltgrm1pl"))
@ 

As can be seen in Table \ref{tab:tcq2daltgrm1pl}, there are no obvious problems with this solution, as before the homeopathy and reiki questions tend to have higher ability estimates.



<<tcq2daltgrm2pl, echo=FALSE, results=hide>>=
print(xtable(coef(tcq2d.alt.grm.2pl), caption="Coefficients of TCQ Alternative (Split C) Two Parameter Graded Response Model", label="tab:tcq2daltgrm2pl"))
@ 

The two parameter alternative GRM (not shown) was similiar to  the pattern of other splits, in that the discrimination parameters of the acupuncture items lowered, while that of the other sets of items rises, with a corresponding tradeoff in estimated difficulty parameters. 

Finally for this model, we examine its performance on unseen data. 

<<tcq2cgrmmodtest, echo=FALSE, results=tex>>=
tcq2notc.alt.irt <- tcq2notc[,35:52]
tcq2d.alt.grm.1pl.done <- testIRTModels(tcq2d.alt.grm.1pl, tcq2notc.alt.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2d.alt.grm.2pl.done <- testIRTModels(tcq2d.alt.grm.2pl, tcq2notc.alt.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2d.alt.grm.modcomp <- rbind(tcq2d.alt.grm.1pl.done, tcq2d.alt.grm.2pl.done)
rownames(tcq2d.alt.grm.modcomp) <- c("One Parameter GRM", "Two Parameter GRM")
print(xtable(tcq2d.alt.grm.modcomp, caption="Performance of Split C TCQ Alternative Graded Response Models, tested on Splits A, B and D", label="tab:tcq2daltgrmmodcomp"))
@ 

As can be seen from Table \ref{tab:tcq2daltgrmmodcomp}, the one parameter model provides a better fit to the unseen data. 

\subsection{Backtesting}
\label{sec:backtesting}





The next stage in  our analysis is to take the best of these models from each split and test them on the entire dataset. While this is, in a sense, analysing the data twice, it is the most practicable way in which to determine the best model for the entire sample~\footnote{due to the changes in the scale in Sample Two, a backtesting strategy was not possible in this case}. 

The best fitting models on the out of sample data were as follows:
\begin{itemize}
%% \item  Split A:  TCQ7

\item Split B:  TCQ7

\item Split C:  TCQ7

\item Split D: TCQ7
\end{itemize}

Each of these models will be run on the full dataset, and the results assessed. The model which fits best on this sample will be used to predict factor scores for the experimental data. 

<<fullscales2, echo=FALSE, results=hide, cache=TRUE>>=
tcqall2 <- tcq2[,17:52]
bamall2 <- tcq2[,53:70]
@ 

<<tcq7notAsemAll, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Seven")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
seven <- c("Inj1", "Inj3")
Tcq7modelnotA.all <- mxModel(name="TCQ7notAAll", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Seven", to=seven),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2)), type="cov", numObs=594))
tcq7fit.notA.all <- mxRun(Tcq7modelnotA.all)
tcq7summ.notA.all <- summary(tcq7fit.notA.all)
@ 



<<tcq7notBsemAll, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Confidence in Conventional Treatments")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
confconv <- c("Pill3", "Cream3", "Inj1", "Inj3")
Tcq7modelnotB.all <- mxModel(name="TCQ7notBAll", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Confidence in Conventional Treatments", to=confconv),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2)), type="cov", numObs=594))
tcq7fit.notB.all <- mxRun(Tcq7modelnotB.all)
tcq7summ.notB.all <- summary(tcq7fit.notB.all)
@ 




<<tcq7notCsemAll, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Confidence in Conventional Treatments")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
confconv <- c("Pill3", "Inj1", "Inj3")
Tcq7modelnotC.all <- mxModel(name="TCQ7notCAll", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Confidence in Conventional Treatments", to=confconv),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2)), type="cov", numObs=594))
tcq7fit.notC.all <- mxRun(Tcq7modelnotC.all)
tcq7summ.notC.all <- summary(tcq7fit.notC.all)
@ 



<<tcq7notDAllsemAll, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Confidence in Conventional Treatments")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
confconv <- c("Pill3", "Cream3", "Inj3")
Tcq7modelnotD.all <- mxModel(name="TCQ7notDAll", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Confidence in Conventional Treatments", to=confconv),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2)), type="cov", numObs=594))
tcq7fit.notD.all <- mxRun(Tcq7modelnotD.all)
tcq7summ.notD.all <- summary(tcq7fit.notD.all)
@ 





<<tcqall2semcompare, echo=FALSE, results=tex>>=
tcqall2.semcompare <- mxCompare(tcq7fit.notA.all, c(tcq7fit.notB.all, tcq7fit.notC.all, tcq7fit.notD.all))
print(xtable(tcqall2.semcompare, label="tab:tcqall2semcompare", caption="TCQ2 Models from each split tested against the full dataset Results"), scalebox=0.8)
@ 

As can be seen from Table \ref{tab:tcqall2semcompare}, models B, C and D were identical and they appear to provide the best fit on all of the data. 

%% \subsection{IRT Analyses}
%% \label{sec:irt-analyses}


%% The next step in the analysis procedure was to examine the treatment credibility questionnaire in terms of item response theory. The same approach as taken for the factor analytic procedures was taken, such that seperate models were fitted on subsets of the data, and then tested against the out-of-sample data, before being finalised on the entire set of data. First, non-parametric IRT (or Mokken analysis) was applied to test the assumptions required for the parametric models. The analysis proper then began with the simplest of IRT models, the Rasch model, followed by a one parameter model with an estimated discrimination, followed by a two parameter model. 


\section{Reducing the size of the TCQ}
\label{sec:reducing-size-tcq}

The TCQ Version 2 discussed in this chapter consisted of 36 questions. It was decided to reduce the number of items in the questionnaire in order to reduce the burden on participants, and to reduce the time needed to complete the experiment to less than one hour (in almost every case). Therefore, it was decided to reduce the TCQ to 18 questions, three for each methodology. Additionally, given that the measures across different forms of treatments needed to be comparable, this meant removing the same three questions across all treatment options. 

This procedure was carried out using the IRT and Factor Analytic models built up in this chapter. 

One interesting part of the factor analytical results reported above was that a seven factor solution was consistently a better performer on unseen data using SEM. This factor tended to consist of the pill and injection items 1 and 3. This would seem to suggest that these two items loaded on both the relevant treatment factor(s), and another overall factor that tended to be termed confidence in (conventional) treatment. Additionally, these two items tended to have lower factor loadings on their respective treatment factors. Therefore, it was decided to remove items 1 and 3 for each of the six sections of the TCQ before administering it to the experimental sample. 

\begin{figure}
<<inffig1and3, echo=FALSE, fig=TRUE>>=
par(mfrow=c(3, 3))
plot(tcq2a.conv.grm.2pl, items=c(1, 3, 7, 9, 13, 15), main=NULL)
@   
  \caption{Information Curves for Items One and Three for TCQ-Conventional, Split A}
  \label{fig:infcurveoneandthree}
\end{figure}

Figure \ref{fig:infcurveoneandthree} shows the estimated parameters for items one and three for conventional treatments. It can be seen that Item one consistently has extremely poor coverage over the range of abilities, given that only response thresholds 1, 4 and 5 cover any appreciable amount of the ability distribution. Perhaps surprisingly, items one and three for the alternative treatments did not have this problem, but overall they showed an extremely bimodal split, with respondents either endorsing them whole-heartedly or rejecting them outright. 

With the decision taken to remove the potentially problematic items one and three, the choice was between items two, four, five and six. Of these, items 2, 4 and 6 are coherent and cover overall expectancies, cognitive expectancies and emotional expectancies. Previous research has outlined these as two important factors of care \cite{Blasi2001}, and the three questions span a relatively broad span of ability ranges, and cover approximately 50\% of the available test information between -3 and +3 (assuming that the ability scores are normally distributed). %% Indeed, comparing the Item 2, 4, 6 split against the 1, 3, 5 split over the ranges (-2, 2) and (-3, 3) shows that in all cases, the the 2, 4, 6 split had a greater amount of test information (assuming constant models). The models used to measure the information were the one parameter graded response models which had been shown to perform the best 


\section{Regression Analyses}
\label{sec:regression-analyses}

The next part of the analysis to be carried out was regression analysis. There were a number of demographic variables collected in the second sample, to allow for examination of their effects on the outcome variables (the treatment credibility scores). Gender, education, college of study or work, health, income and experience with the six forms of treatment were collected. %% The approach taken to the analysis was the following. Using the four splits that were used for the psychometric analysis. In this case, models were fit on 3 of the four splits, and the results of these analyses were predicted using the held out data. This allows for the use of step methods of regression while ensuring unbiased p values and standard errors. 

The method used was the following. Firstly, the sample was divided into training (70\%) and test (30\%) splits. Ten-fold cross-validation was performed on all training sets, and the best model(s) were then tested on the test set, which allowed for accurate p-values and standard errors (for stepwise approaches) to be calculated. 

<<splitdata, echo=FALSE, results=hide>>=

tcq2.full <- tcq2[complete.cases(tcq2),]
tcq2.pill.ind <- with(tcq2.full, createDataPartition(Pilltot, times=1, p=0.7, list=FALSE))
tcq2.pill.train <- tcq2.full[tcq2.pill.ind,]
tcq2.pill.pred.train <- tcq2.pill.train[,c("Creamtot", "Injtot", "Acutot", "Homtot", "ExpPill", "ExpCream", "ExpInj", "ExpAcu", "ExpRei")]
## tcq2.pill.pred.train.mm <- model.matrix(tcq2.pill.pred.train)
tcq2.pill.test <- tcq2.full[-tcq2.pill.ind,]
tcq2.pill.pred.test <- tcq2.pill.test[,c("Creamtot", "Injtot", "Acutot", "Homtot", "ExpPill", "ExpCream", "ExpInj", "ExpAcu", "ExpRei")]
tcq2.pill.resp.train <- with(tcq2.pill.train, Pilltot)
tcq2.pill.resp.test <- with(tcq2.pill.test, Pilltot)
@ 

%% \subsubsection{Split A}
%% \label{sec:split}

%% The Split A sample consisted of Splits B, C and D, with Split A being used as held out data for testing. %% The first step was to examine the inter-relationships of the variables graphically, to give insights into which variables were the most important. 



<<stepwiselm, echo=FALSE, results=hide, cache=TRUE>>=
pilltotlm1 <- lm(Pilltot~Creamtot+Injtot+Acutot+Homtot+Reitot+ ExpPill+ExpCream+ExpInj+ExpAcu+ExpHom+ExpRei, data=tcq2.pill.train)
pilltot.step <- stepAIC(object=pilltotlm1, upper=pilltotlm1,lower=~1, direction="both", k=3)

@

<<steppilla, echo=FALSE, results=hide>>=
print(xtable(summary(pilltot.step), label="tab:tcq2steppill", caption="Results of Stepwise Regression for Pill Total on Training Data"))
pilltot.pred <- predict(pilltotlm1, newdata=tcq2.pill.test)
@ 

<<lmonheldoutdata, echo=FALSE, results=tex>>=
pilltotlm.holdout <- lm(Pilltot~Creamtot+Injtot+Acutot+ExpPill+ExpCream, data=tcq2.pill.test)
print(xtable(summary(pilltotlm.holdout), label="tab:tcq2pillholdout", caption="Coefficients for Pill credibility Regression on Held Out Data"))
@ 


Rerunning the model on the held out data, the model (Table~\ref{tab:tcq2pillholdout}) was highly significant F(10,129)=54.76, $p\le 0.001$. The model had an adjusted $R^2$ of 0.689914, which equates to approximately 70\% of the variance in Pilltotal explained. The Cream and Injection variables were highly significant, while the Acupuncture and Experience variables did not pass the traditional significance filter. 

Next, lasso and ridge regressions were performed on the Pill Total variable. 

<<pill2lasso, echo=FALSE, results=tex, cache=TRUE>>=
pill.test <- with(na.omit(tcq2a), Pilltot)
pill2.lasso <- penalisedRegression(tcq2.pill.pred.train, tcq2.pill.resp.train, testdata=tcq2.pill.pred.test, newy=tcq2.pill.resp.test, alpha=1, type="coefficients")
@

<<pill2lassoprint, echo=FALSE, results=tex>>=
colnames(pill2.lasso) <- "Coefficients"
print(xtable(as.matrix(pill2.lasso), label="tab:tcq2apilllasso", caption="Coefficient Estimates for Lasso Regression using Pilltotal as a dependent variable"))
@ 


Table \ref{tab:tcq2apilllasso} shows the estimated coefficients for the lasso regression solution on held out data. As can be seen, there were strong positive coefficients for Creams and Inhjectons, some weak negative correlations for the alternative treatments and experience with alternative treatments variable, and surprisingly enough, a weak negative coefficient for Experience with painkilling creams. 

<<pill2aridge, echo=FALSE, results=tex>>=
pill2.ridge <- penalisedRegression(tcq2.pill.pred.train, tcq2.pill.resp.train, tcq2.pill.pred.test, alpha=0, newy=tcq2.pill.resp.test, type="coefficients")
colnames(pill2.ridge) <- "Coefficients"
print(xtable(as.matrix(pill2.ridge), label="tab:tcq2apillridge", caption="Coefficient Estimates on Held Out Data for Pilltotal, Ridge Regression, Split A"))
@ 

Table \ref{tab:tcq2apillridge} shows the estimated coefficients for the ridge regression solution. It can be seen that the results are broadly in line with those from the lasso regression, with the exception that Experience with Reiki now has a positive coefficient. 

The next step was to repeat this process using Cream total as a dependent variable.

<<splitdata, echo=FALSE, results=hide>>=
tcq2.full <- tcq2[complete.cases(tcq2),]
tcq2.cream.ind <- with(tcq2.full, createDataPartition(Creamtot, times=1, p=0.7, list=FALSE))
tcq2.cream.train <- tcq2.full[tcq2.cream.ind,]
tcq2.cream.pred.train <- tcq2.cream.train[,c("Pilltot", "Injtot", "Acutot", "Homtot", "ExpPill", "ExpCream", "ExpInj", "ExpAcu", "ExpRei")]
## tcq2.cream.pred.train.mm <- model.matrix(tcq2.cream.pred.train)
tcq2.cream.test <- tcq2.full[-tcq2.cream.ind,]
tcq2.cream.pred.test <- tcq2.cream.test[,c("Creamtot", "Injtot", "Acutot", "Homtot", "ExpCream", "ExpCream", "ExpInj", "ExpAcu", "ExpRei")]
tcq2.cream.resp.train <- with(tcq2.cream.train, Creamtot)
tcq2.cream.resp.test <- with(tcq2.cream.test, Creamtot)
@ 

<<stepwiselm, echo=FALSE, results=hide, cache=TRUE>>=
creamtotlm1 <- lm(Creamtot~Pilltot+Injtot+Acutot+Homtot+Reitot+ ExpPill+ExpCream+ExpInj+ExpAcu+ExpHom+ExpRei, data=tcq2.cream.train)
creamtot.step <- stepAIC(object=creamtotlm1, upper=creamtotlm1,lower=~1, direction="both", k=3)
@

<<steppilla, echo=FALSE, results=hide>>=
print(xtable(summary(creamtot.step), label="tab:tcq2stepcream", caption="Results of Stepwise Regression for Cream Total on Training Data"))
creamtot.pred <- predict(creamtotlm1, newdata=tcq2.cream.test)
@ 

<<lmonheldoutdata, echo=FALSE, results=tex>>=
creamtotlm.holdout <- lm(Creamtot~Pilltot+Injtot+Acutot+ExpPill+ExpCream, data=tcq2.cream.test)
print(xtable(summary(creamtotlm.holdout), label="tab:tcq2creamholdout", caption="Coefficients for Cream credibility Regression on Held Out Data"))
@ 





The results for the held out data are shown in Table \ref{tab:tcq2creamholdout}. The model was again signficiant, with an $F(6,144)=20.61$, and a p-value of $p\le 0.001$. The adjusted $R^2$ for the model was equal to 0.4497.


Next, lasso and ridge regression models were fit to this variable. 

<<cream2lasso, echo=FALSE, results=tex, cache=TRUE>>=
cream.test <- with(na.omit(tcq2a), Creamtot)
cream2.lasso <- penalisedRegression(tcq2.cream.pred.train, tcq2.cream.resp.train, testdata=tcq2.cream.pred.test, newy=tcq2.cream.resp.test, alpha=1, type="coefficients")
@

<<cream2lassoprint, echo=FALSE, results=tex>>=
colnames(cream2.lasso) <- "Coefficients"
print(xtable(as.matrix(cream2.lasso), label="tab:tcq2acreamlasso", caption="Coefficient Estimates for Lasso Regression using Creamtotal as a dependent variable"))
@ 

Tavle \ref{tab:tcq2acreamlasso} shows the estimated coefficients for the lasso fit. Pill and Injection totals have high coefficients while the coefficient for Acupuncture is moderate. Note that in this model, the coefficient for experience with cream treatments was negative, reinforcing the notion that something around experience with these two treatments is negatively related. 

<<pill2aridge, echo=FALSE, results=tex>>=
pill2.ridge <- penalisedRegression(tcq2.pill.pred.train, tcq2.pill.resp.train, tcq2.pill.pred.test, alpha=0, newy=tcq2.pill.resp.test, type="coefficients")
print(xtable(as.matrix(pill2.ridge), label="tab:tcq2apillridge", caption="Coefficient Estimates on Held Out Data for Pilltotal, Ridge Regression, Split A"))
@ 


<<cream2aridge, echo=FALSE, results=tex>>=
cream2.ridge <- penalisedRegression(tcq2.cream.pred.train, tcq2.cream.resp.train, tcq2.cream.pred.test, alpha=0, newy=tcq2.cream.resp.test, type="coefficients")
colnames(cream2.ridge) <- "Coefficients"
print(xtable(as.matrix(cream2.ridge), label="tab:tcq2acreamridge", caption="Coefficient Estimates on Held Out Data for Cream Credibility Total, Ridge Regression, Split A"))
@ 



Table \ref{tab:tcq2acreamridge} shows a similar enough pattern to the results of the lasso regression, including the strong negative coefficient of experience with pill painkillers on cream credibility.  

Next, the same modelling procedure was applied to the Injection credibility scores. 

<<splitdata, echo=FALSE, results=hide>>=
tcq2.full <- tcq2[complete.cases(tcq2),]
tcq2.inj.ind <- with(tcq2.full, createDataPartition(Injtot, times=1, p=0.7, list=FALSE))
tcq2.inj.train <- tcq2.full[tcq2.inj.ind,]
tcq2.inj.pred.train <- tcq2.inj.train[,c("Pilltot", "Creamtot", "Acutot", "Homtot", "ExpPill", "ExpCream", "ExpInj", "ExpAcu", "ExpRei")]
## tcq2.inj.pred.train.mm <- model.matrix(tcq2.inj.pred.train)
tcq2.inj.test <- tcq2.full[-tcq2.inj.ind,]
tcq2.inj.pred.test <- tcq2.inj.test[,c("Pilltot", "Creamtot", "Acutot", "Homtot", "ExpPill", "ExpCream", "ExpInj", "ExpAcu", "ExpRei")]
tcq2.inj.resp.train <- with(tcq2.inj.train, Injtot)
tcq2.inj.resp.test <- with(tcq2.inj.test, Injtot)
@ 

<<stepwiselm, echo=FALSE, results=hide, cache=TRUE>>=
injtotlm1 <- lm(Injtot~Pilltot+Injtot+Acutot+Homtot+Reitot+ ExpPill+ExpInj+ExpInj+ExpAcu+ExpHom+ExpRei, data=tcq2.inj.train)
injtot.step <- stepAIC(object=injtotlm1, upper=injtotlm1,lower=~1, direction="both", k=3)
@


<<lmonheldoutdata, echo=FALSE, results=tex>>=
injtotlm.holdout <- lm(Injtot~Pilltot+Acutot+Reitot+ExpInj, data=tcq2.inj.test)
print(xtable(summary(injtotlm.holdout), label="tab:tcq2injholdout", caption="Coefficients for Injection credibility Regression on Held Out Data"))
@ 


The model results shown in Table \ref{tab:tcq2injholdout} show that Cream and Pill credibility scores were excellent predictors, while Experience with Injections is not significant on the unseen data, while experience with pills is. The model was independently significant: F(4,313)=16.42, $p\le 0.0001$, and the adjusted $R^2$ was equal to 0.3912. 


<<inj2lasso, echo=FALSE, results=tex, cache=TRUE>>=
inj.test <- with(na.omit(tcq2a), Injtot)
inj2.lasso <- penalisedRegression(tcq2.inj.pred.train, tcq2.inj.resp.train, testdata=tcq2.inj.pred.test, newy=tcq2.inj.resp.test, alpha=1, type="coefficients")
@

<<inj2lassoprint, echo=FALSE, results=tex>>=
colnames(inj2.lasso) <- "Coefficients"
print(xtable(as.matrix(inj2.lasso), label="tab:tcq2ainjlasso", caption="Coefficient Estimates for Lasso Regression using Injection Credibility Total as a dependent variable"))
@ 

As shown in Table~\ref{tab:tcq2ainjlasso}, the pattern was similar to the stepwise regression, with strong effects of the other conventional treatments. Again, the experience with pills has a larger coefficient than does experience with Injections, suggesting that the distinctions between painkilling treatments were not particularly salient to the participants. 




<<inj2aridge, echo=FALSE, results=tex>>=
inj2.ridge <- penalisedRegression(tcq2.inj.pred.train, tcq2.inj.resp.train, tcq2.inj.pred.test, alpha=0, newy=tcq2.inj.resp.test, type="coefficients")
colnames(inj2.ridge) <- "Coefficients"
print(xtable(as.matrix(inj2.ridge), label="tab:tcq2ainjridge", caption="Coefficient Estimates on Held Out Data for Injtotal, Ridge Regression, Split A"))
@ 

Table~\ref{tab:tcq2ainjridge} shows the corresponding coefficients for the ridge regression. The general pattern remains the same, with the experience with pills coefficient being larger than that for injections. 

Next, the same procedure was applied to the Acupuncture credibility scores. 

<<splitdata, echo=FALSE, results=hide>>=
tcq2.full <- tcq2[complete.cases(tcq2),]
tcq2.acu.ind <- with(tcq2.full, createDataPartition(Acutot, times=1, p=0.7, list=FALSE))
tcq2.acu.train <- tcq2.full[tcq2.acu.ind,]
tcq2.acu.pred.train <- tcq2.acu.train[,c("Pilltot", "Creamtot", "Injtot", "Homtot","Reitot",  "ExpPill", "ExpCream", "ExpAcu", "ExpInj", "ExpRei", "ExpHom")]
## tcq2.acu.pred.train.mm <- model.matrix(tcq2.acu.pred.train)
tcq2.acu.test <- tcq2.full[-tcq2.acu.ind,]
tcq2.acu.pred.test <- tcq2.acu.test[,c("Pilltot", "Creamtot", "Injtot", "Reitot","Homtot", "ExpPill", "ExpCream", "ExpAcu", "ExpInj", "ExpRei", "ExpHom")]
tcq2.acu.resp.train <- with(tcq2.acu.train, Acutot)
tcq2.acu.resp.test <- with(tcq2.acu.test, Acutot)
@ 

<<stepwiselm, echo=FALSE, results=hide, cache=TRUE>>=
acutotlm1 <- lm(Acutot~Pilltot+Creamtot+Injtot+Homtot+Reitot+ ExpPill+ExpAcu+ExpAcu+ExpAcu+ExpHom+ExpRei, data=tcq2.acu.train)
acutot.step <- stepAIC(object=acutotlm1, upper=acutotlm1,lower=~1, direction="both", k=3)
@


<<lmonheldoutdata, echo=FALSE, results=tex>>=
acutotlm.holdout <- lm(Acutot~Creamtot+Homtot+Reitot+ExpAcu+ExpHom, data=tcq2.acu.test)
print(xtable(summary(acutotlm.holdout), label="tab:tcq2acuholdout", caption="Coefficients for Acu credibility Regression on Held Out Data"))
@ 

As shown in Table \ref{tab:tcq2acuholdout}, only Creams and Homeopathy, along with experience with Acupuncture remained significant on the holdout sample. 

<<acu2lasso, echo=FALSE, results=tex, cache=TRUE>>=
acu.test <- with(na.omit(tcq2a), Acutot)
acu2.lasso <- penalisedRegression(tcq2.acu.pred.train, tcq2.acu.resp.train, testdata=tcq2.acu.pred.test, newy=tcq2.acu.resp.test, alpha=1, type="coefficients")
@

<<acu2lassoprint, echo=FALSE, results=tex>>=
colnames(acu2.lasso) <- "Coefficients"
print(xtable(as.matrix(acu2.lasso), label="tab:tcq2aaculasso", caption="Coefficient Estimates for Lasso Regression using Acutotal as a dependent variable"))
@ 



Table \ref{tab:tcq2aaculasso} shows the estimated coefficients for the lasso fit on Acupuncture credibility totals. It shows that the major contributors were Homeopathy and Reiki credibility totals. Experience with Acupuncture appeared to exert a strong positive effect, while experience with injections had a large negative coefficient. 

<<acu2aridge, echo=FALSE, results=tex>>=
acu2.ridge <- penalisedRegression(tcq2.acu.pred.train, tcq2.acu.resp.train, tcq2.acu.pred.test, alpha=0, newy=tcq2.acu.resp.test, type="coefficients")
colnames(acu2.ridge) <- "Coefficients"
print(xtable(as.matrix(acu2.ridge), label="tab:tcq2aacuridge", caption="Coefficient Estimates on Held Out Data for Acutotal, Ridge Regression, Split A"))
@ 

Table \ref{tab:tcq2aacuridge} shows the estimated coefficients for the holdout sample. It can be seen that the major loadings are quite similar to those from the lasso fit, and no coefficients have changed sign. 

Next, the same procedure was applied to the Homeopathy credibility totals. 

<<splitdata, echo=FALSE, results=hide>>=
tcq2.full <- tcq2[complete.cases(tcq2),]
tcq2.hom.ind <- with(tcq2.full, createDataPartition(Homtot, times=1, p=0.7, list=FALSE))
tcq2.hom.train <- tcq2.full[tcq2.hom.ind,]
tcq2.hom.pred.train <- tcq2.hom.train[,c("Pilltot", "Creamtot", "Injtot", "Acutot","Reitot",  "ExpPill", "ExpCream", "ExpAcu", "ExpInj", "ExpRei", "ExpHom")]
## tcq2.hom.pred.train.mm <- model.matrix(tcq2.hom.pred.train)
tcq2.hom.test <- tcq2.full[-tcq2.hom.ind,]
tcq2.hom.pred.test <- tcq2.hom.test[,c("Pilltot", "Creamtot", "Injtot", "Reitot","Acutot", "ExpPill", "ExpCream", "ExpAcu", "ExpInj", "ExpRei", "ExpHom")]
tcq2.hom.resp.train <- with(tcq2.hom.train, Homtot)
tcq2.hom.resp.test <- with(tcq2.hom.test, Homtot)
@ 

<<stepwiselm, echo=FALSE, results=hide, cache=TRUE>>=
homtotlm1 <- lm(Homtot~Pilltot+Creamtot+Injtot+Acutot+Reitot+ ExpPill+ExpCream+ExpInj+ExpAcu+ExpHom+ExpRei, data=tcq2.hom.train)
homtot.step <- stepAIC(object=homtotlm1, upper=homtotlm1,lower=~1, direction="both", k=3)
@


<<lmonheldoutdata, echo=FALSE, results=tex>>=
homtotlm.holdout <- lm(Homtot~Acutot+Reitot+ExpAcu+ExpHom, data=tcq2.hom.test)
print(xtable(summary(homtotlm.holdout), label="tab:tcq2homholdout", caption="Coefficients for Hom credibility Regression on Held Out Data"))
@ 

Table \ref{tab:tcq2homholdout} shows the estimated coefficients from the stepwise selected model on unseen data. It can be seen that Acupuncture and Homeopathy credibility remain significant, as does the experience with homeopathy variable. 

<<hom2lasso, echo=FALSE, results=tex, cache=TRUE>>=
hom.test <- with(na.omit(tcq2a), Homtot)
hom2.lasso <- penalisedRegression(tcq2.hom.pred.train, tcq2.hom.resp.train, testdata=tcq2.hom.pred.test, newy=tcq2.hom.resp.test, alpha=1, type="coefficients")
@

<<hom2lassoprint, echo=FALSE, results=tex>>=
colnames(hom2.lasso) <- "Coefficients"
print(xtable(as.matrix(hom2.lasso), label="tab:tcq2ahomlasso", caption="Coefficient Estimates for Lasso Regression using Homtotal as a dependent variable"))
@ 


Table \ref{tab:tcq2ahomlasso} shows the estimated fit using the lasso method. It can be seen that Acupuncture and Homeopathy were the major contributors, while experience wih Homeopathy also contributed to the model. 

<<hom2aridge, echo=FALSE, results=tex>>=
hom2.ridge <- penalisedRegression(tcq2.hom.pred.train, tcq2.hom.resp.train, tcq2.hom.pred.test, alpha=0, newy=tcq2.hom.resp.test, type="coefficients")
colnames(hom2.ridge) <- "Coefficients"
print(xtable(as.matrix(hom2.ridge), label="tab:tcq2ahomridge", caption="Coefficient Estimates on Held Out Data for Homtotal, Ridge Regression, Split A"))
@ 

Table \ref{tab:tcq2ahomridge} shows a similar pattern to the lasso fit described earlier. 

Next, the selection and testing procedure was applied to the Reiki totals. 


<<splitdata, echo=FALSE, results=hide>>=
tcq2.full <- tcq2[complete.cases(tcq2),]
tcq2.rei.ind <- with(tcq2.full, createDataPartition(Reitot, times=1, p=0.7, list=FALSE))
tcq2.rei.train <- tcq2.full[tcq2.rei.ind,]
tcq2.rei.pred.train <- tcq2.rei.train[,c("Pilltot", "Creamtot", "Injtot", "Acutot","Homtot",  "ExpPill", "ExpCream", "ExpAcu", "ExpInj", "ExpRei", "ExpHom")]
## tcq2.rei.pred.train.mm <- model.matrix(tcq2.rei.pred.train)
tcq2.rei.test <- tcq2.full[-tcq2.rei.ind,]
tcq2.rei.pred.test <- tcq2.rei.test[,c("Pilltot", "Creamtot", "Injtot", "Homtot","Acutot", "ExpPill", "ExpCream", "ExpAcu", "ExpInj", "ExpRei", "ExpHom")]
tcq2.rei.resp.train <- with(tcq2.rei.train, Reitot)
tcq2.rei.resp.test <- with(tcq2.rei.test, Reitot)
@ 

<<stepwiselm, echo=FALSE, results=hide, cache=TRUE>>=
reitotlm1 <- lm(Reitot~Pilltot+Creamtot+Injtot+Acutot+Homtot+ ExpPill+ExpCream+ExpInj+ExpAcu+ExpRei+ExpRei, data=tcq2.rei.train)
reitot.step <- stepAIC(object=reitotlm1, upper=reitotlm1,lower=~1, direction="both", k=3)
@


<<lmonheldoutdata, echo=FALSE, results=tex>>=
reitotlm.holdout <- lm(Reitot~Pilltot+Acutot+Homtot, data=tcq2.rei.test)
print(xtable(summary(reitotlm.holdout), label="tab:tcq2reiholdout", caption="Coefficients for Rei credibility Regression on Held Out Data"))
@ 

Table \ref{tab:tcq2reiholdout} shows the performance of the stepwise selected coefficients on unseen data. It can be seen that the only coefficient which maintained signifiance was that for Homeopathy credibility. 


<<rei2lasso, echo=FALSE, results=tex, cache=TRUE>>=
rei.test <- with(na.omit(tcq2a), Reitot)
rei2.lasso <- penalisedRegression(tcq2.rei.pred.train, tcq2.rei.resp.train, testdata=tcq2.rei.pred.test, newy=tcq2.rei.resp.test, alpha=1, type="coefficients")
@

<<rei2lassoprint, echo=FALSE, results=tex>>=
colnames(rei2.lasso) <- "Coefficients"
print(xtable(as.matrix(rei2.lasso), label="tab:tcq2areilasso", caption="Coefficient Estimates for Lasso Regression using Reitotal as a dependent variable"))
@ 

Table \ref{tab:tcq2areilasso} shows that Homeopahty, Acupuncture and Experience with Reiki all contribute to the model, whjile there are tiny negative loadings on the conventional treatments. 

<<rei2aridge, echo=FALSE, results=tex>>=
rei2.ridge <- penalisedRegression(tcq2.rei.pred.train, tcq2.rei.resp.train, tcq2.rei.pred.test, alpha=0, newy=tcq2.rei.resp.test, type="coefficients")
colnames(rei2.ridge) <- "Coefficients"
print(xtable(as.matrix(rei2.ridge), label="tab:tcq2areiridge", caption="Coefficient Estimates on Held Out Datafor Reitotal, Ridge Regression, Split A"))
@ 

Table \ref{tab:tcq2areiridge} shows that the estimated coefficients for the ridge regression are very similar to those for the lasso regression.

Interestingly, it appears that the experience with a particular form of treatment was only usefully predictive for the alternative treatments. Further comments on this are made in the Discussion. 






\subsection{Discussion}
\label{sec:discussion}
This chatper has demonstrated a number of matters with regards to this new instrument. Firstly, it appears to have the predicted factor structure, especially the reduced structure, with the cross-loading items removed.  Secondly, this factor structure has been replicated over two samples. Thirdly, all the major hypotheses (from Study 2) have been confirmed. The measure appears to be stable, possesses good reliability, and seems to correlate in the expected ways with the Beliefs About Medicine Questionnaire. Interestingly enough, the hypothesis that experience with a particular treatment would correlate with experience of a particular treatment was only borne out for the alternative treatments. This data cannot be used to establish causality in this case, as both an experience to credibility and a credibility to experience causal chain are equally plausible. 

That being said, there are some important limitations to the study. Firstly, there was no behavioural or observational outcome to benchmark the test against. Secondly, although we sampled twice from the student population and once from the staff population, this test still relies entirely on the responses of staff and students at one particular university. Further replication of the factor structure in heterogenous groups is warranted before extensive use of the instrument takes place. 


The major aim of this work was to develop and test an instrument which would capture more of the key factors surrounding treatment related expectancies. This aim has been achieved, in that the measure appears to be stable, and to correlate in the expected fashion with similar instruments. It does appear, from this work, that the conception of conventional treatments and alternative treatments appears to differ, and do not appear to form one general treatment credibility factor, but rather to have two distinct factors. This finding was used to inform the development of the IAT (see Chapter \ref{cha:devel-impl-meas}). 

<<saveimage, echo=FALSE, results=hide>>=
pill.all <- c(with(tcq1, PillTot), with(tcq2, Pilltot))
cream.all <- c(with(tcq1, CreamTot), with(tcq2, Creamtot))
inj.all <- c(with(tcq1, InjTot), with(tcq2, Injtot))
acu.all <- c(with(tcq1, AcuTot), with(tcq2, Acutot))
hom.all <- with(tcq2, Homtot)
rei.all <- with(tcq2, Reitot)
all.cred <- list(pill.all, cream.all, inj.all, acu.all, hom.all, rei.all)
all.cred <- lapply(all.cred, as.data.frame)
names(all.cred) <- c("PillCredibility", "CreamCredibility", "InjectionCredibility", "AcupunctureCredibility", "HomeopathyCredibility", "ReikiCredibility")
credtotals <- tcq2[,c("Pilltot", "Creamtot", "Injtot", "Acutot", "Homtot", "Reitot")]
save.image("tcqthesislatest.rda")
@   

%%% Local Variables:
%%% TeX-master: "PlaceboMeasurementByMultipleMethods"
%%% End:
