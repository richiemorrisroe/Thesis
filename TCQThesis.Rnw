
\section{Introduction}

Expectancies are considered to be at the core of the placebo response \cite{Montgomery1997}. However, currently they are assessed using very simple methods which fail to capture the multidimensional nature and changes over time in these important constructs \cite{Stone2005}. While these methods work, they typically explain only 10\% of the variance in response to placebo, which is clearly not optimal \cite{Whalley2008}.  

This chaper describes an adaptation of the Credibility/Expectancy Questionnaire \cite{devilly2000psychometric}  to measure pain expectancies in a student sample, and reports on its psychometric validation over two studies. 

While expectancies are considered the prime factor in response to placebo, there is some evidence that they are not the best predictors in all situations, and that there may be components of expectancies which are not tapped by current measures \cite{Hyland2007,Geers2005,Geers2005a}. The CEQ is useful in that it taps both cognitive and affective components of the expectancy construct, and this should lead to better predictions. This chapter describes the development of the CEQ for assessing treatment expectancies. 

It is important to note that current or former use of the treatments measured was not a requirement for the completion of the measure, but this should not be regarded as a flaw given that many if not most participants in placebo research do not have any experience of the treatments used (and indeed, such knowledge is often an exclusion criteria for the research) \cite{Kirsch1985,Kirsch1997}. The CEQ has been used in a family therpay setting for children with conduct disorder \cite{Nock2007}, in the assessment of relational therapy for Vietnam war veterans and their spouses \cite{Devilly2002} and in the treatment of PTSD \cite{Devilly2008}. It has not been used in any non-clinical samples, and this is its first adaptation for the study of both pain and treatment response expectancies. 

\section{Methodology}
\label{sec:methodology}


\subsection{Measures}


The Treatment Credibility Questionnaire was a measure developed for this research, to compensate for the lack of detail in placebo response expectancy measurement. The questionnaire was based on the Credibility/Expectancy Questionnaire developed by Devilly and Borkovec which consisted of six questions, three which tapped credibility and three which tapped expectancies \cite{Devilly2000}. The scale was developed to assess expectancies around treatment and each question was scored on a 10 point scale (0-9). A number of changes were made to this instrument for use in this research. Firstly, the scale was changed to a 1-5 scale, to simplify the scoring. Secondly, the six questions in each condition were prefaced by a statement that read: You have been suffering pain for a number of days. You go to the doctor, and he/she suggests you try X (where X is one of the treatments listed above).

The questions were as follows:


\begin{enumerate}
	\item How logical does the therapy offered to you seem?
	\item How successful do you think this treatment will be in reducing your symptoms?
 	\item How confident would you be in recommending this treatment to a friend?
	\item How much improvement in your symptoms do you think will occur?
	\item How much do you really \textit{feel} that therapy will help you to reduce your symptoms?
	\item How much improvement in your symptoms do you really \textit{feel} will occur?
\end{enumerate}

\paragraph{Beliefs About Medicine Questionnaire}

In addition to this, the Beliefs about Medicine Questionnaire (BAM) was administered to all participants. This is an instrument developed to assess the beliefs of chronic pain patients regarding their medicines~\cite{Horne1999}. This instrument was included in order to validate the TCQ by means of correlations with this similar measure. The BAM is an eight item measure which purports to have two factors. The eight items were those retained from a pool of 16 items which derived from interviews with chronic pain patients. All 16 items were administered to all participants, of which 8 are the items selected for the final questionnaire by the original authors, and the other 8 are items which were dropped due to poor loadings.

\subsection{Sampling}

The sampling for the Treatment Credibility Questionnaire was conducted in two rounds, as the instrument needed to be validated in one sample, and then confirmed and revised in another. The first sample was sent to a random subset of students at the University in February 2010, to which 299 students responded. This data was analysed over the next two months, and following this, a revised version of the questionnaire was sent to both staff and students at the University.The Beliefs About Medicine Questionnaire was also administered, to assess the construct validity of the TCQ.

\subsection{Analysis}

Sample one was treated as an overall training set (most appropriate given tha the measure was changed as a result of these methods), and the results tested on a subset of Sample 2. 

%% All data analysis was preceded by fitting a multiple imputation model where necessary, and was split into 4 parts as described above under the section Analysis for Health, Optimism and Mindfulness.

Data for Sample Two was split into four parts of approximately 300 non missing observations each, in line with the procedure described in Chapter~\ref{cha:methodology}. 

Firstly, the data was checked for errors in entry or recording using summary functions and plots. Following this, the question responses were recoded according to the instructions for use. Following this, the summary scores were calculated. Next, summary statistics and characteristics of the data were reported. %% Next, the data was tested for normality using a Shapiro-Wilks test. 
Following this, a correlation matrix for the data was calculated and analysed.

Simple reliability analyses were carried out on the scales themselves. Following this, parallel analysis, the MAP criterion and the scree plot were used to estimate the number of factors which could be extracted from the data. 

After this, factor solutions were extracted using principal axis methods primarily, and maximum likelihood methods where these did not converge.

Primarily, direct oblimin methods of rotations were utilised, but promax rotations were also applied to ensure that the proposed structure was not overly sensitive to the methods of rotation used.

After the various factor structures were obtained, they were plotted and analysed for interpretability. Communalities and uniquenesses were assessed to ensure that there was no over or under factoring in the solutions. %% Communalities were then graphed against the number of factors extracted and the methods of extraction to provide a simple graphical guide to the usefulness of each solution.

Following this procedure of extraction and interpretation, Structural Equation Modelling was applied to each of the proposed factor solutions using the OpenMx package for R. The optimal factor solution was chosen using the AIC of each fitted model, along with the RMSEA of the proposed solutions.


Following the investigation of structure with the methods of classical test theory, the scales were analysed using Rasch models and item response theory. Firstly, mokken analyses were run, in order to check the assumptions of monotonicity, local independence and to assess how many sub-scales the analysis should be carried out on. 

Following this, three successively more complicated IRT models were fitted to each sub-scale (Rasch, one parameter and two parameter). Both Partial Credit Models and Graded Response Models were used. 


Linear regressions were run to examine the differential effects of each of the correlated variables. Stepwise selection on the training set was carried out, along with lasso, ridge and least angle regression methods. The performance of each of these methods was then assessed on held-out data (from Sample One, using ten fold cross-validation as previously described). 

In the case of Sample One, some of Sample Two was used as a heldout data set. For Sample two, the entire dataset was split into four splits, and the cross validation procedure carried out for each. The splits were kept quite large (approximately 300 non missing observations) to allow for psychometric models to be fit to each split seperately, and to be able to compare the performance of simple mean/sum scores against the factor scores and ability estimates derived from the psychometric modelling procedures.



The Beliefs About Medicine Questionnaire was a special case in this analysis. As only eight items are included in the canonical version of the scale, the other eight were given to test the hypothesis that different items might load better in a general population sample, rather than a clinical sample. Given the small sample sizes in the original research, and the inappropriate use of principal components analysis, this was also used as an opportunity to examine the structure using better methods. Therefore, the eight items of the published scale were analysed first, and then all analyses reported in this section were carried out on the larger sixteen item set. Results of these analyses are in the appropriate section, and the implications are discussed both in the discussion in that section and in the General Discussion.



\part{Sample One}

\section{Demographic Statistics}

The mean age of the participants in this sample was  22.61, the median Age was 21 and the range of reported ages was 10-56, which suggests some data entry errors on the part of the participants. The sample was 68.8\% female, and 83.4\% consisted of undergraduate students. 



<<packagesanddata, echo=FALSE, results=hide>>=
require(cacheSweave)
require(ggplot2)
require(reshape2)
require(lmtest)
require(psych)
require(xtable)
require(mokken)
require(eRm)
require(ltm)
require(xtable)
require(OpenMx)
require(MASS)
require(reshape2)
require(glmnet)
source("func.R")
require(gridExtra)
require(stargazer)
tcq1<-read.csv("CSV TCQ030410updatedJan11.csv")
@ 







The next step was to look at the scores on the response variables regarding the different forms of treatment. 

In Table \ref{tab:tcq1sumtotals} the summary statistics for the credibility scores for each of the four modalites are shown. 

<<totalscreate, echo=FALSE, results=hide, cache=TRUE>>=
totals <- tcq1[,c("PillTot", "CreamTot", "InjTot", "AcuTot")]
@


<<totalsummary, echo=FALSE, results=tex>>=
sum.totals<-summary(totals)
mat.totals<-as.matrix(sum.totals)
xtab.totals<-xtable(mat.totals, caption="Summary Statistics, Total Credibility Scores", label="tab:tcq1sumtotals")
print(xtab.totals)
@ 



%% As can be seen,  none of these distributions are normally distributed, a point which is reinforced by Figure \ref{fig:tcqscatterplotmat} below, which shows both the correlations between the scale totals and their distribution. 


Next, the differences in credibility totals between Genders will be examined. 
<<gendercred, echo=FALSE, results=hide, cache=TRUE>>=
gendpill <- ggplot(na.omit(tcq1), aes(y=PillTot, x=Gender))+geom_boxplot()
gendcream <- ggplot(na.omit(tcq1), aes(y=CreamTot, x=Gender))+geom_boxplot()
gendinj <- ggplot(na.omit(tcq1), aes(y=InjTot, x=Gender))+geom_boxplot()
gendacu <- ggplot(na.omit(tcq1), aes(y=AcuTot, x=Gender))+geom_boxplot()
@ 

\begin{figure}
<<gendpill, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
print(arrangeGrob(gendpill, gendcream, gendinj, gendacu))
@   
  \caption{Gender Differences in Credibility  Scores, TCQ1}
  \label{fig:gendcredpill}
\end{figure}



As can be seen from this Figure \ref{fig:gendcredpill}, there appear to be no significant differences in median Pill scores that can be attributed to the Gender of the respondents. It can be seen, however, that the variability is larger within the male responses. 

Again, we see a similar pattern to the scores for Creams, in that there appears to be no mean differences in the credibility totals. We can see a larger variability with the responses from men.  

From  the figure, we can observe that again, no significant differences are visible between the credibility totals.  We can observe that men tend to report much higher variability in their assessment of injections.

However, the acupuncture credibility scores show a different pattern. We can see from a simple inspection of the graph that the mean credibility totals are very different for females and males. We performed a Kruskall Wallis test to examine whether this visual difference can be backed up with a rigorous analysis. The results tended towards significance (p=0.09).


As can be seen from this, the difference, although visible is not significant, although it probably would be if the sample were larger. Again, the pattern of larger variability in the responses of men is apparent.   


<<collegeplots, echo=FALSE, results=hide, cache=TRUE>>=
collpill <- ggplot(na.omit(tcq1), aes(y=PillTot, x=College))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collcream <- ggplot(na.omit(tcq1), aes(y=CreamTot, x=College))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collinj <- ggplot(na.omit(tcq1), aes(y=InjTot, x=College))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collacu <- ggplot(na.omit(tcq1), aes(y=AcuTot, x=College))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
@ 

\begin{figure}
<<collpill, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
print(arrangeGrob(collpill, collcream, collinj, collacu))+theme(axis.text.x=element_text(angle=45, hjust=1))
@   
  \caption{Treatment Credibility Scores by College of Study}
  \label{fig:collpill}
\end{figure}


From Figure \ref{fig:collpill} it can be seen that the were differences in the crediblity scores of various treatments across the colleges of study. These differences were only significant for the Cream ($p=0.0158$) and Injection ($p=0.0168$) credibility scores. 

\section{Pyschometric Analyses}
\label{sec:pysch-analys}



\subsection{Reliability Analysis}

%Reliability is an extremely important part of any measurement instrument, given that if we cannot rely on the instrument giving us similar answers on different equations, it is of no use in our studies.
The reliability of this scale was assessed. The method used was Cronbachs $\alpha$ , which is the mean of all possible split half reliabilities, and is the most commonly used measure of reliability in psychological research. %% Of course, the extent to which people give the same responses at different time points also needs to be assessed, but that will be examined after the factor structure and other methodological issues have been assessed. 

This analysis was performed on the sample, and the mean alpha was equal to .9, which is well above the threshold used for survey research (.7) and would, on the basis of this sample, qualify as a clinical instrument, for which the threshold is 0.9. This reliability analysis (shown in Tables \ref{tab:reltcq1short} and \ref{tab:tcq1rellong})  did not suggest that any of the items should be removed from the scale. 

<<scalemake, echo=FALSE, results=hide, cache=TRUE>>=
Pill.g <- grep("Pill[1-6]", x=names(tcq1))
Cream.g <- grep("Cream[1-6]", x=names(tcq1))
Inj.g <- grep("Inj[1-6]", x=names(tcq1))
Acu.g <- grep("Acu[1-6]", x=names(tcq1))
Pillall <- tcq1[,Pill.g]
Creamall <- tcq1[,Cream.g]
Injall <- tcq1[,Inj.g]
Acuall <- tcq1[,Acu.g]
tcqall <- as.data.frame(cbind(Pillall, Creamall, Injall, Acuall))
rel.tcq <- psych:::alpha(na.omit(tcqall))
@ 




<<reltcq2, echo=FALSE, results=hide>>=
print(xtable(rel.tcq[["item.stats"]], caption="Item reliability Statistics for the TCQ 1", label="tab:tcq1rellong"))
@ 





\section{Factor Analysis}

%% Factor Analysis is a method for examining inter-correlations between sets of variables in order to reduce the number of items required to model the instrument. It is commonly used in psychological research either to confirm a predicted structure (Confirmatory Factor Analysis) or to explore the factor structure of a new instrument (Exploratory Factor Analysis).


The first analysis carried out on the data was an assessment of the number of factors suggested by both the parallel analysis and MAP criterion. The results of the parallel analysis and scree plot suggested four factors. The MAP criterion suggested that six factors should be extracted. Both of these factor solutions will be created and examined based on fit indices and interpretability below. 



<<tcqfact4, echo=FALSE, results=tex>>=
tcq.fact.4<-fa(na.omit(tcqall), 4, rotate='oblimin', fm="pa")
print(FactorXtab(tcq.fact.4,names=c("Acupuncture", "Cream", "Inj", "Pills"), label="tab:tcq1fact4", caption="Four Factor Solution, TCQ 1 Oblimin rotation"))
@ 

<<factorloadings4, echo=FALSE, results=verbatim, eval=FALSE>>=
print(ExtractLoadings(tcq.fact.4))
@ 


<<factorcor4, echo=FALSE, results=hide>>=
print(FactorCor(tcq.fact.4, label="tab:tcq1fact4cor", caption="Four Factor TCQ correlations"))
@ 




As can be seen from Table \ref{tab:tcq1fact4}  this factor structure is extremely interpretable, with each group of six questions loading highly on its own factor. This fits with the expectations prior to the research. 

%% Below, in Table \ref{tab:tcq1fact4cor} are shown the inter-correlations between these factors.
The Acupuncture factor does not correlate highly with the other three factors, but they do correlate reasonably well with one another. This  makes clear that the distinction between the western and alternative treatment modalities was apparent to the participants. 



This four factor solution explains 74\% of the variance, which is extremely high for a psychological self report scale \footnote{though typically the proportion of variance explained is higher when a scale is developed, and falls on new samples}. 



Next, the six factor solution was examined for interpretability, and the results are shown in Table \ref{tab:tcq1fact6}


<<tcqfact6, echo=FALSE, results=tex>>=
tcq.fact.6<-fa(na.omit(tcqall), 6, rotate='promax', fm="pa")
print(FactorXtab(tcq.fact.6,  names=c("Acu", "Cream", "Inj", "Pill", "Cred", "Exp"), label="tab:tcq1fact6", caption="Six Factor Solution, TCQ 1, Oblimin Rotation"))
@ 


<<tcq6cor, echo=FALSE, results=hide>>=
print(FactorCor(tcq.fact.6, label="tab:tcq1fact6cor",caption="TCQ Six Factor Solution Correlations"))
@ 



As can be seen in Table \ref{tab:tcq1fact6} the four factors from the original solution still have the highest loadings, but there are a number of lower loadings on the fifth and sixth factors.

<<fitindices,echo=FALSE, results=tex, eval=FALSE>>=
fit4 <- FitIndices(tcq.fact.4)
fit5 <- FitIndices(tcq.fact.5)
fit6 <- FitIndices(tcq.fact.6)
fit.tcq1 <- as.data.frame(cbind(fit4, fit5, fit6))
fittcq1.m <- melt(fit.tcq1)
names(fittcq1.m)[1] <- "Fit Index"
print(xtable(fittcq1.m, caption="Fit Indices, TCQ 1", label="tab:tcq1modelcomp"), scalebox=0.75)
@ 

\section{Confirmatory Factor Analyses}
\label{sec:conf-fact-analys}

<<tcq4sem, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
Tcq4model <- mxModel(name="TCQ4", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Pills", to=pills), 
                      mxPath(from="Creams", to=creams),
                      mxPath(from="Injections", to=inj),
                      mxPath(from="Acupuncture", to=Acu),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                      mxData(observed=cov(na.omit(tcqall)), type="cov", numObs=264)
                      )
tcq4fit <- mxRun(Tcq4model)
tcq4summ <- summary(tcq4fit)
@ 




<<tcq6sem, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Fifth", "Sixth")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
fifth <- c("Pill1", "Pill3","Cream1", "Cream3","Inj1", "Inj3")
sixth <- c("Pill2", "Pill4","Inj2", "Inj4")
Tcq6model <- mxModel(name="TCQ6", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Pills", to=pills), 
                      mxPath(from="Creams", to=creams),
                      mxPath(from="Injections", to=inj),
                      mxPath(from="Acupuncture", to=Acu),
                     mxPath(from="Fifth", to=fifth),
                     mxPath(from="Sixth", to=sixth), 
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                      mxData(observed=cov(na.omit(tcqall)), type="cov", numObs=264))
tcq6fit <- mxRun(Tcq6model)
tcq6summ <- summary(tcq6fit)
@ 



<<tcq1semcompare, echo=FALSE, results=tex>>=
print(xtable(mxCompare(base=tcq4fit, comp=c(tcq6fit)), label="tab:tc1modelcomp", caption="CFA on TCQ Models, Sample One"))
@ 



As can be seen in Table \ref{tab:tcq1modelcomp}, the six factor model appears to fit the data much better, which is unexpected. Possible explanations are discussed below. 




\section{Item Response Theory Analyses}


<<tcqcheckassumptions, echo=FALSE, results=hide, cache=TRUE>>=
tcq.scales <- aisp(na.omit(tcqall))
print(xtable(tcq.scales, label="tab:tcq1aisp", caption="Item Selection Procedure Results for TCQ1"))
@ 

An IRT based item-selection procedure showed that  the overall scale appears to divide into two scales, one for the conventional items and another for the acupuncture items. Therefore, these two sets of items will be analysed seperately. Pill2 was the only item which did not meet the assumptions of the model in that it violated the item ordering assumption (assumption of monotonicity). Therefore, this item was removed from the scale before further analyses. 



<<tcqitemord, echo=FALSE, results=hide, cache=TRUE>>=
tcqconv.item.ord <- check.iio(na.omit(convtcq))
tcqalt.item.ord <- check.iio(na.omit(tcqalt))
tcqconv.monotonicity <- check.monotonicity(na.omit(convtcq))
tcqalt.monotonicity <- check.monotonicity(na.omit(tcqalt))
@ 



The alternative TCQ (i.e. the Acupuncture items showed now violations of the item ordering or monotonicity assumptions, and so no items were removed. 







<<tcqconvpcm, echo=FALSE, results=hide, cache=TRUE>>=
tcqconv.pcm.rasch<-gpcm(convtcq, constraint="rasch")
tcqcoef <- coef(tcqconv.pcm.rasch)
## tcqconv.pcm.fscores.rasch <- factor.scores(tcqconv.pcm.rasch)
## tcqconv.pcm.absest.rasch <- getIRTestimates(tcqconv.pcm.fscores.rasch)
@ 







The generalised partial credit model has been shown to be entirely inappropriate for the analysis of the conventional scale items in this sample. The next step was to fit the graded response model, and examine if this model can be fit accurately to the dataset at hand. 

<<tcqconvgrmconstrained, echo=FALSE, results=hide, cache=TRUE>>=
tcqconv.grm.1pl <- grm(convtcq, constrained=TRUE)
tcqconv.grm1.coef <- coef(tcqconv.grm.1pl)

## tcqconv.grm.fscores.1pl <- factor.scores(tcqconv.grm.1pl)
## tcqconv.grm.absest <- getIRTestimates(tcqconv.grm.fscores.1pl)
@ 

<<tcqconvgrm1plprint, echo=FALSE, results=tex>>=
print(xtable(tcqconv.grm1.coef, label="tab:tcq1convgrm1pl", caption="Coefficients for the TCQ 1 Conventional Scale, One Parameter Graded Response Model"))
@ 
It can be seen from Table \ref{tab:tcq1convgrm1pl} that the fit is much better for this model, with no violations of monotonicity. The next step taken is to examine the fit of a more flexible model (with a discrimination parameter for each item), and assess whether or not this represents a significant enough improvement over the model above.

<<tcqconvgrm2, echo=FALSE, results=tex, cache=TRUE>>=
tcqconv.grm.2pl <- grm(convtcq, constrained=FALSE)
tcqconv.grm2.coef <- coef(tcqconv.grm.2pl)

## tcqconv.grm.fscores.2pl <- factor.scores(tcqconv.grm.2pl)
## tcqconv.grm.absest <- getIRTestimates(tcqconv.grm.fscores.2pl)
@ 
<<tcqconvgrm2plprint, echo=FALSE, results=hide>>=
print(xtable(tcqconv.grm2.coef, label="tab:tcq1convgrm2pl", caption="Coefficients for TCQ 1 Conventional One Parameter Graded Response Model"))
@ 
<<tcqgrmcomp, echo=FALSE, results=hide, cache=TRUE>>=
grm.comp <- anova(tcqconv.grm.1pl, tcqconv.grm.2pl)
@ 
The result of this model comparison exercise showed that the 1 parameter model was a significantly better fit than the 2 parameter model ($p\le 0.001$). Next, the fit of the alternative TCQ (i.e. the acupuncture items) was examined under both the partial credit model and the graded response model.  

<<tcqaltpcm, echo=FALSE, results=tex, cache=TRUE>>=
tcqalt.pcm.rasch <- gpcm(tcqalt, constraint="rasch")
tcqaltcoef <- coef(tcqalt.pcm.rasch)

## tcqalt.pcm.fscores.rasch <- factor.scores(tcqalt.pcm.rasch)
## tcqalt.pcm.absest <- getIRTestimates(tcqalt.pcm.fscores.rasch)
@ 


<<tcqaltgpcmraschprint, echo=FALSE, results=tex>>=
print(xtable(tcqaltcoef, label="tab:tcq1altgpcmrasch", caption="Coefficients for TCQ 1 Alternative Scale, Rasch Generalised Partial Credit Model"))
@ 
Unlike the partial credit model formed from the conventional items, the scale composed of the acupuncture items shows no clear violations of monotonicity (Table \ref{tab:tcq1altgpcmrasch}), even when a simple Rasch model is fitted. Next, more complex versions of the partial credit model are fitted to examine if they add useful predictive power to the model. 

<<tcqaltpcm1pl, echo=FALSE, results=tex, cache=TRUE>>=
tcqalt.pcm.1pl <- gpcm(tcqalt, constraint="1PL")
tcqaltcoef.1pl <- coef(tcqalt.pcm.1pl)

## tcqalt.pcm.fscores <- factor.scores(tcqalt.pcm.1pl)
## tcqalt.pcm.absest <- getIRTestimates(tcqalt.pcm.fscores)
@ 
<<tcqaltgpcm1plprint, echo=FALSE, results=tex>>=
print(xtable(tcqaltcoef.1pl, label="tab:tcq1altgpcm1pl", caption="Coefficients for TCQ1 Alternative, One Parameter Generalised Partial Credit Model"))
@ 
The examination of the more complex model with a discrimination parameter estimated from the data (Table \ref{tab:tcq1altgpcm1pl}) shows that the acupuncture items can perhaps be modelled best with a much higher discrimination rather than higher ability estimates. An ANOVA confirms that the 1 parameter model is a significantly better fit than the Rasch model fitted before ($p\le 0.001$). 

Next, a two parameter model was fitted to this data. 

<<tcqaltpcm2pl, echo=FALSE, results=tex, cache=TRUE>>=
tcqalt.pcm.2pl <- gpcm(tcqalt, constraint="gpcm")
tcqaltcoef.2pl <- coef(tcqalt.pcm.2pl)

@ 
<<tcqaltgpcm2plprint, echo=FALSE, results=tex>>=
print(xtable(tcqaltcoef.2pl, label="tab:tcq1altgpcm2pl", caption="Coefficients for TCQ1 Alternative Scale, Two Parameter Graded Response Model"))
@ 


The two parameter model (shown in Table \ref{tab:tcq1altgpcm2pl}) has some interesting features compared to the one parameter model. Firstly, the discrimanation parameter of Items 1 and 3 have significantly decreased compared to the one parameter model. The discrimination parameter for Acu 2 has lowered slightly. The discrimination of the other three items has icnreased substantially. An anova between the two models shows that the model is a significant improvement on the one parameter model ($p\le 0.001$). 

Next, two graded response models were fit to the the alternative tcq question-set. 

<<tcqaltgrm1, echo=FALSE, results=tex, cache=TRUE>>=
tcqalt.grm.constrained <- grm(tcqalt, constrained=TRUE)
tcqalt.grm1.coef <- coef(tcqalt.grm.constrained)

## tcqalt.grm1.fscores <- factor.scores(tcqalt.grm.constrained)
## tcqalt.grm1.absest <- getIRTestimates(tcqalt.grm1.fscores)
@ 
<<tcaltgrm1plprint, echo=FALSE, results=tex>>=
print(xtable(tcqalt.grm1.coef, label="tab:tcq1altgrm1pl", caption="Coefficients for TCQ 1 Alternative Scale, One parameter Graded Response Model"))
@ 
The model described in Table \ref{tab:tcq1altgrm1pl} is quite different from the one parameter model estimated under the partial credit model. Firstly, the discrimination parameter is estimated at a much lower level (3.88 as opposed to 5.20). In addition, the parameter estimates are much more closely distributed around zero, and the category 4 parameter estimates are much less extreme. 

<<tcqaltgrm2, echo=FALSE, results=tex, cache=TRUE>>=
tcqalt.grm2 <- grm(tcqalt)
tcqalt.grm2.coef <- coef(tcqalt.grm2)

## tcqalt.grm2.fscores <- factor.scores(tcqalt.grm2)
## tcqalt.grm2.absest <- getIRTestimates(tcqalt.grm2.fscores)
@ 
<<tcqaltgrm2plprint, echo=FALSE, results=tex>>=
print(xtable(tcqalt.grm2.coef, label="tab:tcq1altgrm2pl", caption="Coefficient Estimates for TCQ 1 Alternative Scale, Two Parameter Graded Response Model"))
@ 
Again, the model shown in Table \ref{tab:tcq1altgrm2pl} has a much lower estimate of the discrimination of the individual items, counterbalanced by higher ability estimates for all of the item difficulty parameters. 


\section{Regression Analyses}
\label{sec:regression-analyses}

In this section, the totals for each of the treatment modalities are examined to determine if any of the demographic variables can account for them. Firstly, a linear regression was run on the Pilltotal variable using the demographics as predictors.

<<pilltotreg1, echo=FALSE, results=tex>>=
pillLm1 <- lm((PillTot/5)~CreamTot+InjTot+AcuTot+Gender+College+UGPG+Year, data=tcq1)
print(xtable(summary(pillLm1), caption="Coefficient for Linear Regression on Pill Credibility Scores, TCQ1", label="tab:tcq1pilllmsum"))
@ 

As can be seen from Table \ref{tab:tcq1pilllmsum}, there were no only Cream and Injection credibility scores were predictors of Pill Credibility scores from amongst the variables collected in Study One. 

Next, we examine the relationship of cream credibility variables to others in the sample.

<<creamlm,echo=FALSE, results=tex>>=
creamlm <- lm(CreamTot~PillTot+InjTot+AcuTot+Gender+College+UGPG, data=tcq1)
print(xtable(summary(creamlm), caption="Cream Credibility Linear Regression Results",label="tab:creamlm"))
@ 

As can be seen from the model in Table \ref{tab:creamlm}, there appears to only be a relationship with cream credibility for the other credibility scores. Surprisingly, the relationship between Cream credibility and Acupuncture credibility is positive, a pattern which was also seen in the raw correlations and suggests that participants in study one were responding in the same fashion due to overall response characteristics rather than a considered examination of each treatment in isolation. 

Next, we examine the relationship between Injection Credibility scores and the other variables in the sample.

<<injlm, echo=FALSE, results=tex>>=
injlm <- lm(InjTot~PillTot+CreamTot+AcuTot+Gender+College+UGPG, data=tcq1)
print(xtable(summary(injlm), caption="Injection Credibility Totals Regression, Study One", label="tab:injlm1"))
@ 

As can be seen from Table \ref{tab:injlm1}, a similar pattern as was seen for the Cream credibility scores emerges, except that Acupuncture now has a negative coefficient (which is much smaller than those for Pill or Cream credibility). 

Finally, we examine the relationship between Acupuncture credibility and other variables in the sample. 

<<acutotlm, echo=FALSE, results=tex>>=
acutotlm <- lm(AcuTot~PillTot+CreamTot+InjTot+Gender+College+UGPG, data=tcq1)
print(xtable(summary(acutotlm), caption="Acupuncture Credibility Linear Regression, Study One", label="tab:acutotlm1"))
@ 

The pattern of results was a little different when acupuncture credibility total was used as the response variable. Cream Credibility was extremely significant, injection credibility was marginally significant, while Pill credibility was not significant. Note the negative coefficient on Injections, which suggests that these treatments were regarded as useful by different subsets of participants. 



\section{Confirmatory Analyses}
\label{sec:conf-analys}

<<tcq2importandsplit, echo=FALSE, results=hide, cache=TRUE>>=
tcq2 <- read.csv("tcq2.csv")
@ 




<<scalemake2, echo=FALSE, results=hide, cache=TRUE>>=
Pillall <- tcq2[,grep("Pill[1-6]", x=names(tcq2))]
Creamall <- tcq2[,grep("Cream[1-6]", x=names(tcq2))]
Injall <- tcq2[,grep("Inj[1-6]", x=names(tcq2))]
Acuall <- tcq2[,grep("Acu[1-6]", x=names(tcq2))]
Homall <- tcq2[,grep("Hom[1-6]", x=names(tcq2))]
Reiall <- tcq2[,grep("Rei[1-6]", x=names(tcq2))]
Bamall <- tcq2[,grep("BAM[1-18]", x=names(tcq2))]
tcq2[,"Pilltot"] <- apply(Pillall, 1, mean, na.rm=TRUE)
tcq2[,"Creamtot"] <- apply(Creamall, 1, mean, na.rm=TRUE)
tcq2[,"Injtot"] <- apply(Injall, 1, mean, na.rm=TRUE)
tcq2[,"Acutot"] <- apply(Acuall, 1, mean, na.rm=TRUE)
tcq2[,"Homtot"] <- apply(Homall, 1, mean, na.rm=TRUE)
tcq2[,"Reitot"] <- apply(Reiall, 1, mean, na.rm=TRUE)
tcq2[,"Bamtot"] <- apply(Bamall, 1, mean, na.rm=TRUE)
tcqtotals <- with(tcq2, as.data.frame(cbind(Pilltot, Creamtot, Injtot, Acutot, Homtot, Reitot, Bamtot)))
@ 

<<expconvaltcalc, echo=FALSE, results=hide, cache=TRUE>>=
tcq2[,"ConvMean"] <- with(tcq2, (Pilltot+Creamtot+Injtot)/3)
tcq2[,"AltMean"] <- with(tcq2, (Acutot+Homtot+Reitot)/3)
tcq2[,"Expconv"] <- with(tcq2, (ExpPill+ExpCream+ExpInj)/3)
tcq2[,"Expalt"] <- with(tcq2, (ExpAcu+ExpHom+ExpRei)/3)
@ 
<<subsamplestcq2, echo=FALSE, results=hide, cache=TRUE>>=
set.seed(52)
tcq2.ind <- sample(1:1329, 1329, replace=FALSE)
tcq2.ind.a <-tcq2.ind[1:310]
tcq2.ind.b <-tcq2.ind[311:620]
tcq2.ind.c <-tcq2.ind[621:930]
tcq2.ind.d <- tcq2.ind[931:length(tcq2.ind)]
tcq2a <- tcq2[tcq2.ind.a,]
tcq2b <- tcq2[tcq2.ind.b,]
tcq2c <- tcq2[tcq2.ind.c,]
tcq2d <- tcq2[tcq2.ind.d,]
Pill.g <- grep("Pill[1-6]", x=names(tcq2a))
Cream.g <- grep("Cream[1-6]", x=names(tcq2a))
Inj.g <- grep("Inj[1-6]", x=names(tcq2a))
Acu.g <- grep("Acu[1-6]", x=names(tcq2a))
Hom.g <- grep("Hom[1-6]", x=names(tcq2a))
Rei.g <- grep("Rei[1-6]", x=names(tcq2a))
Pillall.a <- tcq2a[,Pill.g]
Creamall.a <- tcq2a[,Cream.g]
Injall.a <- tcq2a[,Inj.g]
Acuall.a <- tcq2a[,Acu.g]
Homall.a <- tcq2a[,Hom.g]
Reiall.a <- tcq2a[,Rei.g]
Bamall.a <- tcq2a[,grep("BAM[1-18]", x=names(tcq2a))]
tcq2.1 <- as.data.frame(cbind(Pillall.a, Creamall.a, Injall.a, Acuall.a))
tcqfull.a <- as.data.frame(cbind(Pillall.a, Creamall.a, Injall.a,
 Acuall.a, Homall.a, Reiall.a))
@ 

As in previous analyses (see Chapter \ref{cha:health-for-thesis}), the second sample was much larger than the first, and therefore was split into a number of equal parts. In this case, the second sample (consisting of student and staff responses) was split into four equal sub-samples(A-D). The first of these (hereafter denoted as A), was then  used as a test sample for the models developed on the data from Sample 1. 

\section{Confirmatory Factor Analysis}
\label{sec:conf-fact-analys-1}

<<tcq4sem2a, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
Tcq4model2 <- mxModel(name="TCQ42", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Pills", to=pills), 
                      mxPath(from="Creams", to=creams),
                      mxPath(from="Injections", to=inj),
                      mxPath(from="Acupuncture", to=Acu),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                      mxData(observed=cov(na.omit(tcq2.1)), type="cov", numObs=310)
                      )
tcq4fit2 <- mxRun(Tcq4model2)
tcq4summ2 <- summary(tcq4fit2)
@ 


<<tcq5sem2, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Fifth")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
fifth <- c("Pill4", "Pill5", "Pill6", "Cream5", "Cream6", "Inj6")
Tcq5model2 <- mxModel(name="TCQ52", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Pills", to=pills), 
                      mxPath(from="Creams", to=creams),
                      mxPath(from="Injections", to=inj),
                      mxPath(from="Acupuncture", to=Acu),
                     mxPath(from="Fifth", to=fifth),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                      mxData(observed=cov(na.omit(tcqall)), type="cov", numObs=310))
tcq5fit2 <- mxRun(Tcq5model2)
tcq5summ2 <- summary(tcq5fit2)
@ 

<<tcq6sem2, echo=FALSE, results=hide>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Fifth", "Sixth")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
fifth <- c("Pill1", "Pill3","Cream1", "Cream3","Inj1", "Inj3")
sixth <- c("Pill2", "Pill4","Inj2", "Inj4")
Tcq6model2 <- mxModel(name="TCQ62", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Pills", to=pills), 
                      mxPath(from="Creams", to=creams),
                      mxPath(from="Injections", to=inj),
                      mxPath(from="Acupuncture", to=Acu),
                     mxPath(from="Fifth", to=fifth),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                      mxData(observed=cov(na.omit(tcq2.1)), type="cov", numObs=310))
tcq6fit2 <- mxRun(Tcq6model2)
tcq6summ2 <- summary(tcq6fit2)
@ 

<<tcq2testsemcomp, echo=FALSE, results=tex>>=
tcq2.1.comp <- mxCompare(tcq4fit2, comparison=c(tcq5fit2, tcq6fit2))
print(xtable(tcq2.1.comp, caption="Comparison of Four, Five and Six Factor Models for the TCQ1 on Sample Two", label="tab:tcq2testsemcomp"))
@ 

As can be seen from Table \ref{tab:tcq2testsemcomp} the six factor model appears to fit the data best, even on this unseen data-set. This is somewhat unexpected, especially given the compelling reasons to believe in a four factor model. Further explanations are given in the Discussion, below.




%add confirmatory IRT and regression analyses

\subsection{Confirmatory Regression Analyses}
\label{sec:conf-regr-analys}


Given that the models developed on the first data set are useful, then they should generalise to the new data. Examining this supposition is the purpose of this section.

Firstly, the Pill credibility model was replicated on a subset of the new data. 

<<pilllm2a, echo=FALSE, results=tex>>=
pilllm2a <- lm(Pilltot~Creamtot+Injtot+Acutot+Gender+College+UGPG, data=tcq2a)
print(xtable(summary(pilllm2a), caption="Replication of Pill Credibility Model from Study One on a subsample from Study 2", label="tab:pilllm2a"))
@ 

As can be seen from Table \ref{tab:pilllm2a}, the significant variables from the old model were still significant, and additionally there was a small effect of Acupuncture credibility and gender on the overall Pill Credibility scores. 

Next, the original model on cream credibility scores was examined. 

<<creamlm2a, echo=FALSE, results=tex>>=
creamlm2a <- lm(Creamtot~Pilltot+Injtot+Acutot+Gender+College+UGPG, data=tcq2a)
print(xtable(summary(creamlm2a), caption="Regression of Cream Credibility Scores Model from Study One on a subsample of Study Two Data", label="tab:creamlm2a"))
@ 

As can be seen from Table \ref{tab:creamlm2a}, a similar pattern  as was seen from the Study One data emerges from this regression model. Note that the positive coefficient for Acupuncture remains in this data, and is again significant. This suggests that cream and acupuncture painkilling treatments are somehow linked together in the minds of participants in both studies. This could be due to the fact that they are not as widely used as pills and injections, and so possess less face validity to the participants studied. 

Next, we examine the Injection Credibility model developed on the first sample. 

<<injlm2a, echo=FALSE, results=tex>>=
injlm2a <- lm(Injtot~Pilltot+Creamtot+Acutot+Gender+College+UGPG, data=tcq2a)
print(xtable(summary(injlm2a), caption="Regression of Injection Credibility Score Model from Study One on subsample from Study Two", label="tab:injlm2a"))
@ 

As can bee seen from Table \ref{tab:injlm2a}, the results of this same model on Study Two data were in line with those from Study One. That being said, both Gender Coefficients are significant in Study Two, while they were not in Study One. This is interesting as it represents a larger effect being seen on an equivalent instrument. 

Finally, the Acupuncture credibility model from Study One was examined. 

<<acutotlm2a, echo=FALSE, results=tex>>=
acutotlm2a <- lm(Acutot~Pilltot+Creamtot+Injtot+Gender+College+UGPG, data=tcq2a)
acutot2a.xtab <- xtable(summary(acutotlm2a), caption="Acupuncture Credibility Model from Study One replicated on a subsample from Study Two", label="tab:acutotlm2a")
print(acutot2a.xtab)
@ 

Table \ref{tab:acutotlm2a} shows that the model for Acupuncture credibility is quite different on the Study Two data. Firstly, the coefficient for Injection is positive, unlike in the previous data, and the coefficients for College and Gender are significant. This would seem to suggest that the representation of the acupuncture credibility questions were quite different between the two samples, with a stronger effect of demographic questions in sample two. 

\subsection{Confirmatory IRT Analyses}
\label{sec:conf-irt-analys}


The first step in examining the predictive power of the IRT models is to score the current subsample of the Study Two data (Split A) using the prior models. Then, the same model can be fit on this data alone, and the error of estimation between the two processes can be calculated. Essentially, the root mean square error of approximation (RMSEA) was used to assess the usefulness of each of the models. 

Firstly, the Conventional Treatment Scale was assessed. 

<<tcqconvpcmraschtest, echo=FALSE, results=hide, cache=TRUE>>=
tcq2a.conv <- tcq2.1[,c(1,3:18)]
pcm.rasch.done <- testIRTModels(tcqconv.pcm.rasch, tcq2a.conv, gpcmconstraint="rasch", grmconstraint=NULL)
@ 


<<tcqconvpcm1pltest, echo=FALSE, results=hide, cache=TRUE>>=
pcm.1pl.done <- testIRTModels(tcqconv.pcm.1pl, tcq2a.conv, gpcmconstraint="1PL", grmconstraint=NULL)
@ 

<<tcqconvpcmgpcmtest, echo=FALSE, results=hide, cache=TRUE>>=
pcm.gpcm.done <- testIRTModels(tcqconv.pcm.gpcm, tcq2a.conv, gpcmconstraint="gpcm", grmconstraint=NULL)
@ 

<<pcmmodcomp, echo=FALSE, results=hide, cache=TRUE>>=
pcm.mod.comp <- rbind(pcm.rasch.done, pcm.1pl.done, pcm.gpcm.done)
rownames(pcm.mod.comp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")


@ 
<<pcmmodcompprint, echo=FALSE, results=tex>>=
pcm.mod.comp.xtab <- xtable(pcm.mod.comp, caption="Comparison of Performance of IRT PCM Models on Study Two Data", label="tab:pcmmodcomp")
print(pcm.mod.comp.xtab)
@ 
As can be seen from Table \ref{tab:pcmmodcomp}, the one parameter Partial Credit Model appears to fit better in that it has a lower square root of the sum of the squared errors, and the predicted scores and actual scores correlate higher than those for the rasch model. However, despite these fit indices an argument can be made for the Rasch model in terms of simplicity (even though a complexity parameter was added to the error term to account for this possibility). 

Next, the same process is repeated for the graded response models. 

<<grmtest, echo=FALSE, results=tex, cache=TRUE>>=
grm1pl.done <- testIRTModels(tcqconv.grm.1pl, tcq2a.conv, grmconstraint=TRUE)
grm2pl.done <- testIRTModels(tcqconv.grm.2pl, tcq2a.conv, grmconstraint=FALSE)
grm.modcomp <- rbind(grm1pl.done, grm2pl.done)
rownames(grm.modcomp) <- c("One Parameter GRM", "Two Parameter GRM")

@ 
<<grmmodcompprint, echo=FALSE, results=tex>>=
grm.modcomp.xtab <- xtable(grm.modcomp, caption="Comparison of One and Two Parameter Graded Response Models, Split 2A", label="tab:grmmodcomp")
print(grm.modcomp.xtab)
@ 
As shown in Table \ref{tab:grmmodcomp}, the one parameter model performed better on the unseen data than did the two parameter model (unlike the analysis using likelihoods which picked the more complicated model in each case)


\section{Study Two}

Given the results of Study 1, this study added two more Complementary and Alternative Medicine (CAM) methodologies to the questionnaire, to determine if a higher order factor structure could be found which represented conventional and complementary methodologies.
The hypotheses were as follows: 

\begin{itemize}
\item The TCQ V2.0 will have six factors, one for each treatment modality, along with two higher level factors, one for Conventional and Alternative treatments each;

\item The BAM will have two factors;

\item The BAM will correlate negatively with the Pills, Cream and Injection totals, and positively with the Acupuncture, Homeopathy and Reiki totals;
\item   The TCQ will not fit an item response theory model well, and will need to be divided into TCQ Conventional (Pills, Creams, Injections) and a TCQ Alternative (Acupuncture, Homeopathy and Reiki) in order to meet the assumptions of the model(s).;

\item Income will correlate postively with experience of CAM methodologies;

\item Experience with a particular treatment will be correlated with higher ratings of its credibility. 
\end{itemize}



\subsection{Results}
\subsubsection{Descriptive Statistics}

The sample size collected was 1329, however, only 700 completed all questions. The analysis was carried out on those participants who had provided data for all questions. 

<<tcq2demo, echo=FALSE, results=tex>>=
tcq2.demo <- tcq2[,2:17]
tcq2.demo1 <- tcq2.demo[,1:5]
tcq2.demo2 <- tcq2.demo[,6:10]
tcq2.demo3 <- tcq2.demo[,11:16]
tcq2.sum1 <- summary(tcq2.demo1)

stargazer(tcq2.demo1, tcq2.demo2, tcq2.demo3, summary=TRUE, title="TCQ2 Summary Statistics", label="tab:tcq2sumstats")
@ 



As can be seen from the second sub-table of Table \ref{tab:tcq2sumstats} , many respondents stopped answering questions throughout the demographic variables. The reasons for this are unknown, but are probably not related to the design in any substantial way. The median age is 22, which shows that most of the sample was made up of students.

The Health variable is quite skewed, as most respondents rated their health as very good as good, as can be seen from the mean and the median. 
The mean level of experience with a particular treatment was highest for pills and steadily declined for all of the other treatments. 

The sample was 67.88\% female, and 29.12\% male, with 45 respondents not specifying their gender. 

The next step in the analysis is visualisation of data using scatterplot matrices and conditioning plots. Figure \ref{fig:tcq2pairs}, the correlations between the scale totals can be seen. 
@ 

\begin{figure}
	\centering
<<tcq2pairs, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
sink("tmp.txt")
pairs.panels(tcqtotals)
sink(NULL)
@ 
	\caption{Scatterplot Matrix, TCQ 2}
	\label{fig:tcq2pairs}
\end{figure}



As can be seen from Figure \ref{fig:tcq2pairs}, the predicted relationship appear to be apparent. The high inter-correlations between the first three sub-scales of the TCQ and the last three are immediately apparent, and there is no evidence of nonlinearity in any of the relationships which is useful given the intention to model some of these later in the analyses. 


Interestingly enough, it can be seen from Figure \ref{fig:tcq2pairs} that the Beliefs About Medicine Questionnaire totals seem normally distributed, which is unexpected  (Micceri et al, 1989). The boxplots for the alternative treatments are also quite interesting, given that they appear to have a number of peaks with very little in between. This may reflect the polarised nature of the attitudes towards these treatments. It may be (for example) that those involved with medicine tend to rate them very low, while those involved in the liberal arts tend to rate them quite highly. These kinds of differences will be teased apart in analyses below. 

As can be seen from Table \ref{fig:tcq2credgend}, the sample scores showed some significant differences attributable to Gender. The cream, acupuncture, homeopathy and reiki totals were significantly different in the sample, as was the Beliefs About Medicine scale total. The usual caveats regarding multiple comparisons do of course apply to this finding. 


\begin{figure}
<<credgender, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
gendPill <- ggplot(na.omit(tcq2), aes(y=Pilltot, x=Gender))+geom_boxplot()
gendcream <- ggplot(na.omit(tcq2), aes(y=Creamtot, x=Gender))+geom_boxplot()
gendInj <- ggplot(na.omit(tcq2), aes(y=Injtot, x=Gender))+geom_boxplot()
gendAcu <- ggplot(na.omit(tcq2), aes(y=Acutot, x=Gender))+geom_boxplot()
gendHom <- ggplot(na.omit(tcq2), aes(y=Homtot, x=Gender))+geom_boxplot()
gendRei <- ggplot(na.omit(tcq2), aes(y=Reitot, x=Gender))+geom_boxplot()
print(arrangeGrob(gendPill, gendcream, gendInj, gendAcu, gendHom, gendRei))
@   
  \caption{Credibility Scores by Gender, Sample Two}
  \label{fig:tcq2credgend}
\end{figure}

\begin{figure}
<<collcredplot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
collpill <- ggplot(tcq2, aes(x=College, y=Pilltot))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collCream <- ggplot(tcq2, aes(x=College, y=Creamtot))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collInj <- ggplot(tcq2, aes(x=College, y=Injtot))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collAcu <- ggplot(tcq2, aes(x=College, y=Acutot))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collHom <- ggplot(tcq2, aes(x=College, y=Homtot))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
collRei <- ggplot(tcq2, aes(x=College, y=Reitot))+geom_boxplot()+theme(axis.text.x=element_text(angle=45, hjust=1))
print(arrangeGrob(collpill, collCream, collInj, collAcu, collHom, collRei ))
@   
  \caption{Credibility Scores by College}
  \label{fig:tcq2collcred}
\end{figure}



As can be seen from Figure \ref{fig:tcq2collcred}, there were significant differences between the credibility totals in each college for the three conventional treatment modalities. This appears to be due to higher credibility totals amongst those respondents whose primary affiliation was with the College of Medicine and Health. %% The Beliefs about Medicine difference makes sense as the questions are quite negative towards medicines, and it would be expected that many Medicine and Health students would disagree with them, given their perspective.


Following these investigations of the descriptive qualities of the data, the next stage of the analysis is to examine the inter-correlations and latent structure behind the data through the use of factor analysis. 

<<semsplits, echo=FALSE, results=hide, cache=TRUE>>=
tcq2nota <- tcq2[-tcq2.ind.a,]
tcq2notb <- tcq2[-tcq2.ind.b,]
tcq2notc <- tcq2[-tcq2.ind.c,]
tcq2notd <- tcq2[-tcq2.ind.d,]
tcqall2nota <- tcq2nota[,17:52]
tcqall2notb <- tcq2notb[,17:52]
tcqall2notc <- tcq2notc[,17:52]
tcqall2notd <- tcq2notd[,17:52]
bamnotA <- tcq2nota[,53:70]
bamnotB <- tcq2notb[,53:70]
bamnotC <- tcq2notc[,53:70]
bamnotD <- tcq2notd[,53:70]
@ 



\section{Treatment Credibility Questionnaire, Version 2}



\subsubsection{TCQ Version2 Split A}
\label{sec:tcq-version2-split}

<<scales2a, echo=FALSE, results=hide, cache=TRUE>>=
Pillall2a <- tcq2a[,grep("Pill[1-6]", x=names(tcq2a))]
Creamall2a <- tcq2a[,grep("Cream[1-6]", x=names(tcq2a))]
Injall2a <- tcq2a[,grep("Inj[1-6]", x=names(tcq2a))]
Acuall2a <- tcq2a[,grep("Acu[1-6]", x=names(tcq2a))]
Homall2a <- tcq2a[,grep("Hom[1-6]", x=names(tcq2a))]
Reiall2a <- tcq2a[,grep("Rei[1-6]", x=names(tcq2a))]
bamall2a <- tcq2a[,53:70]
tcqall2a <- as.data.frame(cbind(Pillall2a, Creamall2a, Injall2a, Acuall2a, Homall2a, Reiall2a))
@ 

Parallel analysis and the scree plot agree that six factors seems most optimal for this instrument. However, the MAP criterion disagrees, suggesting that seven factors might be more appropriate. To determine which of these criteria is correct, both the six and seven factor solutions will be examined for interpretability. 


<<tcq2afact6, echo=FALSE, results=tex>>=
tcq2a.fact.6 <- fa(na.omit(tcqall2a),  nfactors=6, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2a.fact.6, names=c("Rei", "Hom", "Acu", "Cream", "Inj", "Pill"), label="tab:tcq2afact6", caption="Six factor Solution, TCQ 2, Oblimin Rotation"))
@ 


As can be seen from Table \ref{tab:tcq2afact6} , this factor structure fits the predicted one extremely well. The six factors map exactly to the six treatment modalities. PA5 equates to Reiki, PA1 to Homeopathy, PA4 to Acupuncture, PA3 to Cream, PA2 to Injections and PA6 equates to Pills. 

%% Below can be seen the correlations between factors, in Table \ref{tab:tcq2a6factorcor}.


<<tcq2afactorcor, echo=FALSE, results=hide>>=
print(FactorCor(tcq2a.fact.6, label="tab:tcq2a6factorcor", caption="Factor Correlations, Six Factor Solution TCQ 2"))
@ 




The proportion of variance explained by the six factor solution is equal to 82\% which is an extremely high amount, arguing for the usefulness of this solution. 

As can be seen from Table \ref{tab:tcq2a6factorcor}, the correlations between factors are very similar to those between the total scores, which is perhaps unsurprising as both are linear combinations of the scores on each questions. Nonetheless, this gives supporting evidence in favour of the utility of this solution. 



<<tcq2afact7, echo=FALSE, results=tex>>=
tcq2a.fact.7 <- fa(na.omit(tcqall2a), nfactors=7, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2a.fact.7, names=c("Reiki", "Hom", "Acu", "Cream", "Pill", "Inj", "Seven"), label="tab:tcq2afact7",caption="Seven Factor Solution, TCQ 2, Oblimin Rotation"))
@ 



Table \ref{tab:tcq2afact7} is enlightening in that it can be seen that factor 7 has no questions loading highest on it. Therefore, we can probably use the six factor structure on the basis of this data. 
The correlations between the factors are reported in Table \ref{tab:tcq2a7factorcorr}.

<<tcq2a7factorcorr, echo=FALSE, results=hide>>=
print(FactorCor(tcq2a.fact.7, label="tab:tcq2a7factorcorr", caption="Correlations Between factors, TCQ 2A, Seven factor solution"))
@ 

<<tcq2afitindices, echo=FALSE, results=tex, cache=TRUE, eval=FALSE>>=
tcq2aFit6 <- FitIndices(tcq2a.fact.6)
tcq2aFit7 <- FitIndices(tcq2a.fact.7)
tcq2afit <- as.data.frame(cbind(tcq2aFit6, tcq2aFit7))
tcq2afit.m <- melt(tcq2afit)
names(tcq2afit)[1] <- "Fit Index"
print(xtable(tcq2afit.m,caption="Fit Indices, TCQ 2", label="tab:tcq2afit"))
#Fix this godawffully ugly table, possibily using cast
@ 

%% In Table \ref{tab:tcq2afit}, the fit indices for each of the solutions are shown.











%put in other 3 sem fits, although i suspect they won\'t converge. Look for debugging information online when you have internet. 

\subsection{Split B}
\label{sec:split-b}

Next, the same process of analysis will be repeated on the second of four splits of the data. 

<<tcq2bscalesplit, echo=FALSE, results=hide, cache=TRUE>>=
tcqall2b <- tcq2b[,17:52]
bamall2b <- tcq2b[,53:70]
@ 



Parallel analysis and the scree plot suggest that five factors seems most optimal for this instrument. However, the MAP criterion disagrees, suggesting that seven factors might be more appropriate. To determine which of these criteria is correct, the five,  six and seven factor solutions will be examined for interpretability and then subjected to CFA on the other splits of the data.

\paragraph{Five Factor Solution}
\label{sec:five-factor-solution}

<<tcq2afact5, echo=FALSE, results=tex>>=
tcq2b.fact.5 <- fa(na.omit(tcqall2b), nfactors=5, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2b.fact.5, names=c("Pill&Inj", "Cream", "Rei", "Hom", "Acu"),  label="tab:tcq2afact5",caption="Five factor Solution, TCQ 2 (Split B), Oblimin Rotation"))
@ 

The five factor solution (shown in Table \ref{tab:tcq2afact5}) broke down as follows:
It explained 81\% of the variance, and all the communalities were greater than 0.5. 

PA2: "Pill1", "Pill2", "Pill3", "Pill4", "Pill5", "Pill6", "Inj1",  "Inj2",  "Inj3",  "Inj4",  "Inj5",  "Inj6". This factor appears to consist of the Pill and Injection questions, and so can be termed Pills \& Injections.

PA3:"Cream1", "Cream2", "Cream3", "Cream4", "Cream5", "Cream6". This factor consists of the Cream questions and can thus be termed Creams. 

PA5: "Rei1",  "Rei2",  "Rei3",  "Rei4",  "Rei5",  "Rei6". There was a small negative loading on Pill1 for this factor, but given its strong loadings on other factors, this was ignored. This left this factor consisting solely of the Reiki items, and so this factor was termed Reiki. 

PA1: "Hom1", "Hom2", "Hom3", "Hom4", "Hom5", "Hom6". This factor consisted solely of the homeopathy items, and thus was termed Homeopathy.

PA4: "Acu1", "Acu2", "Acu3", "Acu4", "Acu5", "Acu6". This factor consisted solely of the Acupuncture items and thus was termed acupuncture. 





\paragraph{Six Factor Solution, Split B}
\label{sec:six-factor-solution}



<<tcq2bfact6, echo=FALSE, results=tex>>=
tcq2b.fact.6 <- fa(na.omit(tcqall2b), nfactors=6, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2b.fact.6, names=c("Rei", "Hom", "Acu", "Cream", "Inj", "Pill"),label="tab:tcq2bfact6",caption="Six factor Solution, TCQ 2, Oblimin Rotation"))
@ 


As can be seen from Table \ref{tab:tcq2bfact6} , the six factor structure fits the predicted one extremely well. The six factors map exactly to the six treatment modalities. PA5 equates to Reiki, PA1 to Homeopathy, PA4 to Acupuncture, PA3 to Cream, PA2 to Injections and PA6 equates to Pills. One small exception to this was that Pill1 loaded slightly onto the Reiki factor. However, in light of its strong loading on other factors, this was disregarded \footnote{it is perhaps interesting that this strange loading also occurred in other factor solutions}.  

%% Below can be seen the correlations between factors, in Table \ref{tab:tcq2b6factorcor} . 


<<tcq2bfactorcor, echo=FALSE, results=hide>>=
print(FactorCor(tcq2b.fact.6,label="tab:tcq2b6factorcor",caption="Factor Correlations, Six Factor Solution TCQ 2B"))
@ 





The proportion of variance explained by the six factor solution is equal to 84\% which is an extremely high amount, arguing for the usefulness of this solution. 

The correlations between factors are very similar to those between the total scores, which is perhaps unsurprising as both are linear combinations of the scores on each questions. Nonetheless, this gives supporting evidence in favour of the utility of this solution. 

\paragraph{Seven Factor Solution}
\label{sec:seven-fact-solut}



<<tcq2bfact7, echo=FALSE, results=tex>>=
tcq2b.fact.7 <- fa(na.omit(tcqall2b), nfactors=7, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2b.fact.7, names=c("Hom", "Rei", "Acu", "Cream","Inj", "Pill", "Cred"), label="tab:tcq2bfact7",caption="Seven Factor Solution, TCQ 2B, Oblimin Rotation"))
@ 


The seven factor solution shown in Table \ref{tab:tcq2bfact7} explained 86\% of the variance in the sample, and the items were assigned to factors as follows.

PA1: "Hom1", "Hom2", "Hom3", "Hom4", "Hom5", "Hom6". This factor clearly maps to the Homeopathy questions, and is therefore termed as Homeoapathy.

PA5: "Pill1", "Rei1",  "Rei2",  "Rei3",  "Rei4",  "Rei5",  "Rei6". Again, apart from a small loading of Pill1 on this factor, it maps exactly to the Reiki questions, and thus will be termed Reiki. 

PA4: "Acu1", "Acu2", "Acu3", "Acu4", "Acu5", "Acu6". This factor maps exactly to the Acupuncture questions, and will be termed thusly.

PA3: "Cream1", "Cream2", "Cream3", "Cream4", "Cream5", "Cream6". Again, this factor is an exact map to the Cream questions and thus is termed Creams.

PA2: "Inj1", "Inj2", "Inj3", "Inj4", "Inj5", "Inj6". These items are all Injection items, and so this factor gets that name. 

PA6: "Pill1", "Pill2", "Pill3", "Pill4", "Pill5", "Pill6". This factor maps to all of the pill items, and is thus called Pills. 

PA7: "Pill3",  "Cream3", "Inj1",   "Inj3" . This factor is a little strange, as it only takes some of the questions from the conventional factors. It does take the confidence question from all three conventional methodologies, and thus can be termed confidence in conventional treatments. 


The correlations between the factors are reported in Table \ref{tab:tcq2b7factorcorr}.

<<tcq2b7factorcorr, echo=FALSE, results=tex>>=
print(FactorCor(tcq2b.fact.7,label="tab:tcq2b7factorcorr", caption="Factor Correlations, TCQ2B, Seven factor Solution"))
@ 

<<tcq2bfitindices, echo=FALSE, results=tex, cache=TRUE, eval=FALSE>>=
tcq2bFit5 <- FitIndices(tcq2b.fact.5)
tcq2bFit6 <- FitIndices(tcq2b.fact.6)
tcq2bFit7 <- FitIndices(tcq2b.fact.7)
tcq2bfit <- as.data.frame(cbind(tcq2bFit5, tcq2bFit6, tcq2bFit7))
tcq2bfit.m <- melt(tcq2bfit)
names(tcq2bfit.m) <- "Fit Index"
print(xtable(tcq2bfit,caption="Fit Indices, TCQ 2 (Split B)", label="tab:tcq2bfit"))
@ 


\subsection{TCQ, Split C}
\label{sec:tcq-split-c}



<<tcq2cscalesplit, echo=FALSE, results=hide, cache=TRUE>>=
tcqall2c <- tcq2c[,17:52]
bamall2c <- tcq2c[,53:70]
@ 


\paragraph{Five Factor Solution}
\label{sec:five-factor-solution}


<<tcq2cfact5, echo=FALSE, results=tex>>=
tcq2c.fact.5 <- fa(na.omit(tcqall2c), nfactors=5, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2c.fact.5, names=c("PillInj", "Hom", "Rei", "Cream", "Acu"), label="tab:tcq2cfact5",caption="Five factor Solution, TCQ 2 (Split C), Oblimin Rotation"))
@ 


The five factor  solution (shown in Table \ref{tab:tcq2cfact5}) explained 79\% of the variance, and all of the communalities were extremely high. 

PA2: "Pill1", "Pill2", "Pill3", "Pill4", "Pill5", "Pill6", "Inj1",  "Inj2",  "Inj3", "Inj4",  "Inj5",  "Inj6". This factor consists of the Pill and Injection items, and can therefore best be termed Pills and Injections.

PA1: "Hom1", "Hom2", "Hom3", "Hom4", "Hom5", "Hom6". This factor maps exactly to the Homeopathy items, and is therefore given that name.

PA5: "Rei1", "Rei2", "Rei3", "Rei4", "Rei5", "Rei6". Again, this factor maps exactly to the Reiki items and is named after them.

PA4: "Cream1", "Cream2", "Cream3", "Cream4", "Cream5", "Cream6". PA4 maps to the Cream items and so retains that name. 

PA3: "Acu1", "Acu2", "Acu3", "Acu4", "Acu5", "Acu6". PA3 maps to the acupuncture items and so is termed Acupuncture. 



<<tcq2cfactorcor5, echo=FALSE, results=tex>>=
print(FactorCor(tcq2c.fact.5,label="tab:tcq2cfactorcor5", caption="Factor Correlations, TCQ 2 Five Factor Solution, Split C"))
@ 

Table \ref{tab:tcq2cfactorcor5} shows that the Pills/Injections factor correlated highly with the Cream factor (as would be expected), while the Alternative factors correlate quite well with one another also. Of particular note is Acupuncture, which appears to occupy a middle ground between the other alternative methods and the conventional ones, as least as evinced by this correlation structure. 


\paragraph{Six Factor Solution}
\label{sec:six-factor-solution}



<<tcq2cfact6, echo=FALSE, results=tex>>=
tcq2c.fact.6 <- fa(na.omit(tcqall2c), nfactors=6, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2c.fact.6,names=c("Hom", "Rei", "Acu", "Cream", "Inj", "Pill"), label="tab:tcq2cfact6",caption="Six factor Solution, TCQ 2, Split C,  Oblimin Rotation"))
@ 


Again, as can be seen in Table \ref{tab:tcq2cfact6} the six factors map exactly to the six forms of treatment, rendering an interpretation of the resulting factor solution rather superflous. 


<<tcq2cfactorcor, echo=FALSE, results=tex>>=
print(FactorCor(tcq2c.fact.6,label="tab:tcq2c6factorcorr",caption="Factor Correlations, Six Factor Solution TCQ 2, Split C"))
@ 

Again (Table \ref{tab:tcq2c6factorcorr} ) shows that Acupuncture again shows correlations with the conventional factors, but homeopathy does also in this particular solution. This solution explained 83\% of the variance, which is consistent with the other splits and factor solutions examined so far. 



<<tcq2cfact7, echo=FALSE, results=tex>>=
tcq2c.fact.7 <- fa(na.omit(tcqall2c), nfactors=7, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2c.fact.7, names=c("Hom", "Rei", "Acu", "Cream", "Inj", "Pill", "Cred"), label="tab:tcq2cfact7",caption="Seven Factor Solution, TCQ 2, Split C,  Oblimin Rotation"))
@ 

Table \ref{tab:tcq2cfact7} shows the seven factor solution structure for Split C. 


Again, the factors mostly break down into the six forms of treatment.

PA1: "Hom1", "Hom2", "Hom3", "Hom4", "Hom5", "Hom6". This factor represents the homeopathy items and retains that name. 

PA5: "Rei1", "Rei2", "Rei3", "Rei4", "Rei5", "Rei6". This is the Reiki items factor. 

PA3: "Acu1", "Acu2", "Acu3", "Acu4", "Acu5", "Acu6". This is the Acupuncture items factor. 

PA4: "Cream1", "Cream2", "Cream3", "Cream4", "Cream5", "Cream6". This is the Cream factor. 

PA2:"Inj1", "Inj2", "Inj3", "Inj4", "Inj5", "Inj6". This is the Injections factor. 

PA6:"Pill1", "Pill2", "Pill3", "Pill4", "Pill5", "Pill6". This is the Pills factor. 

PA7: "Pill3", "Inj1",  "Inj3" . This factor has supplementary loadings for some of the Pill and Injection items, most notably the confidence in the treatment items, so this can best be termed Confidence in Treatment Factor. 

The correlations between the factors are reported in Table \ref{tab:tcq2c7factorcorr}.

<<tcq2c7factorcorr, echo=FALSE, results=tex>>=
print(FactorCor(tcq2c.fact.7,label="tab:tcq2c7factorcorr", caption="Factor Correlations, Seven Factor Solution, TCQ 2, Split C"))
@ 

The seven factor solution (Table \ref{tab:tcq2c7factorcorr} shows high intercorrelations between each of the conventional forms of treatment and each of the alternative forms of treatment but does not show any real correlations between them (except for Acupuncture). 

<<tcq2cfitindices, echo=FALSE, results=tex, cache=TRUE, eval=FALSE>>=
tcq2cFit5 <- FitIndices(tcq2c.fact.5)
tcq2cFit6 <- FitIndices(tcq2c.fact.6)
tcq2cFit7 <- FitIndices(tcq2c.fact.7)
tcq2cfit <- as.data.frame(cbind(tcq2cFit5, tcq2cFit6, tcq2cFit7))
tcq2cfit.m <- melt(tcq2cfit)
names(tcq2cfit.m)[1] <- "Fit Index"
print(xtable(tcq2cfit.m,caption="Fit Indices, TCQ 2 (Split C)", label="tab:tcq2cfit"))
@ 


%% It can be seen from Table \ref{tab:tcq2cfit} that the NNFI increases across all factor solutions, but is still quite low for an acceptable factor structure. The BIC performs likewise, reaching its lowest value for the seven factor solution. The RMSEA are uniformly poor, but again appear to be best for the seven factor solution. 




\subsection{Split D}
\label{sec:split-d}



<<tcq2dscalesplit, echo=FALSE, results=hide, cache=TRUE>>=
tcqall2d <- tcq2d[,17:52]
bamall2d <- tcq2d[,53:70]
@ 

In this Split, the parallel analysis criterion suggested six factors while the MAP criterion suggested seven. Following previous practice, these two solutions were reported and examined for adequacy of fit and interpretability. 

\paragraph{Six Factor Solution}
\label{sec:six-factor-solution}



<<tcq2dfact6, echo=FALSE, results=tex>>=
tcq2d.fact.6 <- fa(na.omit(tcqall2d), nfactors=6, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2d.fact.6, names=c("Reiki", "Hom", "Acu", "Cream", "Inj", "Pill"), label="tab:tcq2dfact6",caption="Six factor Solution, TCQ 2(Split D), Oblimin Rotation"))
@ 


As per all previous splits, the six factor solution mapped all six treatment modalities to the six factors, as is clearly shown in Table \ref{tab:tcq2dfact6}. This solution explained 81\% of the variance. 


<<tcq2dfactorcor, echo=FALSE, results=tex>>=
print(FactorCor(tcq2d.fact.6,label="tab:tcq2dfactorcor",caption="Factor Correlations, Six Factor Solution TCQ 2 (Split D)"))
@ 


Similiarly to the results in other splits, the three conventional treatment factors and the three alternative factors correlated with each other but tended not to correlate highly with the factors of the opposite modality. Details of the correlations between factors are shown in Table \ref{tab:tcq2dfactorcor}. 

\paragraph{Seven Factor Solution}
\label{sec:seven-fact-solut}



<<tcq2dfact7, echo=FALSE, results=tex>>=
tcq2d.fact.7 <- fa(na.omit(tcqall2d), nfactors=7, rotate="oblimin", fm="pa")
print(FactorXtab(tcq2d.fact.7, names=c("Reiki", "Hom", "Acu", "Cream", "Inj", "Pill", "Cred"), label="tab:tcq2dfact7",caption="Seven Factor Solution, TCQ 2, Oblimin Rotation (Split D)"))
@ 

The details of the seven factor solution for this split are shown in Table \ref{tab:tcq2dfact7}. 

This solution explained 84\% of the variance, an amount which was in line with that observed in other splits. 

PA1: "Rei1", "Rei2", "Rei3", "Rei4", "Rei5", "Rei6". These items map exactly to the Reiki questions, and so this factor will be termed Reiki. 

PA5: "Hom1", "Hom2", "Hom3", "Hom4", "Hom5", "Hom6". This factor will be termed Homeopathy. 

PA4: "Acu1", "Acu2", "Acu3", "Acu4", "Acu5", "Acu6". This factor will be termed Acupuncture. 

PA2: "Cream1", "Cream2", "Cream3", "Cream4", "Cream5", "Cream6". This factor will be termed Creams.

PA3: "Inj1", "Inj2", "Inj3", "Inj4", "Inj5", "Inj6". This factor will be termed Injections.

PA6: "Pill1", "Pill2", "Pill3", "Pill4", "Pill5", "Pill6". This factor will be termed Pills. 

PA7: "Pill3",  "Cream3", "Inj3" This factor has emerged in the other splits also, and again will be termed Confidence in Conventional Treatment.



<<tcq2d7factorcorr, echo=FALSE, results=tex>>=
print(FactorCor(tcq2d.fact.7,label="tab:tcq2d7factorcorr", caption="Factor Correlations, Seven Factor Solution, TCQ 2, Split D"))
@ 


<<tcq2dfitindices, echo=FALSE, results=tex, cache=TRUE, eval=FALSE>>=
tcq2dFit6 <- FitIndices(tcq2d.fact.6)
tcq2dFit7 <- FitIndices(tcq2d.fact.7)
tcq2dfit <- as.data.frame(cbind( tcq2dFit6, tcq2dFit7))
tcq2dfit.m <- melt(tcq2dfit)
names(tcq2dfit.m)[1] <- "Fit Index"
print(xtable(tcq2dfit.m,caption="Fit Indices, TCQ 2 (Split D)",label="tab:tcq2dfit"))
@ 


%% From Table \ref{tab:tcq2dfit}, the same pattern  as has been seen in previous splits emerges in that the NNFI increases while  the BIC decreases along with the RMSEA. 



\section{Structural Equation Modelling}

Normally, cross-validation of particular models involves the setting aside of a small portion of the data for testing of the model. However, SEM and factor analytic requirements for relatively large sample sizes meant that this approach was not practicable. Therefore a different strategy was followed. %% In essence, a boosting strategy was attempted\footnote{contrary to Richie's belief when he wrote this, this strategy is not a boosting strategy}. 
This is where many models are fit on smaller subsets of the data, and then they are tested on a larger subset of the data (all of the data save those that they were trained on. So, for Split A models, they will be tested on all the data that was not included in Split A. This approach was taken in order to take advantage of the random variability in the smaller samples while maintaining a rigorous test on a large sample to ensure that only the best models survive. 

\subsection{Split A CFA}
\label{sec:split-cfa}



<<tcq6notaSem, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
Tcq6modelnotA <- mxModel(name="TCQ6notA", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2nota)), type="cov", numObs=460))
tcq6fit.notA <- mxRun(Tcq6modelnotA)
tcq6summ.notA <- summary(tcq6fit.notA)
@ 

<<tcq7notAsem, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Seven")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
seven <- c("Inj1", "Inj3")
Tcq7modelnotA <- mxModel(name="TCQ7notA", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Seven", to=seven),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2nota)), type="cov", numObs=460))
tcq7fit.notA <- mxRun(Tcq7modelnotA)
tcq7summ.notA <- summary(tcq7fit.notA)
@ 

<<tcq2notAsemcompare, echo=FALSE, results=tex>>=
tcq2.notA.semcompare <- mxCompare(tcq6fit.notA, tcq7fit.notA)
print(xtable(tcq2.notA.semcompare, label="tab:tcq2notAsemcompare", caption="Comparison of Factor Models built on Split A on Splits B, C and D"))
@ 

It can be seen from Table \ref{tab:tcq2notAsemcompare} that the seven factor model from Split A provided a better fit to the out of sample data than did the 6 factor model. 


\subsection{Split B CFA}
\label{sec:split-b-cfa}

<<tcq5notbSem, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
pillinj.cols <- c(pillitems.cols, Injitems.cols)
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills & Injections", "Creams", "Acupuncture", "Homeopathy", "Reiki")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
pillinj <- c(pills, inj)
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
Tcq5modelnotB <- mxModel(name="TCQ5notB", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills & Injections", to=pillinj), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notb)), type="cov", numObs=450))
tcq5fit.notB <- mxRun(Tcq5modelnotB)
tcq5summ.notB <- summary(tcq5fit.notB)
@ 


<<tcq6notbSem, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
Tcq6modelnotB <- mxModel(name="TCQ6notB", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notb)), type="cov", numObs=460))
tcq6fit.notB <- mxRun(Tcq6modelnotB)
tcq6summ.notB <- summary(tcq6fit.notB)
@ 

<<tcq7notBsem, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Confidence in Conventional Treatments")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
confconv <- c("Pill3", "Cream3", "Inj1", "Inj3")
Tcq7modelnotB <- mxModel(name="TCQ7notB", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Confidence in Conventional Treatments", to=confconv),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notb)), type="cov", numObs=460))
tcq7fit.notB <- mxRun(Tcq7modelnotB)
tcq7summ.notB <- summary(tcq7fit.notB)
@ 

<<tcq2notBsemcompare, echo=FALSE, results=tex>>=
tcq2.notB.semcompare <- mxCompare(tcq5fit.notB,c(tcq6fit.notB, tcq7fit.notB))
print(xtable(tcq2.notB.semcompare, label="tab:tcq2notBsemcompare", caption="TCQ 2 Factor Solutions From Split B, Tested Against Splits A, C and D"))
@ 

It can be seen from Table \ref{tab:tcq2notBsemcompare} that the seven factor model from Split B provided a better fit to the out of sample data than did the 6 factor model. 


\subsection{Split C CFA}
\label{sec:split-c-cfa}

Next, the fit of the models developed on Split C will be tested on Splits A, B and D. Firstly, the TCQ factor structures will be compared. 

<<tcq5notcSem, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
pillinj.cols <- c(pillitems.cols, Injitems.cols)
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills & Injections", "Creams", "Acupuncture", "Homeopathy", "Reiki")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
pillinj <- c(pills, inj)
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
Tcq5modelnotC <- mxModel(name="TCQ5notC", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills & Injections", to=pillinj), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notc)), type="cov", numObs=452))
tcq5fit.notC <- mxRun(Tcq5modelnotC)
tcq5summ.notC <- summary(tcq5fit.notC)
@ 


<<tcq6notcSem, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
Tcq6modelnotC <- mxModel(name="TCQ6notC", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notc)), type="cov", numObs=460))
tcq6fit.notC <- mxRun(Tcq6modelnotC)
tcq6summ.notC <- summary(tcq6fit.notC)
@ 

<<tcq7notCsem, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Confidence in Conventional Treatments")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
confconv <- c("Pill3", "Inj1", "Inj3")
Tcq7modelnotC <- mxModel(name="TCQ7notC", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Confidence in Conventional Treatments", to=confconv),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notc)), type="cov", numObs=460))
tcq7fit.notC <- mxRun(Tcq7modelnotC)
tcq7summ.notC <- summary(tcq7fit.notC)
@ 

<<tcq2notCsemcompare, echo=FALSE, results=tex>>=
tcq2.notC.semcompare <- mxCompare(tcq5fit.notC,c(tcq6fit.notC, tcq7fit.notC))
print(xtable(tcq2.notC.semcompare, label="tab:tcq2notCsemcompare", caption="TCQ Models from Split C tested against Splits A, B and D"))
@ 

It can be seen from Table \ref{tab:tcq2notCsemcompare} that the seven factor model from Split C provided a better fit to the out of sample data than did the 5 or 6 factor model. 




\subsection{Split D CFA}
\label{sec:split-d-cfa}


Next, the fit of the models developed on Split C will be tested on Splits A, B and D. Firstly, the TCQ factor structures will be compared. 



<<tcq6notdSem, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
Tcq6modelnotD <- mxModel(name="TCQ6notD", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notd)), type="cov", numObs=460))
tcq6fit.notD <- mxRun(Tcq6modelnotD)
tcq6summ.notD <- summary(tcq6fit.notD)
@ 

<<tcq7notDsem, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Confidence in Conventional Treatments")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
confconv <- c("Pill3", "Cream3", "Inj3")
Tcq7modelnotD <- mxModel(name="TCQ7notD", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Confidence in Conventional Treatments", to=confconv),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2notd)), type="cov", numObs=460))
tcq7fit.notD <- mxRun(Tcq7modelnotD)
tcq7summ.notD <- summary(tcq7fit.notD)
@ 

<<tcq2notDsemcompare, echo=FALSE, results=tex>>=
tcq2.notD.semcompare <- mxCompare(tcq6fit.notD, tcq7fit.notD)
print(xtable(tcq2.notD.semcompare, label="tab:tcq2notDsemcompare", caption="TCQ 2 Models built on Split D, tested against Splits A, B and C"))
@ 

It can be seen from Table \ref{tab:tcq2notDsemcompare} that the seven factor model from Split D provided a better fit to the out of sample data than did the 6 factor model. 





The next stage in  our analysis is to take the best of these models from each split and test them on the entire dataset. While this is, in a sense, analysing the data twice, it is the most practicable way in which to determine the best model for the entire sample. 

The best fitting models on the out of sample data were as follows:
\begin{itemize}
\item  Split A: Bam4, TCQ7

\item Split B: Bam2, TCQ7

\item Split C: Bam1, TCQ7

\item Split D: Bam1, TCQ7
\end{itemize}

Each of these models will be run on the full dataset, and the results assessed. The model which fits best on this sample will be used to predict factor scores for the experimental data. 

<<fullscales2, echo=FALSE, results=hide, cache=TRUE>>=
tcqall2 <- tcq2[,17:52]
bamall2 <- tcq2[,53:70]
@ 

<<tcq7notAsemAll, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Seven")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
seven <- c("Inj1", "Inj3")
Tcq7modelnotA.all <- mxModel(name="TCQ7notAAll", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Seven", to=seven),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2)), type="cov", numObs=594))
tcq7fit.notA.all <- mxRun(Tcq7modelnotA.all)
tcq7summ.notA.all <- summary(tcq7fit.notA.all)
@ 

<<bam4notAsemAll, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Medicine Avoidance", "NoLoad", "Medicine Effectiveness","Differences between Medicines", "Regular Taking of Medicines")
medavoid <- paste(Bam, c(6,7,8,9,12,13,14,17,18), sep="")
medeffect <- paste(Bam, c(1,3,4,10), sep="")
diffmed <- paste(Bam, c(1,2,7,10,11,16, 18), sep="")
regmed <- paste(Bam, 5, sep="")
bamnoload <- paste(Bam, 15, sep="")
Bam4modelnotA.all<- mxModel(name="Bam4notAAll", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Medicine Avoidance", to=medavoid),
                      mxPath(from="Medicine Effectiveness", to=medeffect),
                        mxPath(from="Differences between Medicines", to=diffmed),
                        mxPath(from="Regular Taking of Medicines", to=regmed),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamall2)), type="cov", numObs=671))
Bam4fitnotA.all <- mxRun(Bam4modelnotA.all)
Bam4asummnotA.all <- summary(Bam4fitnotA.all)
@ 


<<tcq7notBsemAll, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Confidence in Conventional Treatments")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
confconv <- c("Pill3", "Cream3", "Inj1", "Inj3")
Tcq7modelnotB.all <- mxModel(name="TCQ7notBAll", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Confidence in Conventional Treatments", to=confconv),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2)), type="cov", numObs=594))
tcq7fit.notB.all <- mxRun(Tcq7modelnotB.all)
tcq7summ.notB.all <- summary(tcq7fit.notB.all)
@ 

<<bam2notBsemAll, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Medicine Avoidance", "NoLoad", "Responsible Use of Medicines")
medavoid <- paste(Bam, c(3,4,6,7,8,9,10,11,12,13,14,17,18), sep="")
respmed <- paste(Bam, c(1,2,11,16,18), sep="")
bamnoload <- paste(Bam, c(5,15), sep="")
Bam2modelnotB.all <- mxModel(name="Bam2notBAll", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Medicine Avoidance", to=medavoid),
                      mxPath(from="Responsible Use of Medicines", to=respmed),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamall2)), type="cov", numObs=671))
Bam2fitnotB.all <- mxRun(Bam2modelnotB.all)
Bam2asummnotB.all <- summary(Bam2fitnotB.all)
@ 

<<tcq7notCsemAll, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Confidence in Conventional Treatments")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
confconv <- c("Pill3", "Inj1", "Inj3")
Tcq7modelnotC.all <- mxModel(name="TCQ7notCAll", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Confidence in Conventional Treatments", to=confconv),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2)), type="cov", numObs=594))
tcq7fit.notC.all <- mxRun(Tcq7modelnotC.all)
tcq7summ.notC.all <- summary(tcq7fit.notC.all)
@ 

<<bam1notCsemAll, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- c(bamitems.cols)
latents <- c("Beliefs About Medicine", "NoLoad")
Bamq <- paste(Bam, c(3,4,6,7,8,9,10,12,13,14,17, 18), sep="")
bamnoload <- paste(Bam, c(1,2,5,11,15,16), sep="")
Bam1modelnotC.all<- mxModel(name="Bam1notCAll", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Beliefs About Medicine", to=Bamq),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamall2)), type="cov", numObs=671))
Bam1fitnotC.all <- mxRun(Bam1modelnotC.all)
Bam1asumm.notC.all <- summary(Bam1fitnotC.all)
@ 

<<tcq7notDAllsemAll, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
Hom <- "Hom"
Rei <- "Rei"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
Homitems.cols <- paste(Hom, 1:6, sep="")
Reiitems.cols <- paste(Rei, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols, Homitems.cols, Reiitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Homeopathy", "Reiki", "Confidence in Conventional Treatments")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
hom <- paste(Hom, 1:6, sep="")
rei <- paste(Rei, 1:6, sep="")
confconv <- c("Pill3", "Cream3", "Inj3")
Tcq7modelnotD.all <- mxModel(name="TCQ7notDAll", 
                         type="RAM",
                         manifestVars=manifests,
                         latentVars=latents,
                         mxPath(from="Pills", to=pills), 
                         mxPath(from="Creams", to=creams),
                         mxPath(from="Injections", to=inj),
                         mxPath(from="Acupuncture", to=Acu),
                         mxPath(from="Homeopathy", to=hom),
                         mxPath(from="Reiki", to=rei),
                         mxPath(from="Confidence in Conventional Treatments", to=confconv),
                         mxPath(from=manifests, arrows=2),
                         mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                         mxData(observed=cov(na.omit(tcqall2)), type="cov", numObs=594))
tcq7fit.notD.all <- mxRun(Tcq7modelnotD.all)
tcq7summ.notD.all <- summary(tcq7fit.notD.all)
@ 

<<bam1notDsemAll, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- c(bamitems.cols)
latents <- c("Beliefs About Medicine", "NoLoad")
Bamq <- paste(Bam, c(1,2,3,4,6,7,8,9,10,13,14,17, 18), sep="")
bamnoload <- paste(Bam, c(5,11,12,15,16), sep="")
Bam1modelnotD.all<- mxModel(name="Bam1notDAll", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Beliefs About Medicine", to=Bamq),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotD)), type="cov", numObs=671))
Bam1fitnotD.all <- mxRun(Bam1modelnotD.all)
Bam1asumm.notD.all <- summary(Bam1fitnotD.all)
@

<<bamallsemcompare, echo=FALSE, results=tex>>=
bamall.semcompare <- mxCompare(Bam4fitnotA.all, c(Bam2fitnotB.all, Bam1fitnotC.all, Bam1fitnotD.all))
print(xtable(bamall.semcompare, label="tab:bamallsemcompare", caption="Best Model from Each Split tested against one another on the full dataset, Beliefs About Medicine Questionnaire"))
@ 

As can be seen from Table \ref{tab:bamallsemcompare}, the two factor model from Split B provided the best fit to all of the data, striking a balance between the complexity of the four factor model and the over simplicity of the one factor model. 

<<tcqall2semcompare, echo=FALSE, results=tex>>=
tcqall2.semcompare <- mxCompare(tcq7fit.notA.all, c(tcq7fit.notB.all, tcq7fit.notC.all, tcq7fit.notD.all))
print(xtable(tcqall2.semcompare, label="tab:tcqall2semcompare", caption="TCQ2 Models from each split tested against the full dataset Results"))
@ 

As can be seen from Table \ref{tab:tcqall2semcompare}, models B, C and D were identical and they appear to provide the best fit on all of the data. 

\subsection{IRT Analyses}
\label{sec:irt-analyses}

\subsubsection{Treatment Credibility Questionnaire}
\label{sec:treatm-cred-quest}


The next step in the analysis procedure was to examine the treatment credibility questionnaire in terms of item response theory. The same approach as taken for the factor analytic procedures was taken, such that seperate models were fitted on subsets of the data, and then tested against the out-of-sample data, before being finalised on the entire set of data. First, non-parametric IRT (or Mokken analysis) was applied to test the assumptions required for the parametric models. The analysis proper then began with the simplest of IRT models, the Rasch model, followed by a one parameter model with an estimated discrimination, followed by a two parameter model. 

\subsubsection{Split A}
\label{sec:split-a}



<<tcq2aitemselection, echo=FALSE, results=tex>>=
tcq.aisp <- aisp(na.omit(tcqall2a))
print(xtable(tcq.aisp, label="tab:tcq2aitemselection", caption="Item selection procedure, TCQ 2 Split A"))
@ 

As can be seen from Table \ref{tab:tcq2aitemselection}, the TCQ divides neatly into two scales, one for the conventional items and another for the alternative items. 

The next assumption to check was that of invariant item ordering, and the results are shown below.

<<tcq2asplitscales, echo=FALSE, results=hide, cache=TRUE>>=
tcq2a.conv <- tcqall2a[,1:18]
tcq2a.alt <- tcqall2a[,19:36]
@ 

<<tcq2aconvcheckiio, echo=FALSE, results=tex>>=
tcq2aconv.iio <- check.iio(na.omit(tcq2a.conv))
print(xtable(tcq2aconv.iio$violations, label="tab:tcq2aconvcheckiio", caption="Check of Item Ordering Assumptions, TCQ 2 Conventional Split A"))
@ 

It can be seen from Table \ref{tab:tcq2aconvcheckiio} that Pill4 and Pill6 violated the assumption of invariant item ordering. However, invariant item ordering is only necessary for restricted versions of the rating scale model and the graded response model, so this assumption is not as important in our case. That being said, the assumption was also investigated for the alternative items to allow for a minimal subset of items to be retained if restrictive models are to be fit later in the process. 

<<tcq2aaltitemord, echo=FALSE, results=tex>>=
tcq2aalt.iio <- check.iio(na.omit(tcq2a.alt))
print(xtable(tcq2aalt.iio$violations, label="tab:tcq2aaltcheckiio", caption="Item Ordering Assumption Check for TCQ Alternative, Split A"))
@ 
Table \ref{tab:tcq2aaltcheckiio} shows that in contrast to the conventional items, there were no violations of the IIO assumption for the alternative items. 

Next, the assumption of monotonicity was assesed for both scales. 

<<tcq2aconvmonotonicity, echo=FALSE, results=tex>>=
tcq2aconv.mono <- check.monotonicity(na.omit(tcq2a.conv))
print(xtable(summary(tcq2aconv.mono), label="tab:tcq2aconvmonotonicity", caption="Monotonicity Check Results for TCQ 2 Conventional, Split A"))
@ 
As can be seen from Table \ref{tab:tcq2aconvmonotonicity}, there were no violations of monotonicity for the conventional items in this split (the vi column is the most important here). 

<<tcq2aaltmonotonicity, echo=FALSE, results=tex>>=
tcq2aalt.mono <- check.monotonicity(na.omit(tcq2a.alt))
print(xtable(summary(tcq2aalt.mono), label="tab:tcq2aaltmonotonicity"))
@ 

As shown in Table \ref{tab:tcq2aaltmonotonicity}, there were no violations of the monotonicity assumption for the alternative items in this split either. 

<<tcq2aguttmanerrors, echo=FALSE, results=hide, cache=TRUE>>=
tcq2a.conv.errors <- check.errors(na.omit(tcq2a.conv))
tcq2a.alt.errors <- check.errors(na.omit(tcq2a.alt))
@ 

Guttman errors are interesting in that they can provide a quick measure of person fit. They have mostly been applied to dichotomous outcomes, but are examined in this work in order to check their adequacy as a measure of person fit. 



<<tcqconvguttmanplot, echo=FALSE, results=hide, cache=TRUE>>=
conv.guttman <- ggplot(as.data.frame(tcq2a.conv.errors), aes(x=tcq2a.conv.errors))+geom_histogram()

@   
\begin{figure}
  
<<tcqaltguttmanplot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
alt.guttman <- ggplot(as.data.frame(tcq2a.alt.errors), aes(x=tcq2a.alt.errors))+geom_histogram()
print(arrangeGrob(conv.guttman, alt.guttman))
@ 
  \caption{Guttman errors histogram for TCQ2A Conventional (top) and alternative (bottom) items}
  \label{fig:convaltguttman}
\end{figure}

As can be seen from Figure \ref{fig:convaltguttman}, the majority of participants had zero guttman errors, which indicates that they were responding to the scale in a coherent manner. 

The major assumptions of parametric IRT are satisfied for this split, and so the next step is the estimation of Rasch, One and Two parameter models. 

<<tcq2aconvgpcm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2a.conv.gpcm.rasch <- gpcm(na.omit(tcq2a.conv), constraint="rasch")
tcq2a.conv.gpcm.1pl <- gpcm(na.omit(tcq2a.conv), constraint="1PL")
tcq2a.conv.gpcm.gpcm <- gpcm(na.omit(tcq2a.conv), constraint="gpcm")
@ 
<<tcq2aconvsum, echo=FALSE, results=hide, cache=TRUE>>=
tcq2a.conv.rasch.sum <- summary(tcq2a.conv.gpcm.rasch)
tcq2a.conv.1pl.sum <- summary(tcq2a.conv.gpcm.1pl)
tcq2a.conv.2pl.sum <- summary(tcq2a.conv.gpcm.gpcm)
@ 

<<tcq2acoefrasch, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2a.conv.gpcm.rasch), label="tab:tcq2acoefrasch", caption="Coefficients for TCQ 2 Alternative Scale, Two parameter Generalised Partial Credit Model"))
@ 

Table \ref{tab:tcq2acoefrasch} shows the estimated thresholds for these items under the Rasch model, which has all discrimination parameters fixed to one. %% Even a cursory inspection of this table shows that the model does not fit well. 
The Category 3 estimates are almost all below the catgory 1 and 2 estimates, suggesting that those who responded using this category (the middle one) had the lowest estimated abilities. %% which is a clear violation of the model\'s assumptions. 
This can occur in PCM's, as the model uses a local comparison between thresholds, and so this does not necessitate that the model should be abandoned. 
Next, a one parameter IRT model is examined. 

<<tcq2acoefpcm1pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2a.conv.gpcm.1pl), label="tab:tcq2aconvcoef1pl", caption="Coefficients for TCQ2 Conventional One Parameter Generalised Partial Credit Model"))
@ 

Table ~\ref{tab:tcq2aconvcoef1pl} shows that a similiar issue arises using the one parameter model, with an estimated discrimination parameter of 1.531. %% This suggests that the model will need to be further expanded to allow for an acceptable fit. 

<<tcq2acoefgpcm, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2a.conv.gpcm.gpcm), label="tab:tcq2aconvcoef1pl", caption="Coefficients for TCQ2 (Split A), Conventional Scale, Two Parameter Generalised Partial Credit Model"))
@ 

Table ~\ref{tab:tcq2aconvcoef1pl} shows that even with a discrimination parameter estimated individually for each item, the generalised partial credit model still exhibits this behaviour with regards to Category C. It is possible that participants who tended to use this particular response category were using it as a default when they did not know how to answer. Next,  One and Two parameter Graded Response Models were fit to the same items.

<<tcq2convgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2a.conv.grm.1pl <- grm(na.omit(tcq2a.conv), constrained=TRUE)
tcq2a.conv.grm.2pl <- grm(na.omit(tcq2a.conv), constrained=FALSE)
@ 

<<tcq2aconvgrm1plsumm, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2a.conv.grm.1pl), label="tab:tcq2aconvgrm1plsumm", caption="Coefficients for TCQ 2 (Split A) Conventional Scale, One parameter Graded Response Model"))
@ 

As can be seen from Table ~\ref{tab:tcq2aconvgrm1plsumm}, the graded response model provides a much better fit to the data.  There are no obvious violations of the model assumptions, with an estimated discrimination parameter of 2.197. Note that the cream items are considered the most difficult, suggesting that this was the least credible form of conventional treatment.  The next model fit was a two parameter graded response model.  

<<tcq2aconvgrm1plsumm, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2a.conv.grm.2pl), label="tab:tcq2aconvgrm1plsumm", caption="Coefficients for TCQ 2 Conventional (Split A), Two Parameter Graded Response Model"))
@ 

Again, it can be seen from Table \ref{tab:tcq2aconvgrm1plsumm} that the Cream items appear to be the most discriminating, and possess the highest difficulty levels (on average).  
Both the pill and injection items seem to be endorsed by a much large proportion of the sample. This suggests that Cream Itemsappear to be the least credible treatment for pain. 

\begin{figure}
<<tcq2aconvgrm1plPlot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE, pdf=TRUE, png=TRUE>>=
print(ggplotGRM(tcq2a.conv.grm.1pl)+geom_rug())
@   
  \caption{Item Parameter Plot for TCQ2 (Split A). The Threshold parameter indicates the ability point where the next response becomes most likely. If the thresholds are not in order, this indicates a failure of montonicity}
  \label{fig:tcqcov2agrm1pl}
\end{figure}

A plot showing the threshold parameters for each of the items in the conventional model can be seen in Figure \ref{fig:tcqcov2agrm1pl}.

The same plot for the two parameter model can be seen in Figure \ref{fig:tcq2aconvgrm2pl}. 


\begin{figure}
<<tcq2aconvgrm2plPlot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
print(ggplotGRM(tcq2a.conv.grm.2pl))
@   
  \caption{Item Parameter Plot for TCQ2 (Split A). The Threshold parameter indicates the ability point where the next response becomes most likely. If the thresholds are not in order, this indicates a failure of montonicity}
  \label{fig:tcq2aconvgrm2pl}
\end{figure}

Another item parameter plot for the two parameter model is shown in Figure ~\ref{fig:tcq2aconvgrm2pl}, which again shows no obvious problems with the model. 


A likelihood ratio test was carried out for the two models, and the two parameter model appeared a better fit in terms of likelihood($p<0.001$), AIC and BIC. That being said, given the tradeoff in degrees of freedom (17), a better test will be the models accuracy on unseen data.

For models built on Split A, Splits B, C and D were used as a test set. 

The first check was to examine the fit of each of the partial credit models. %% Although none of these models met the assumptions of the model, they may still be useful in a predictive sense. 

<<tcq2aconvpcmtest, echo=FALSE, results=hide>>=
tcq2nota.conv <- tcq2nota[,c(17:34)]
tcq2a.pcm.rasch.done <- testIRTModels(tcq2a.conv.gpcm.rasch, tcq2nota.conv, gpcmconstraint="rasch", grmconstraint=NULL)
tcq2a.pcm.1PL.done <- testIRTModels(tcq2a.conv.gpcm.1pl, tcq2nota.conv, gpcmconstraint="1PL", grmconstraint=NULL)
tcq2a.pcm.gpcm.done <- testIRTModels(tcq2a.conv.gpcm.gpcm, tcq2nota.conv, gpcmconstraint="gpcm", grmconstraint=NULL)
@ 

<<pcmtestprint, echo=FALSE, results=tex, cache=TRUE>>=
tcq2a.pcm.modcomp <- rbind(tcq2a.pcm.rasch.done, tcq2a.pcm.1PL.done, tcq2a.pcm.gpcm.done)
rownames(tcq2a.pcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")


@ 
<<tcq2apcmmodcomprint, echo=FALSE, results=tex>>=
pcm.modcomp2a <- xtable(tcq2a.pcm.modcomp, caption="Partial Credit Models from Split A tested on Splits B, C and D", label="tab:pcmmodcomp2a")
print(pcm.modcomp2a)
@ 
As can be seen from Table \ref{tab:pcmmodcomp2a}, the one parameter PCM appears to provide the best predictive accuracy on the heldout data. The measure of error approximation used is essentially the root mean differences between the abilities estimated directly from the new sample versus those estimated from the parameters of the new model.

Next, the two graded response models were assessed. 

<<grmtest2a, echo=FALSE, results=hide, cache=TRUE>>=
tcq2a.grm.1pl.done <- testIRTModels(tcq2a.conv.grm.1pl, tcq2nota.conv, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2a.grm.2pl.done <- testIRTModels(tcq2a.conv.grm.2pl, tcq2nota.conv,gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2a.grm.done <- rbind(tcq2a.grm.1pl.done, tcq2a.grm.2pl.done)
rownames(tcq2a.grm.done) <- c("One Parameter GRM", "Two Parameter GRM")

@ 
<<tcq2agrmdone, echo=FALSE, results=tex>>=
tcq2a.grm.done.xtab <- xtable(tcq2a.grm.done, caption="Comparison of Split A Graded Response Models on Splits B, C and D", label="tab:grmdone2a")
print(tcq2a.grm.done.xtab)
@ 
Table \ref{tab:grmdone2a} shows that the one parameter model performed best on the unseen data, suggesting that the additional complexity of a two parameter model was not necessary in this sample. 


Next, the same process is repeated for the TCQ Alternative Scale for Split A. 

<<tcq2aaltpcm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2a.alt.gpcm.rasch <- gpcm(tcq2a.alt, constraint="rasch")
tcq2a.alt.gpcm.1PL <- gpcm(tcq2a.alt, constraint="1PL")
tcq2a.alt.gpcm.gpcm <- gpcm(tcq2a.alt, constraint="gpcm")
@ 

<<tcq2aaltgpcmrasch, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2a.alt.gpcm.rasch), caption="Estimated Coefficients for Rasch Partial Credit Model, TCQ2, Split A, Alternative Scale", label="tab:tcq2aaltgpcmrasch"))
@ 

It can be seen from Table \ref{tab:tcq2aaltgpcmrasch} that the estimated difficulty coefficients for the alternative scale are much higher than those for the conventional scale, which makes sense given that these are both less familiar, and less accepted treatments for pain. However, it as also apparent that these high difficulties are more a factor of the difficulty of the highest category more than anything else. The estimated thresholds for the other three categories are in line with those of the conventional scale, at least for acupuncture. It is possible that these difficulty levels may be lowered when a more flexible one parameter model is fit. 


<<tcq2aaltgpcm1pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2a.alt.gpcm.1PL), caption="Coefficient Estimates for One Parameter Partial Credit Model, TCQ2, Split A, Alternative Scale", label="tab:tcq2aaltgpcm1pl"), table.placement="ht")
@ 


Table \ref{tab:tcq2aaltgpcm1pl} shows that this did occur, as the discrimination parameter has increased to 1.852, while the average difficulty of the top threshold has noticeably dropped. Finally, a two parameter model was fit to this scale. It would be exepected that the discrimination parameters of Q4 in each scale will increase, while those of the Acupuncture questions will fall. 

<<tcq2aaltgpcm1pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2a.alt.gpcm.gpcm), caption="Coefficient Estimates for Two Parameter Partial Credit Model, TCQ2, Split A, Alternative Scale", label="tab:tcq2aaltgpcm2pl"), table.placement="ht")
@ 

As can be seen from Table \ref{tab:tcq2aaltgpcm2pl}, this prediction was partially fulfilled. While the discrimination parameter of the Acupuncture items lowered, the difficulty of the items rose to match. Additionally, the Reiki items now have extremely large discrimination parameters along with relatively high thresholds, suggesting that these are the items most predictive of high credibility. 



Next, one and two parameter Graded Response Models were applied to the TCQ Alternative for this split. 

<<tcq2aaltgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2a.alt.grm.1pl <- grm(tcq2a.alt, constrained=TRUE)
tcq2a.alt.grm.2pl <- grm(tcq2a.alt, constrained=FALSE)
@

<<tcq2agrm1pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2a.alt.grm.1pl), caption="Coefficients for TCQ Alternative (Split A) One Parameter Graded Response Model", label="tab:tcq2aaltgrm1pl"))
@ 

The coefficients for the one parameter graded response model for the alternative scale are shown in Table \ref{tab:tcq2aaltgrm1pl}. It can be seen that the estimated discrimination parameter is quite high, suggesting that all of these items are harder to endorse than those relating to conventional treatments. The Homeopathy and Reiki items tend to be harder to endorse than are the Acupuncture items. 


<<tcq2agrm2pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2a.alt.grm.2pl), caption="Coefficients for TCQ Alternative (Split A) Two Parameter Graded Response Model", label="tab:tcq2aaltgrm2pl"))
@ 

Table \ref{tab:tcq2aaltgrm2pl} shows the corresponding coefficients for the two parameter GRM. It can be seen that the difficulties for the homeopathy and reiki items have lowered, but their discrimination parameters have increased. 

The next step was to assess the performance of each of these models on unseen data. 

<<tcq2aaltgrmtest, echo=FALSE, results=hide, cache=TRUE>>=
tcq2nota.alt <- tcq2nota[,35:52]
tcq2a.alt.grm.1pl.done <- testIRTModels(tcq2a.alt.grm.1pl, tcq2nota.alt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2a.alt.grm.2pl.done <- testIRTModels(tcq2a.alt.grm.2pl, tcq2nota.alt, gpcmconstraint=NULL, grmconstraint=FALSE)
tcq2a.grm.modcomp <- rbind(tcq2a.alt.grm.1pl.done, tcq2a.alt.grm.2pl.done)
rownames(tcq2a.grm.modcomp) <- c("One Parameter GRM", "Two Parameter GRM")

@ 
<<tcqconv2agrmtestprint, echo=FALSE, results=tex>>=
print(xtable(tcq2a.grm.modcomp, caption="Performance of Split A Graded Response Models TCQ Alternative on Splits B, C and D", label="tab:tcq2aaltgrmmodcomp"))
@ 
As can be seen from Table \ref{tab:tcq2aaltgrmmodcomp}, the one parameter model performed significantly better on the unseen data. 

Next, the beliefs about medicine questionnaire was examined in terms of item response theory.

<<bam2ascales, echo=FALSE, results=tex>>=
bam2a.scales <- aisp(na.omit(bamall2a))
print(xtable(bam2a.scales, label="tab:bam2ascales", caption=" Item Scale Analysis  for Beliefs About Medicine Questionnaire, IRT scale, Split A"))
@ 

It can be seen from Table ~\ref{tab:bam2ascales} that many items on the beliefs about medicine questionnaire do not appear to be part of any scale (indicated by the zeros next to the item number). The algorithm suggests that there are two scales.

The first is made up of BAM6, BAM7, BAM9, BAM13, BAM14 and BAM17.
The second is made up of BAM4 and BAM10. This second scale appears to be less than useful, as some of the other tests of assumptions require at least three items per scale. The approach taken here will be to eliminate all but the first scale and conduct our analyses on that set of six items.

<<bam2areduce, echo=FALSE, results=hide, cache=TRUE>>=
bam2ascale <- bamall2a[,c("BAM6","BAM7","BAM9","BAM13","BAM14","BAM17")]
## bam2ascale.other <- bamall2a[,!c("BAM6","BAM7","BAM9","BAM13","BAM14","BAM17")]
@ 

The next step is to check the assumption of invariant item ordering. This is less important here, but is checked for the sake of completeness. 

<<bam2aiio, echo=FALSE, results=tex>>=
bam2a.iio <- check.iio(na.omit(bam2ascale))
print(xtable(bam2a.iio$violations, label="tab:bam2aiio", caption="Item Ordering Assumption Check for Reduced Beliefs About Medicine Questionnaire, Split A"))
@ 

As can be seen from Table ~\ref{tab:bam2aiio}, no items violated the invariant item ordering assumption, and so are are retained until the next stage. The next step is to check the assumption of monotonicity.

<<bam2acheckmono, echo=FALSE, results=tex>>=
bam2a.mono <- check.monotonicity(na.omit(bam2ascale))
print(xtable(summary(bam2a.mono), label="tab:bam2amono", caption="Monotonicity Check, Beliefs About Medicine Questionnaire, Split A"))
@ 

Table \ref{tab:bam2amono} shows that there were no violations of monotonicity in this split for the reduced set of items. 

The next step in our analysis plan is to fit a rasch model to the beliefs about medicine scale. 

<<bam2agpcm, echo=FALSE, results=hide, cache=TRUE>>=
bam2a.gpcm.rasch <- gpcm(bam2ascale, constraint="rasch")
bam2a.gpcm.1PL <- gpcm(bam2ascale, constraint="1PL")
bam2a.gpcm.gpcm <- gpcm(bam2ascale, constraint="gpcm")
@ 

<<bam2arasch, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2a.gpcm.rasch)), label="tab:bam2arasch", caption="Coefficients for Beliefs About Medicine Questionnaire, Rasch partial credit model"))
@ 

As can be seen from Table ~\ref{tab:bam2arasch}, this model shows problems typical to the PCM of the middle category having a lower estimated ability threshold than do the categories to either side. Nonetheless, it can be seen that BAM9, ``It is better to do without medicines'' has the highest thresholds, followed by 17, ``Doctors use too many medicines'', which makes sense as these questions are more absolutist than many of the others. 

We next examine the fit of a one paramater generalised partial credit model with a discrimination parameter estimated from the data. 

<<bam2a1PL, echo=FALSE, results=tex>>=

print(xtable(coef2mat(coef(bam2a.gpcm.1PL)), label="tab:bam2a1PL", caption="Coefficients for Beliefs About Medicine Questionnaire, One parameter Generalised Partial Credit Model"))
@ 

Again, Table \ref{tab:bam2a1PL} makes it very clear that the one parameter GPCM provides little advantage over the Rasch model, in that the estimated difficulties are very similar and the discrimination parameter has not moved very much. 

Next, the fit of a two parameter GPCM to this scale was examined. 

<<bam2agpcm, echo=FALSE, results=tex>>=

print(xtable(coef2mat(coef(bam2a.gpcm.gpcm)), label="tab:bam2agpcm", caption="Coefficients for Beliefs About Medicine Questionnaire, Split A, Two Parameter Generalised Partial Credit Model"))
@ 
It can be clearly seen from Table ~\ref{tab:bam2agpcm} that the two parameter GPCM provides a more interesting picture. Again, 7 is the most difficult, but has a very low discrimination parameter, suggesting that it is relatively poor at clustering high and low scorers on the scale. However, 17 has lowered its difficulties, but shows much better discrimination. 

In line with previous practice, the next models fit were the one and two parameter graded response models. 

<<bam2agrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2a.grm.1pl <- grm(na.omit(bam2ascale), constrained=TRUE)
bam2a.grm.2pl <- grm(na.omit(bam2ascale), constrained=FALSE, Hessian=TRUE)
@ 

<<bam2agrm1pl, echo=FALSE, results=tex>>=

bam2acoef.mat <- coef2mat(coef(bam2a.grm.1pl))
print(xtable(bam2acoef.mat, label="tab:bam2agrm1pl", caption="Coefficients for Beliefs About Medicine Questionnaire, Split A, One parameter Graded Response Model"))
@ 

It can be seen from Table \ref{tab:bam2agrm1pl} that the fit of this model is much better that the fit of any of the partial credit models. 

The next step is to fit a two parameter GRM, and examine the differences in fit between the two models. 

<<bam2agrm2pl, echo=FALSE, results=tex>>=

bam2acoef.mat <- coef2mat(coef(bam2a.grm.2pl))
print(xtable(bam2acoef.mat, label="tab:bam2agrm2pl", caption="Coefficients for Beliefs About Medicine Questionnaire, Split A, Two parameter Graded Response Model"))
@ 

It can be seen from Table \ref{tab:bam2agrm2pl} that this model reveals some interesting features of the items. BAM13 and BAM17 have the highest discrimination parameters, but the ability estimates of their extremities have moved down to compensate. 

A likelihood ratio test carried out between the two models suggested that the two parameter model was significantly better than the one parameter model, ($p\le 0.001$). Again, this is a tentative result until the performance of the model on new data is examined. In any case, while both the AIC and the LR test favoured the two parameter model, the BIC was lower for the one parameter model indicating that according to this criterion, the one parameter model was superior. 

Next, the performance of all the Beliefs About Medicine Models was assessed on unseen data (Splits B, C and D). 

<<bampcmtest, echo=FALSE, results=tex, cache=TRUE>>=
bamnota.irt <-  tcq2nota[,c("BAM6","BAM7","BAM9","BAM13","BAM14","BAM17")]
bam2a.pcm.rasch.done <- testIRTModels(bam2a.gpcm.rasch, bamnota.irt, gpcmconstraint="rasch", grmconstraint=NULL)
bam2a.pcm.1pl.done <- testIRTModels(bam2a.gpcm.1PL, bamnota.irt, gpcmconstraint="1PL", grmconstraint=NULL)
bam2a.pcm.gpcm.done <- testIRTModels(bam2a.gpcm.gpcm, bamnota.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
bam2a.pcm.modcomp <- rbind(bam2a.pcm.rasch.done, bam2a.pcm.1pl.done, bam2a.pcm.gpcm.done)
rownames(bam2a.pcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")

@ 
<<bam2apcmmodcompprint, echo=FALSE, results=tex>>=
bam2a.pcm.modcomp.xtab <- xtable(bam2a.pcm.modcomp, caption="Partial Credit Models for BAM Scale from Split A Performance on Heldout Data", label="tab:bam2apcmmodcomp")
print(bam2a.pcm.modcomp.xtab)
@ 
From Table \ref{tab:bam2apcmmodcomp} it can be seen that the rasch model provided the best performance on unseen data. 

Next, the performance of the graded response models on unseen  data was assessed. 

<<bam2agrmtest, echo=FALSE, results=tex, cache=TRUE>>=
## bam2a.test <- bamnota.irt[,2:length(bamnota.irt)]
## bam2a.grm.1pl.done <- testIRTModels(bam2a.grm.1pl, bam2a.test)
@ 
%fix split A levels problem

\subsubsection{Split B}
\label{sec:split-b}

The next task was to repeat the analyses on Split B. The TCQ was the instrument first examined in this split, in line with previous work.

Again, the first step is to examine whether or not the TCQ should be split into seperate scales, examine the monotonicity, the invariant item ordering assumption and examine a plot of Guttman errors. 

<<tcq2baisp, echo=FALSE, results=tex>>=
tcq2b.aisp <- aisp(na.omit(tcqall2b))
print(xtable(tcq2b.aisp, label="tab:tcq2baisp", caption="Item Selection Procedure for TCQ 2, Split B"))
@ 

As can be seen from Table ~\ref{tab:tcq2baisp}, the scales split along alternative and conventional lines, as in Split A. All further analyses will be carried out on the seperate scales. 

<<tcq2bsplitscales, echo=FALSE, results=hide, cache=TRUE>>=
tcq2b.conv <- tcqall2b[,1:18]
tcq2b.alt <- tcqall2b[,19:36]
@ 

The first step in the examination of the tcq conventional in split B is to check the IIO assumption. 

<<tcq2bcheckiio, echo=FALSE, results=tex>>=
tcq2b.conv.iio <- check.iio(na.omit(tcq2b.conv))
print(xtable(tcq2b.conv.iio$violations, label="tab:tcq2bcheckiio", caption="Item Ordering Assumption Check, TCQ 2 Conventional, Split B"))
@ 

As can be seen from Table \ref{tab:tcq2bcheckiio}, there were no violations of this assumption. 

Next the assumption of montonicity was checked. 

<<tcq2bconvcheckmono, echo=FALSE, results=tex>>=
tcq2b.conv.mono <- check.monotonicity(na.omit(tcq2b.conv))
print(xtable(summary(tcq2b.conv.mono), label="tab:tcq2bconvcheckmono", caption="Monotonicity Check, TCQ2 Conventional (Split B)"))
@ 

As shown in Table \ref{tab:tcq2bconvcheckmono}, there were no violations of the monotonicity assumption in this split.

This process of repeating assumptions is then repeated for the alternative question TCQ for Split B.

<<tcq2baltcheckiio, echo=FALSE, results=tex>>=
tcq2b.alt.iio <- check.iio(na.omit(tcq2b.alt))
print(xtable(tcq2b.alt.iio[["violations"]], label="tab:tcq2baltcheckiio", caption="Item Ordering Check TCQ2 Alternative (Split B)"))
@ 

As can be seen from Table \ref{tab:tcq2baltcheckiio}, there were no violations of the invariant item ordering assumption in this split. Next, the monotonicity assumption was assessed. 

<<tcq2baltcheckmono, echo=FALSE, results=tex>>=
tcq2b.alt.mono <- check.monotonicity(na.omit(tcq2b.alt))
print(xtable(summary(tcq2b.alt.mono), label="tab:tcq2baltcheckmono", caption="Monotonicity Check for TCQ 2, Alternative (Split B)"))
@ 

As shown from Table \ref{tab:tcq2baltcheckmono}, there were no violations of the montonicity assumption in this sample. 

Next, a series of partial credit models were fit and checked for violations of the assumptions. 

<<tcq2bconvgpcm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2b.conv.gpcm.rasch <- gpcm(tcq2b.conv, constraint="rasch")
tcq2b.conv.gpcm.1PL <- gpcm(tcq2b.conv, constraint="1PL")
tcq2b.conv.gpcm.gpcm <- gpcm(tcq2b.conv, constraint="gpcm")
@ 

\begin{figure}
<<tcq2bconvgpcmraschplot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
gpcm.rasch.plot <- ggplotGRM(tcq2b.conv.gpcm.rasch)
print(gpcm.rasch.plot)
@   
  \caption{Item Parameter Plot for TCQ2B Conventional GPCM Rasch}
  \label{fig:tcq2bconvgpcmrasch}
\end{figure}

 Figure \ref{fig:tcq2bconvgpcmrasch} shows the fit of the Rasch generalised partial credit model. Note that the model estimates the thresholds to be almost identical for categories two and three, which is surprising but not necessarily fatal to the fit of the model. 

\begin{figure}
<<tcq2bconvgpcm1PLplot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
gpcm.1PL.plot <- ggplotGRM(tcq2b.conv.gpcm.1PL)
print(gpcm.1PL.plot)
@   
  \caption{Item Parameter Plot for TCQ2B Conventional GPCM}
  \label{fig:tcq2bconvgpcm1PLplot}
\end{figure}

Next, the fit of the one parameter GPCM was examined using an Item Parameter Plot (Figure \ref{fig:tcq2bconvgpcm1PLplot}). 
%% It can be seen that there are failures of the monotonicity assumption for Inj6, Inj2, Inj5, Inj1, Cream6, Cream5, Cream4, Cream2, Cream1, Pill6, Pill5, Pill4, Pill3, Pill2 and Pill1. In fact, most of the 2 and 3 thresholds are reversed, demonstrating that this model is not a good fit for the data. 


\begin{figure}
<<tcq2bconvgpcmgpcmplot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
gpcm.gpcm.plot <- ggplotGRM(tcq2b.conv.gpcm.gpcm)
print(gpcm.gpcm.plot)
@   
  \caption{Item Position Plot for Two Parameter GPCM (Split B)}
  \label{fig:tcq2bconvgpcm2plplot}
\end{figure}

As shown in Figure \ref{fig:tcq2bconvgpcm2plplot}, there are some failures of monotonicity here. Inj6, In5, Inj4, Inj3, Inj2, Inj1, Cream2, Cream1, Pill6, Pill5, Pill4, Pill3, Pill2 and Pill1. 

<<tcq2bconvpcmraschprint, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2b.conv.gpcm.rasch), caption="Coefficient Estimates, TCQ2 Conventional, Split B for Rasch Partial Credit Model", label="tab:tcq2bpcmrasch"))
@ 

As can be seen from Table \ref{tab:tcq2bpcmrasch}, the issues with category three are apparent again with this split, suggesting that it was being used as a default response choice by many of the participants. Again, the cream items have the highest thresholds, while the Injection items have the lowest. 

Next, we examine the coefficients for a one parameter PCM. 

<<tcq2bconvpcm1plprint, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2b.conv.gpcm.1PL), caption="Coefficient Estimates, TCQ2 Conventional, Split B for One Parameter Partial Credit Model", label="tab:tcq2bpcm1pl"))
@ 

Table \ref{tab:tcq2bpcm1pl} shows a similar pattern to the Rasch model, with the discrimination parameter having increased somewhat while the item thresholds have decreased somewhat. Again, the category three pattern is clearly apparent. 

Finally, the ability estimates and discrimination parameters for the two parameter model were examined. 

<<tcq2bconvpcm2plprint, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2b.conv.gpcm.gpcm), caption="Coefficient Estimates, TCQ2 Conventional, Split B for Two Parameter Partial Credit Model", label="tab:tcq2bpcm2pl"))
@ 

Table \ref{tab:tcq2bpcm2pl} shows the fit estimates for the two parameter model. As can be seen, the cream items have the highest estimated discrimination parameters, while those for the injection items have lowered considerably. 

As none of the partial credit model fitted the items, the next step was to examine the fit of the one and two parameter graded response models. 

<<tcq2bconvgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2b.conv.grm.1pl <- grm(tcq2b.conv, constrained=TRUE)
tcq2b.conv.grm.2pl <- grm(tcq2b.conv, constrained=FALSE)
@ 


\begin{figure}
<<tcq2bconvgrm1plot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2convgrm1plot <- ggplotGRM(tcq2b.conv.grm.1pl)
print(tcq2convgrm1plot)
@   
  \caption{Item Parameter Plot for TCQ Conventional 1 parameter Graded Response Model (Split B)}
  \label{fig:tcq2bconvgrm1plot}
\end{figure}

As shown in Figure \ref{fig:tcq2bconvgrm1plot}, there were no violations of monotonicity for the one parameter GRM. 

<<tcq2bconvgrm1plsumm, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2b.conv.grm.1pl), label="tab:tcq2bconvgrm1plsumm", caption="Coefficients for TCQ 2 Conventional (Split B), One parameter Graded Response Model"))
@ 

Table \ref{tab:tcq2bconvgrm1plsumm} shows that the cream items were the least endorsed, especially the highest response category. The estimated discrimination parameter is also quite high, at 2.08. This is probably due to a number of difficult items (the cream ones probably) dragging up the estimated discrimination parameter. 

\begin{figure}
<<tcq2bconvgrm2plot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2convgrm2plot <- ggplotGRM(tcq2b.conv.grm.2pl)
print(tcq2convgrm2plot)
@   
  \caption{Item Parameter Plot for TCQ Conventional 2 parameter Graded Response Model (Split B)}
  \label{fig:tcq2bconvgrm2plot}
\end{figure}
@ 

As can be seen from Figure \ref{fig:tcq2bconvgrm2plot}, there were no violations of monotonicity for the two parameter GRM. 

<<tcq2bconv2plgrmsum, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2b.conv.grm.2pl), label="tab:tcq2bconv2plgrmsum", caption="Coefficients for TCQ 2 Conventional (Split B) Two Parameter Graded Response Model"))
@ 

As can be seen from Table \ref{tab:tcq2bconv2plgrmsum}, the discrimination parameters have lowered for most of the items, with the exception of Pill4, Pill5 and Pill6, where they have significantly increased. This is surprising, as the Cream items have much higher difficulty, but lower discrimination between different ability levels. 

Finally, the predictive power of each of these models was assessed, beginning with the partial credit models. 

<<tcq2bmodtest, echo=FALSE, results=tex, cache=TRUE>>=
tcqconv.notb <- tcq2notb[,17:34]
tcq2b.pcm.rasch.done <- testIRTModels(tcq2b.conv.gpcm.rasch, tcqconv.notb, gpcmconstraint="rasch", grmconstraint=NULL)
tcq2b.pcm.1pl.done <- testIRTModels(tcq2b.conv.gpcm.1PL, tcqconv.notb, gpcmconstraint="1PL", grmconstraint=NULL)
tcq2b.pcm.gpcm.done <- testIRTModels(tcq2b.conv.gpcm.gpcm, tcqconv.notb, gpcmconstraint="gpcm", grmconstraint=NULL)
tcq2b.pcm.modcomp <- rbind(tcq2b.pcm.rasch.done, tcq2b.pcm.1pl.done, tcq2b.pcm.gpcm.done)

@ 
<<tcq2bpcmmodcompprint, echo=FALSE, results=tex>>=
tcq2b.pcm.modcomp.xtab <- xtable(tcq2b.pcm.modcomp, caption="Comparison of Splt B TCQ Conventional Scale Partial Credit Models on Splits A, C and D", label="tab:tcq2bpcmmodcomp")
print(tcq2b.pcm.modcomp.xtab)
@ 
As can be seen from Table \ref{tab:tcq2bpcmmodcomp}, the one parameter PCM model performed best on the unseen data, suggesting that the minimal flexibility allowed by the discrimination parameter was enough for an effective model. 

Next, this process is repeated for the graded response models. 

<<tcq2bgrmtest, echo=FALSE, results=tex, cache=TRUE>>=
tcq2b.grm.1pl.done <- testIRTModels(tcq2b.conv.grm.1pl, tcqconv.notb, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2b.grm.2pl.done <- testIRTModels(tcq2b.conv.grm.2pl, tcqconv.notb, gpcmconstraint=NULL, grmconstraint=FALSE)
tcq2b.grm.modcomp <- rbind(tcq2b.grm.1pl.done, tcq2b.grm.2pl.done)

@ 
<<tcq2bgrmmodcomp, echo=FALSE, results=tex>>=
tcq2b.grm.modcomp.xtab <- xtable(tcq2b.pcm.modcomp, caption="Performance of TCQ Conventional Graded Response Models from Split B, tested on Splits A, C and D", label="tab:tcq2bgrmmodcomp")
print(tcq2b.grm.modcomp.xtab)
@ 

As shown in Table \ref{tab:tcq2bgrmmodcomp}, the one parameter Graded Response Model provided the best performance on unseen data. 

Next, the same model fitting and testing procedure was applied to the Alternative Scale for Split B. 

<<tcq2baltpcm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2b.alt.gpcm.rasch <- gpcm(tcq2b.alt, constraint="rasch")
tcq2b.alt.gpcm.1PL <- gpcm(tcq2b.alt, constraint="1PL")
tcq2b.alt.gpcm.gpcm <- gpcm(tcq2b.alt, constraint="gpcm")
@ 

<<tcq2baltpcmraschprint, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2b.alt.gpcm.rasch), caption="Coefficient Estimates for Rasch Partial Credit Model, Split B, TCQ Conventional", label="tab:tcq2baltpcmrasch"))
@ 

Table \ref{tab:tcq2baltpcmrasch} shows that similarly to the pattern seen in Split A, the Homeopathy and Reiki items possessed much higher thresholds than did the acupuncture items, but all three had higher thresholds than did the conventional items. 

Next, the coefficients for the one parameter PCM are examined. 

<<tcq2baltpcm1plprint, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2b.alt.gpcm.1PL), caption="Coefficient Estimates for One Parameter Partial Credit Model, Split B, TCQ Conventional", label="tab:tcq2baltpcm1pl"))
@ 

Table \ref{tab:tcq2baltpcm1pl} shows that the discrimination parameter has increased by quite a large amount, while the abilities have lowered to compensate for this change. 

Finally, the estimated two parameter PCM was examined. 

<<tcq2baltpcm2plprint, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2b.alt.gpcm.gpcm), caption="Coefficient Estimates for Two Parameter Partial Credit Model, Split B, TCQ Conventional", label="tab:tcq2baltpcmgpcm"))
@

Table \ref{tab:tcq2baltpcmgpcm} shows the estimated coefficients for the two parameter model. It can be seen that the estimated discrimination parameters are much less extreme than those from Split A, and that for this split, the Homeopathy items are the most discriminating, but nonetheless the relationships between the Acupuncture items and the Homeopathy and Reiki items appears to be quite similar. 


<<tcq2baltgrmtest, echo=FALSE, results=tex, cache=TRUE>>=
tcq2notb.alt.irt <- tcq2notb[,35:52]
tcq2b.alt.gpcm.rasch.done <- testIRTModels(tcq2b.alt.gpcm.rasch, tcq2notb.alt.irt, gpcmconstraint="rasch", grmconstraint=NULL)
tcq2b.alt.gpcm.1pl.done <- testIRTModels(tcq2b.alt.gpcm.1PL, tcq2notb.alt.irt, gpcmconstraint="1PL", grmconstraint=NULL)
tcq2b.alt.gpcm.gpcm.done <- testIRTModels(tcq2b.alt.gpcm.gpcm, tcq2notb.alt.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
tcq2b.alt.gpcm.modcomp <- rbind( tcq2b.alt.gpcm.rasch.done,tcq2b.alt.gpcm.1pl.done, tcq2b.alt.gpcm.gpcm.done)
rownames(tcq2b.alt.gpcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")

@ 
<<tcq2baltpcmmodcompprint, echo=FALSE, results=tex>>=
print(xtable(tcq2b.alt.gpcm.modcomp, caption="Performance of Split B TCQ Alternative Partial Credit Models on Splits B, C and D", label="tab:tcq2baltgpcmmodcomp"))
@ 
As can be seen from Table \ref{tab:tcq2baltgpcmmodcomp}, the one parameter PCM provided the best fit to the unseen data. 


Next, two graded response models were fit to the data. 

<<tcq2baltgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2b.alt.grm.1pl <- grm(tcq2b.alt, constrained=TRUE)
tcq2b.alt.grm.2pl <- grm(tcq2b.alt, constrained=FALSE)
@ 
<<tcq2baltgrm1pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2b.alt.grm.1pl), label="tab:tcq2bconv1plgrmsum", caption="Coefficients for TCQ 2 Conventional (Split B) One Parameter Graded Response Model"))
@


In Table \ref{tab:tcq2bconv1plgrmsum} are shown the coefficient estimates for the one parameter alternative scale graded response model for split B.

It can be seen that the ability estimates are extremely low, while the discrimination parameter is far higher than was seen in Split A. 

<<tcq2baltgrm2pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2b.alt.grm.2pl), label="tab:tcq2bconv2plgrmsum", caption="Coefficients for TCQ 2 Conventional (Split B) Two Parameter Graded Response Model"))
@

Table \ref{tab:tcq2bconv2plgrmsum} shows the corresponding coefficient estimates for the two parameter GRM. It can be seen that the discrimination parameter has lowered significantly, while the ability estimates have risen to counter balance this.

Next, each of these models performance was assessed on unseen data. 

<<tcq2baltgrmtest, echo=FALSE, results=tex, cache=TRUE>>=
tcq2notb.alt.irt <- tcq2notb[,35:52]
tcq2b.alt.grm.1pl.done <- testIRTModels(tcq2b.alt.grm.1pl, tcq2notb.alt.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2b.alt.grm.2pl.done <- testIRTModels(tcq2b.alt.grm.2pl, tcq2notb.alt.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2b.alt.grm.modcomp <- rbind(tcq2b.alt.grm.1pl.done, tcq2b.alt.grm.2pl.done)
rownames(tcq2b.alt.grm.modcomp) <- c("One Parameter GRM", "Two Parameter GRM")

@ 
<<tcq2baltgrmmodcomp, echo=FALSE, results=tex>>=
print(xtable(tcq2b.alt.grm.modcomp, caption="Performance of Split B TCQ Alternative Graded Response Model on Splits B, C and D", label="tab:tcq2baltgrmmodcomp"))
@ 
As shown in Table \ref{tab:tcq2baltgrmmodcomp}, the two parameter model provided a better approximation to the unseen data. 

The same model fitting procedure will now be repeated for the Beliefs About Medicine Questionnaire in this split. 

<<bam2baisp, echo=FALSE, results=tex>>=
bam2b.aisp <- aisp(na.omit(bamall2b))
print(xtable(bam2b.aisp, label="tab:bam2baisp", caption="Item Selection Procedure for Beliefs About Medicine Questionnaire, Split B"))
@ 

As shown in Table \ref{tab:bam2baisp}, some items do not load on any scales, and there is one two item scale (BAM1 and BAM2), along with one larger scale. As two items are not enough to form a useful scale, the larger scale will be the only one which is analysed. 

The scale that will be analysed consists of BAM3, BAM4, BAM6, BAM9, BAM10, BAM11, BAM13, BAM14 and BAM17. This is a larger scale than was observed with Split A. 

<<bamscale2b,echo=FALSE, results=hide>>=
bamscale2b <- bamall2b[,c("BAM3","BAM4","BAM6","BAM9","BAM10","BAM11","BAM13","BAM14", "BAM17")]
@ 

The first step is to examine the invariant item ordering assumption.

<<bam2checkiio, echo=FALSE, results=tex>>=
bam2b.iio <- check.iio(na.omit(bamscale2b))
print(xtable(bam2b.iio$violations, label="tab:bam2checkiio", caption="Item Ordering Assumption Check for Beliefs About Medicine Scale, Split B"))
@ 

In line with the results of Split A, no items were in violation of this assumption. 

The next assumption which needs to be checked is the monotonicity assumption. 

<<bam2bcheckmono, echo=FALSE, results=tex>>=
bam2b.mono <- check.monotonicity(na.omit(bamscale2b))
print(xtable(summary(bam2b.mono), label="tab:bam2bcheckmono", caption="Monotonicity Check, Beliefs About Medicine Scale, Split B"))
@ 

Table \ref{tab:bam2bcheckmono} shows clearly that there were no violations of the monotonicity assumption in this sample. 

The final preliminary model check consists of a plot displaying the number of Guttman errors for each participant.
\begin{figure}
<<bam2bguttman, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
bam2b.guttman <- check.errors(na.omit(bamscale2b))
bam2b.guttplot <- ggplot(as.data.frame(bam2b.guttman), aes(x=bam2b.guttman))+geom_histogram(binwidth=2)
print(bam2b.guttplot)
@   
  \caption{Plot of Guttman errors for Beliefs about Medicine Scale, Split B}
  \label{fig:bam2bguttmanplot}
\end{figure}

As can be seen from Figure \ref{fig:bam2bguttmanplot}, the number of guttman errors was much higher for this scale than was observed in the previous split. This suggests that some of the respondents were not answering the questions in a consistent fashion, and will be investigated further when the person fit statistics are examined on a per model basis. 

The first step in modelling the Beliefs about Medicines questionnaire is to attempt to fit a Rasch partial credit model.

<<bam2bgpcm, echo=FALSE, results=hide, cache=TRUE>>=
bam2b.gpcm.rasch <- gpcm(bamscale2b, constraint="rasch")
bam2b.gpcm.1PL <- gpcm(bamscale2b, constraint="1PL")
bam2b.gpcm.gpcm <- gpcm(bamscale2b, constraint="gpcm")
@ 





The estimated parameters for the Rasch model are shown  in Table \ref{tab:bam2bgpcmrasch}. 


<<bam2bgpcmrasch, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2b.gpcm.rasch)), label="tab:bam2bgpcmrasch", caption="Coefficients for Beliefs About Medicine Questionnaire, Split B, Rasch generalised Partial Credit Model"))
@ 

It can be seen from Table \ref{tab:bam2bgpcmrasch} that the Rasch PCM has thresholds in line with those of the conventional item TCQ, and that Q6 is regarded as the most difficult, which is not surprising given the content of the item ``Medicines often do more harm than good''. 

Next, the coefficients are examined for a one parameter PCM on this scale. 


<<bam2bgpcm1pl, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2b.gpcm.1PL)), label="tab:bam2bgpcm1pl", caption="Coefficients for Beliefs About Medicine Questionnaire, Split B, One Parameter Generalised Partial Credit Model"))
@ 

Table \ref{tab:bam2bgpcm1pl} shows the estimated coefficients for this model. It can be seen that there are no major changes from the Rasch model, the discrimination parameter has lowered, but the ability thresholds have risen slightly, most noticeably in the case of BAM6. 


Finally, the fit of a two parameter PCM was examined.

<<bam2bgpcmgpcm, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2b.gpcm.gpcm)), label="tab:bam2bgpcm2pl", caption="Coefficients for Beliefs About Medicine Questionnaire, Split B, Two Parameter Generalised Partial Credit Model"))
@ 

Table \re{tab:bam2bgpcm2pl} shows the results of this fit. It can be seen that the discrimination parameters of items 6, 13,14 and 17 have markedly increased, while those of the other items have lowered slightly. 

The next step in the process of modelling was to fit one and two parameter Graded Response Models. 

<<bam2bgrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2b.grm.1pl <- grm(bamscale2b, constrained=TRUE)
bam2b.grm.2pl <- grm(bamscale2b, constrained=FALSE)
@ 

<<bam2bgrm1sum, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2b.grm.1pl)), label="tab:bam2bgrm1sum", caption="Coefficients for Beliefs About Medicine Questionnaire, Split B, One Parameter Graded Response Model"))
@ 

Table \ref{tab:bam2bgrm1sum} shows no signs of problems with monotonicity, and the fit appears acceptable. Next, the two parameter GRM was examined.

<<bam2bgrm2sum, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2b.grm.2pl)), label="tab:bam2bgrm2sum", caption="Coefficients for Beliefs About Medicine Questionnaire, Two parameter Graded Response Model"))
@ 

Table \ref{tab:bam2bgrm2sum} shows that the fit of the two parameter model is equally unproblematic. 

<<bam2banovagrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2bgrm.anova <- anova(bam2b.grm.1pl, bam2b.grm.2pl)
@ 

A likelihood ratio test suggests that the two parameter model provides a significantly better fit ($p \le 0.001$) than does the one parameter model. 


Finally, the performance of each of the different types of IRT models on unseen data was assessed. 

<<bam2bpcmmodtest, echo=FALSE, results=tex, cache=TRUE>>=
bamnotb.irt <- tcq2notb[,c("BAM3", "BAM4", "BAM6", "BAM9", "BAM10", "BAM11", "BAM13", "BAM14", "BAM17")]
bam2b.gpcm.rasch.done <- testIRTModels(bam2b.gpcm.rasch,  bamnotb.irt, gpcmconstraint="rasch", grmconstraint=NULL)
bam2b.gpcm.1PL.done <- testIRTModels(bam2b.gpcm.1PL, bamnotb.irt, gpcmconstraint="1PL", grmconstraint=NULL)
bam2b.gpcm.gpcm.done <- testIRTModels(bam2b.gpcm.gpcm, bamnotb.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
bam2b.gpcm.modcomp <- rbind(bam2b.gpcm.rasch.done, bam2b.gpcm.1PL.done, bam2b.gpcm.gpcm.done)

@ 
<<bam2bgpcmmodcompprint, echo=FALSE, results=tex>>=
bam2b.gpcm.modcomp.xtab <- xtable(bam2b.gpcm.modcomp, caption="Performance of Beliefs About Medicine IRT Scale from Split B on Splits A, C and D", label="tab:bam2bpcmmodcomp")
print(bam2b.gpcm.modcomp.xtab)
@ 
As can be seen from Table \ref{tab:bam2bpcmmodcomp}, the Rasch PCM provided the best performance on unseen data.

Next, the same procedure was applied to the Graded Response Models. 

<<bam2bgrmtest, echo=FALSE, results=tex, cache=TRUE>>=
#bam2b.grm.1pl.done <- testIRTModels(bam2b.grm.1pl, bamnotb.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
@


% figure out what to do with the different response patterns in grade response models 


\subsubsection{Split C}
\label{sec:split-c}



<<tcq2caisp, echo=FALSE, results=tex>>=
tcq2c.aisp <- aisp(na.omit(tcqall2c))
print(xtable(tcq2c.aisp, label="tab:tcq2caisp", caption="Item Selection Procedure Results, TCQ 2, Split C"))
@ 

As can be seen from Table \ref{tab:tcq2caisp}, the algorithm suggests that there are two scales, one for conventional items and another for alternative items, as was seen in the previous two splits. The assumption checking will therefore be carried out on each scale seperately. 

<<tcq2csplitscales, echo=FALSE, results=hide, cache=TRUE>>=
tcq2c.conv <- tcqall2c[,1:18]
tcq2c.alt <- tcqall2c[,19:36]
@ 



<<tcq2ccheckiio, echo=FALSE, results=tex>>=
tcq2c.conv.iio <- check.iio(na.omit(tcq2c.conv))
print(xtable(tcq2c.conv.iio$violations, label="tab:tcq2ccheckiio", caption="Item Ordering Assumption Check, TCQ2 Conventional, Split C"))
@ 

As can be seen from Table \ref{tab:tcq2ccheckiio}, there were no violations of the item ordering assumption in this sample. 


<<tcq2cconvcheckmono, echo=FALSE, results=tex>>=
tcq2c.conv.mono <- check.monotonicity(na.omit(tcq2c.conv))
print(xtable(summary(tcq2c.conv.mono), label="tab:tcq2cconvcheckmono", caption="Monotonicity Check, TCQ 2 Conventional, Split C"))
@ 

Next, the monotonicity assumption was examined. Table \ref{tab:tcq2cconvcheckmono} shows that there were no violations of monotonicity in this sample. 

Next, the number of guttman errors for the TCQ conventional items were calculated and plotted. 

\begin{figure}
<<tcq2cconvguttman, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2c.conv.gutt <- check.errors(na.omit(tcq2c.conv))
tcq2c.conv.gutt.plot <- ggplot(as.data.frame(tcq2c.conv.gutt), aes(x=tcq2c.conv.gutt))+geom_histogram(binwidth=5)
print(tcq2c.conv.gutt.plot)
@   
  \caption{Histogram of Guttman errors for TCQ conventional items, Split C}
  \label{fig:tcq2cconvguttplot}
\end{figure}

The plot shown in Figure \ref{fig:tcq2cconvguttplot} is interesting. It can be seen that the majority of participants have very few guttman errors, but there are quite a few participants who have an extremely high level of scaling errors, suggesting that they were not engaging with the questions in a coherent manner. These participants may need to be removed in order to estimate accurate measures of person ability and item difficulty. 

Next, the assumptions of IRT were checked for the TCQ alternative items in this split. 

<<tcq2caltcheckiio, echo=FALSE, results=tex>>=
tcq2c.alt.iio <- check.iio(na.omit(tcq2c.alt))
print(xtable(tcq2c.alt.iio$violations, label="tab:tcq2caltcheckiio", caption="Item Ordering Assumption Check, TCQ2 Alternative, Split C"))
@ 

Table \ref{tab:tcq2caltcheckiio} shows that there were no violations of the invariant item ordering assumption in this split for the alternative items. 


<<tcq2caltcheckmono, echo=FALSE, results=tex>>=
tcq2c.alt.mono <- check.monotonicity(na.omit(tcq2c.alt))
print(xtable(summary(tcq2c.alt.mono), label="tab:tcq2caltcheckmono", caption="Monotonicity Check, TCQ2 Alternative, Split C"))
@ 

Next, the monotonicity assumption was examined. Table \ref{tab:tcq2caltcheckmono} shows that there were no violations of the monotonicity assumption for the alternative items in this split. 

The next step in the analysis procedure was to fit a series of generalised partial credit models to the data (Rasch, one parameter and two parameter). The results are shown below. 

<<tcq2cconvgpcm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2c.conv.gpcm.rasch <- gpcm(tcq2c.conv, constraint="rasch")
tcq2c.conv.gpcm.1PL <- gpcm(tcq2c.conv, constraint="1PL")
tcq2c.conv.gpcm.gpcm <- gpcm(tcq2c.conv, constraint="gpcm")
@ 

\begin{figure}
<<tcq2cconvgpcmraschplot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2c.conv.gpcm.rasch.plot <- ggplotGRM(tcq2c.conv.gpcm.rasch)
print(tcq2c.conv.gpcm.rasch.plot)
@   
  \caption{Item Parameter Plot for TCQ2C Conventional GPCM Rasch}
  \label{fig:tcq2cconvgpcmrasch}
\end{figure}

Figure \ref{fig:tcq2cconvgpcmrasch} shows that the PCM again shows non-monotonically increasing parameter estimates, which is allowable in a PCM. This may mean that category 3 could be collapsed into the two adjacent categories. 

<<tcq2cgpcmraschprint, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2c.conv.gpcm.rasch), label="tab:tcq2cconvgpcmrasch", caption="Coefficient Estimates for Split C TCQ, Conventional Items, Partial Credit Rasch Model"))
@ 

The coefficient estimates for the Rasch PCM on the conventional items can be seen in Table \ref{tab:tcq2convgpcmrasch}. It can be seen that the pill items appear to have the lowest estimated threshold for category 1, while the injection items have the lowest threshold for category five. As has happened before, the cream items are regarded as the most difficult to endorse, and category 3 estimates appear to show that this catgory is being used as the base response, when participants have little to no opinion. 

\begin{figure}
<<tcq2cconvgpcm1PLplot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2c.conv.gpcm.1PL.plot <- ggplotGRM(tcq2c.conv.gpcm.1PL)
print(tcq2c.conv.gpcm.1PL.plot)
@   
  \caption{Item Parameter Plot for TCQ2C Conventional GPCM}
  \label{fig:tcq2cconvgpcm1PLplot}
\end{figure}

Again, as can clearly be seen from Figure \ref{fig:tcq2cconvgpcm1PLplot}, the monotonicity assumption was not met for this model. 

<<tcq2cconvgpcm1pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2c.conv.gpcm.1PL), label="tab:tcq2cconvgpcm1pl", caption="Coefficient Estimates for TCQ Conventional One Parameter PCM, Split C"))
@ 

Table \ref{tab:tcq2cgpcmconv1pl} shows the estimated coefficients for the one parameter PCM. The discrimination parameter has risen, but the majority of items retain the rank order from the Rasch estimated model. 



\begin{figure}
<<tcq2cconvgpcmgpcmplot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2c.conv.gpcm.gpcm.plot <- ggplotGRM(tcq2c.conv.gpcm.gpcm)
print(tcq2c.conv.gpcm.gpcm.plot)
@   
  \caption{Item Position Plot for Two Parameter GPCM (Split B)}
  \label{fig:tcq2cconvgpcm2plplot}
\end{figure}


Figure \ref{fig:tcq2cconvgpcm2plplot} shows that like the simpler models, the two parameter generalised partial credit model does not fit the data particularly well. 

<<tcq2cconvgpcmgpcm, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2c.conv.gpcm.gpcm), label="tab:tcq2cconvgpcmgpcm", caption="Coefficient Estimates for TCQ Conventional, Two Parameter PCM, Split C"))
@ 

Table \ref{tab:tcq2cconvgpcmgpmcm} shows the estimated coefficients for the two parameter model. It can be seen that the Cream items have traded off some difficulty and gained higher estimated discrimination parameters, while some of the injection and pill items actually have discrimination parameters lower than one, suggesting that they are less directly informative about the differences between participants of low and high ability. 

<<tcq2cconvgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2c.conv.grm.1pl <- grm(tcq2c.conv, constrained=TRUE)
tcq2c.conv.grm.2pl <- grm(tcq2c.conv, constrained=FALSE)
@ 

Next, the fit of one and two parameter graded response models (GRM) was examined. 

\begin{figure}
<<tcq2cconvgrm1plot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2c.convgrm1plot <- ggplotGRM(tcq2c.conv.grm.1pl)
print(tcq2c.convgrm1plot)
@   
  \caption{Item Parameter Plot for TCQ Conventional 1 parameter Graded Response Model (Split B)}
  \label{fig:tcq2cconvgrm1plot}
\end{figure}

Figure \ref{fig:tcq2cconvgrm1plot} shows that, in contrast to the partial credit models, the one parameter model provides a good fit to this scale. 

<<tcq2cconvgrm1plsumm, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2c.conv.grm.1pl), label="tab:tcq2cconvgrm1plsumm", caption="Coefficients for TCQ 2 Conventional (Split C), One Parameter Graded Response Model"))
@ 

In Table \ref{tab:tcq2cconvgrm1plsumm} the estimated thresholds for the one parameter graded response model are shown. It can be seen that the Cream items are perceived as the most difficult, and that the discrimination parameter (the slope) is estimated at 2.083. This is an average parameter estimated for the whole scale, and based on the results of the previous splits, we would expect to see the discrimination parameters increase for the Cream items and decrease for the Pill and Injection items. 


\begin{figure}
<<tcq2cconvgrm2plot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2convgrm2plot <- ggplotGRM(tcq2c.conv.grm.2pl)
print(tcq2convgrm2plot)
@   
  \caption{Item Parameter Plot for TCQ Conventional 2 parameter Graded Response Model (Split B)}
  \label{fig:tcq2cconvgrm2plot}
\end{figure}
@ 

Firstly, the fit of the two parameter graded response model was examined graphically, as shown in Figure \ref{fig:tcq2cconvgrm2plot}. This figure demonstrates that there are no obvious violations of monotonicity, and the coefficients are the next focus of attention.


<<tcq2cconv2plgrmsum, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2c.conv.grm.2pl), label="tab:tcq2cconv2plgrmsum", caption="Coefficients for TCQ 2 Split C Two Parameter Graded Response Model"))
@ 

Table \ref{tab:tcq2cconv2plgrmsum} shows the estimated coefficients and discrimation paramaters for the two parameter graded response model. Interestingly enough, Pill 5 and Pill6 appear to have been the questions with the most dicriminative power. The estimated thresholds have not changed that much, the Cream items still have the highest threshold estimates. 

Next, an anova likelihood ratio test was carried out between the two models to determine which one fitted the data better. 

<<tcq2cconvanova, echo=FALSE, results=hide, cache=TRUE>>=
tcq2c.conv.anova <- anova(tcq2c.conv.grm.1pl, tcq2c.conv.grm.2pl)
@ 
The results of the anova showed that the two parameter model fit the data significantly better than the one parameter model ($p\le 0.001$). In addition, the AIC and BIC measures (which penalise for extra parameters) agreed with the LR test, unlike in previous splits. Therefore, provisionally, it appears that the two parameter model provides the best fit to the data. 

Next, the performance of the partial credit and graded response models was assessed on unseen data. 

<<tcq2cconvpcmtest, echo=FALSE, results=tex, cache=TRUE>>=
tcq2notc.conv <- tcq2notc[,17:34]
tcq2c.conv.pcm.rasch.done <- testIRTModels(tcq2c.conv.gpcm.rasch, tcq2notc.conv, gpcmconstraint="rasch", grmconstraint=NULL)
tcq2c.conv.pcm.1pl.done <- testIRTModels(tcq2c.conv.gpcm.1PL, tcq2notc.conv, gpcmconstraint="1PL", grmconstraint=NULL)
tcq2c.conv.pcm.gpcm.done <- testIRTModels(tcq2c.conv.gpcm.rasch, tcq2notc.conv, gpcmconstraint="gpcm", grmconstraint=NULL)
tcq2c.conv.pcm.modcomp <- rbind(tcq2c.conv.pcm.rasch.done, tcq2c.conv.pcm.1pl.done, tcq2c.conv.pcm.gpcm.done)
rownames(tcq2c.conv.pcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")
 
@ 
<<tcq2cconvpcmmodcompprint, echo=FALSE, results=tex>>=
tcq2c.conv.pcm.modcomp.xtab <- xtable(tcq2c.conv.pcm.modcomp, caption="Performance of IRT Models TCQ Conventional (Split C), on Splits A, B and D", label="tab:tcq2cconvpcmmodcomp")
print(tcq2c.conv.pcm.modcomp.xtab)                           
@ 
From Table \ref{tab:tcq2cconvpcmmodcomp}, it can be seen that the one parameter partial credit model was the best performing on unseen data. 

Finally, the same procedure was repeated for the graded response models for the TCQ conventional scale developed in this split. 

<<tcq2cconvgrmtest, echo=FALSE, results=tex, cache=TRUE>>=
tcq2c.conv.grm.1pl.done <- testIRTModels(tcq2c.conv.grm.1pl, tcq2notc.conv, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2c.conv.grm.2pl.done <- testIRTModels(tcq2c.conv.grm.2pl, tcq2notc.conv, gpcmconstraint=NULL, grmconstraint=FALSE)
tcq2c.conv.grm.modcomp <- rbind(tcq2c.conv.grm.1pl.done, tcq2c.conv.grm.2pl.done)
rownames(tcq2c.conv.grm.modcomp) <- c("One Paramter GRM", "Two Parameter GRM")

@ 
<<tcq2cconvgrmmodcomp, echo=FALSE, results=tex>>=
tcq2c.conv.grm.modcomp.xtab <- xtable(tcq2c.conv.grm.modcomp, caption="Performance of TCQ Conventional Graded Response Models (Split C) on Splits A, B and D", label="tab:tcq2convgrmmodcomp")
print(tcq2c.conv.grm.modcomp.xtab)
@ 
As can be seen from Table \ref{tab:tcq2convgrmmodcomp}, the one parameter Graded Response Model performed best on the unseen data. 

<<tca2caltpcm, echo=FALSE, results=tex, cache=TRUE>>=
tcq2c.alt.pcm.rasch <- gpcm(tcq2c.alt, constraint="rasch")
tcq2c.alt.pcm.1PL <- gpcm(tcq2c.alt, constraint="1PL")
tcq2c.alt.pcm.gpcm <- gpcm(tcq2c.alt, constraint="gpcm")
@ 

<<tcq2caltgpcmrasch, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2c.alt.pcm.rasch), label="tab:tcq2caltgpcmrasch", caption="Coefficient Estimates for TCQ Alternative Rasch PCM, Split C"))
@ 

Table \ref{tab:tcq2caltgpcmrasch} shows the estimated coefficients for the alternative scale in this split. It can be seen that all of the items have higher thresholds than those for the conventional scale, and that the Acupuncture items have somewhat lower thresholds than do the Homeopathy and Reiki items. 

Next, a one parameter PCM was examined on this scale. 

<<tcq2caltgpcm1pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2c.alt.pcm.1PL), label="tab:tcq2caltgpcm1pl", caption="Coefficient Estimates for TCQ Alternative, One Parameter PCM, Split C"))
@ 

Table \ref{tab:tcq2caltgpcm1pl} shows the estimated coefficients for this model. It can be seen that the discrimination parameter has risen substantially, suggesting that the alternative items are good at distinguishing between high and low ability participants. The relative thresholds of all three sets of items have remained stable, however. 

Finally, a two parameter PCM was fit to this scale. 

<<tcq2caltgpcmgpcm, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2c.alt.pcm.gpcm), label="tab:tcq2caltgpcmgpcm", caption="Coefficient Estimates for TCQ Alternative, Two Parameter PCM, Split C"))
@ 

Table \ref{tab:tcq2caltgpcmgpcm} shows the estimated parameters for the two parameter scale. It can be seen that the Homeopathy items are the most dicriminating, although the Reiki items have higher category four thresholds. This would seem to suggest that these items would be the most useful for discriminating between high and low ability participants. 

<<tcq2caltpcmmodcomp, echo=FALSE, results=tex, cache=TRUE>>=
tcq2notc.alt <- tcq2notc[,35:52]
tcq2c.alt.pcm.rasch.done <- testIRTModels(tcq2c.alt.pcm.rasch, tcq2notc.alt, gpcmconstraint="rasch", grmconstraint=NULL)
tcq2c.alt.pcm.1pl.done <- testIRTModels(tcq2c.alt.pcm.1PL, tcq2notc.alt, gpcmconstraint="1PL", grmconstraint=NULL)
tcq2c.alt.pcm.pcm.done <- testIRTModels(tcq2c.alt.pcm.rasch, tcq2notc.alt, gpcmconstraint="gpcm", grmconstraint=NULL)
tcq2c.alt.pcm.modcomp <- rbind(tcq2c.alt.pcm.rasch.done, tcq2c.alt.pcm.1pl.done, tcq2c.alt.pcm.pcm.done)
rownames(tcq2c.alt.pcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")

@ 
<<tcq2caltpcmmodcompprint, echo=FALSE, results=tex>>=
tcq2c.alt.pcm.modcomp.xtab <- xtable(tcq2c.alt.pcm.modcomp, caption="Performance of IRT Models TCQ Conventional (Split C), on Splits A, B and D", label="tab:tcq2caltpcmmodcomp")
print(tcq2c.alt.pcm.modcomp.xtab)                            

@ 
As can be seen from Table \ref{tab:tcq2caltpcmmodcomp}, the Rasch PCM provided the best fit on unseen data, though there was not much different between the Rasch and the one parameter model. 

Next, two graded response models were fit to the data. 

<<tcq2caltgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2c.alt.grm.1pl <- grm(tcq2c.alt, constrained=TRUE)
tcq2c.alt.grm.2pl <- grm(tcq2c.alt, constrained=FALSE)
@ 

<<tcq2caltgrm1pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2c.alt.grm.1pl), caption="Coefficients of TCQ Alternative (Split C) One Parameter Graded Response Model", label="tab:tcq2caltgrm1pl"))
@ 

As can be seen in Table \ref{tab:tcq2caltgrm1pl}, there are no obvious problems with this solution, as before the homeopathy and reiki questions tend to have higher ability estimates.



<<tcq2caltgrm2pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2c.alt.grm.2pl), caption="Coefficients of TCQ Alternative (Split C) Two Parameter Graded Response Model", label="tab:tcq2caltgrm2pl"))
@ 

Table \ref{tab:tcq2caltgrm2pl} shows that the pattern of other splits is confirmed in that the discrimination parameters of the acupuncture items lowers, while that of the other sets of items rises, with a corresponding tradeoff in estimated difficulty parameters. 

Finally for this model, we examine its performance on unseen data. 

<<tcq2cgrmmodtest, echo=FALSE, results=tex, cache=TRUE>>=
tcq2notc.alt.irt <- tcq2notc[,35:52]
tcq2c.alt.grm.1pl.done <- testIRTModels(tcq2c.alt.grm.1pl, tcq2notc.alt.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2c.alt.grm.2pl.done <- testIRTModels(tcq2c.alt.grm.2pl, tcq2notc.alt.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2c.alt.grm.modcomp <- rbind(tcq2c.alt.grm.1pl.done, tcq2c.alt.grm.2pl.done)

@ 
<<tcq2caltgrmmodcomprint, echo=FALSE, results=tex>>=
print(xtable(tcq2c.alt.grm.modcomp, caption="Performance of Split C TCQ Alternative Graded Response Models, tested on Splits A, B and D", label="tab:tcq2caltgrmmodcomp"))
@ 
As can be seen from Table \ref{tab:tcq2caltgrmmodcomp}, the two parameter model provides a better fit to the unseen data. 


Next, the beliefs about medicine questionnaire was examined in this split. 

<<bam2caisp, echo=FALSE, results=tex>>=
bam2c.aisp <- aisp(na.omit(bamall2b))
print(xtable(bam2c.aisp, label="tab:bam2caisp", caption="Item Selection Procedure, Beliefs About Medicine Questionnaire, Split C"))
@ 

As seen in previous splits, BAM1 and BAM2 were partitioned into their own scale, and many items did not fit any scale. As a two item scale is too small to examine effectively, all further analyses were carried out on the reduced scale (1). Table \ref{tab:bam2caisp} shows these results. In contrast to Split A, the scale had 9 items, and these were the same items as were selected by the scale splitting algorithm in Split B. 

<<bamscale2c,echo=FALSE, results=hide, cache=TRUE>>=
bamscale2c <- bamall2b[,c("BAM3","BAM4","BAM6","BAM9","BAM10","BAM11","BAM13","BAM14", "BAM17")]
@ 

The first assumption to be checked was the invariant item ordering assumption, and the results are shown in Table \ref{tab:bam2checkiio}. 

<<bam2ccheckiio, echo=FALSE, results=tex>>=
bam2c.iio <- check.iio(na.omit(bamscale2c))
print(xtable(bam2c.iio$violations, label="tab:bam2checkiio", caption="Item Ordering Assumption Check, Beliefs About Medicine Questionnaire, Split C"))
@ 

As can be seen from Table \ref{tab:bam2checkiio}, no items violated this assumption and therefore all of them were retained. 


<<bam2ccheckmono, echo=FALSE, results=tex>>=
bam2c.mono <- check.monotonicity(na.omit(bamscale2c))
print(xtable(summary(bam2c.mono), label="tab:bam2ccheckmono", caption="Monotonicity Check, Beliefs About Medicine Questionnaire, Split C"))
@ 

Following the check of the IIO assumption, the next step in assumption checking was a monotonicity check. The results of this check are shown in Table \ref{tab:bam2ccheckmono}. This shows that no items violated this assumption (though the ItemH coefficients are close to the cutoff of 0.3). 

\begin{figure}
<<bam2cguttman, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
bam2c.guttman <- check.errors(na.omit(bamscale2c))
bam2c.guttplot <- ggplot(as.data.frame(bam2c.guttman), aes(x=bam2c.guttman))+geom_histogram(binwidth=2)
print(bam2c.guttplot)
@   
  \caption{Plot of Guttman errors for Beliefs about Medicine Scale, Split C}
  \label{fig:bam2cguttmanplot}
\end{figure}

Next, the guttman errors in the split were examined and checked across this sample of items. Similiarly to the TCQ items in this split, the level of guttman errors was much higher, with a mode at approximately 10. This is worrying, and needs to be investigated further. 


<<bam2cgpcm, echo=FALSE, results=hide, cache=TRUE>>=
bam2c.gpcm.rasch <- gpcm(bamscale2c, constraint="rasch")
bam2c.gpcm.1PL <- gpcm(bamscale2c, constraint="1PL")
bam2c.gpcm.gpcm <- gpcm(bamscale2c, constraint="gpcm")
@ 

Firstly, three generalised partial credit models were fit (Rasch, one parameter and two parameter). The results are shown below. 


<<bam2cgpcmrasch, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2c.gpcm.rasch)), label="tab:bam2cgpcmrasch", caption="Beliefs About Medicine Questionnaire Split C, Rasch generalised partial credit model"))
@ 

Table \ref{tab:bam2cgpcmrasch} shows the coefficient estimates for the Rasch model fitted to the BAM scale. It can be seen that the estimated thresholds are in line with the ranges from the conventional items, while it might have been expected that they would be more along the lines of the alternative items (given the overlap between negativity towards conventional medicines and positivity towards alternative treatments). 
% % . Although the problems of non-monotonic coefficient estimates are less severe than in previous splits, they are still there (BAM9,11, 13, 14, 17). This indicates that the model does not do a good job on this scale. The same problems occurred for both the one parameter and two parameter models, and so these coefficient estimates are not reported.

Next, the fit of a one parameter PCM was examined on this scale.

<<bam2cpcm1plprint, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2c.gpcm.rasch)), label="tab:bam2cgpcmrasch", caption="Coefficient Estimates for BAM Scale, One Parameter PCM, Split C"))
@ 

Table \ref{tab:bam2cgpcmrasch} shows the estimated coefficients for this model. Interestingly enough, the discrimination parameter has lowered for all of the items. This suggests that these items are less good than would be expected at discriminating between high and low ability participants. 

Finally, the fit of the two parameter PCM was examined on this scale.

<<bam2cgpcmgpcmprint, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2c.gpcm.gpcm)), label="tab:bam2cgpcmgpcm", caption="Coefficient Estimates, BAM Scale, Two Parameter PCM, Split C"))
@ 

Table \ref{tab:bam2cgpcmgpcm} shows the estimated coefficients for the two parameter PCM. It can be seen that Q6, 14 and 17 are the most discrimination question, and that 3,4, 9 and 10 appear to have been the drivers of the discrimination parameter being below 1 in the one parameter model. 

Next, the fit of one and two parameter graded response models were examined. 

<<bam2cgrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2c.grm.1pl <- grm(bamscale2c, constrained=TRUE)
bam2c.grm.2pl <- grm(bamscale2c, constrained=FALSE)
@ 

<<bam2cgrm1sum, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2c.grm.1pl)), label="tab:bam2cgrm1sum", caption="Coefficients for Beliefs About Medicine Questionnaire, One Parameter Graded Response Model (Split C)"))
@ 

Table \ref{tab:bam2cgrm1sum} shows that there are no monotonicity problems with the one parameter GRM. The estimated discrimination parameter is 1.523, and BAM6 appears to be the most difficult item in the scale (as no participants gave the highest response category to it, across all of the splits).




<<bam2cgrm2sum, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2c.grm.2pl)), label="tab:bam2cgrm2sum", caption="Coefficients for Beliefs About Medicine Questionnaire, Split C, Two parameter Graded Response Model"))
@ 

Next, the fit of the two parameter  GRM was examined, and is displayed in Table \ref{tab:bam2cgrm2sum}. Note that BAM13 appears to be the most discriminating item, and that BAM3 is the most difficult item (with the exception of BAM6, as noted above). 

<<bam2canovagrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2cgrm.anova <- anova(bam2c.grm.1pl, bam2c.grm.2pl)
@ 

An anova was carried out between the two graded response models, and the LR test showed that the two parameter model was significanly ($p \le 0.001$) better fit than the one parameter model. However, this was contradicted by both the BIC and AIC, which indicated that the one parameter model provided a better fit to the data. 

Next the performance of the IRT models developed was assessed on unseen data. 

<<bam2cpcmtest, echo=FALSE, results=tex, cache=TRUE>>=
bamnotc.irt <- tcq2notc[,c("BAM3", "BAM4", "BAM6",  "BAM9",  "BAM10", "BAM11", "BAM13",  "BAM14", "BAM17")]
bam2c.gpcm.rasch.done <- testIRTModels(bam2c.gpcm.rasch, bamnotc.irt, gpcmconstraint="rasch", grmconstraint=NULL)
bam2c.gpcm.1pl.done <- testIRTModels(bam2c.gpcm.1PL, bamnotc.irt, gpcmconstraint="1PL", grmconstraint=NULL)
bam2c.gpcm.gpcm.done <- testIRTModels(bam2c.gpcm.gpcm, bamnotc.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
bam2c.pcm.modcomp <- rbind(bam2c.gpcm.rasch.done, bam2c.gpcm.1pl.done, bam2c.gpcm.gpcm.done)
rownames(bam2c.pcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")

@ 
<<bam2cpcmmodcompprint, echo=FALSE, results=tex>>=
bam2c.gpcm.modcomp.xtab <- xtable(bam2c.pcm.modcomp, caption="Results of BAM Split C Partial Credit Models on Splits A, B and D", label="tab:bam2cpcmmodcomp")
print(bam2c.gpcm.modcomp.xtab)
@ 
As can be seen from Table \ref{tab:bam2cpcmmodcomp}, the Rasch model for the Beliefs About Medicine Questionnaire provided the best fit to unseen data. 

%% Next, we examine the performance of the Graded Response Models on unseen data. 

<<bam2cgrmtest, echo=FALSE, results=tex, eval=FALSE, cache=TRUE>>=
bam2c.grm.1pl.done <- testIRTModels(bam2c.grm.1pl, bamnotc.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
@ 

\subsubsection{Split D}
\label{sec:split-d}

Next, the fourth and final split was examined. Again, the first step is to examine the Treatment Credibility Questionnaire and assess how many scales the items break down into.

<<tcq2daisp, echo=FALSE, results=tex>>=
tcq2d.aisp <- aisp(na.omit(tcqall2d))
print(xtable(tcq2d.aisp, label="tab:tcq2daisp", caption="Item Selection Procedure Results, TCQ 2 Split D"))
@ 

Table \ref{tab:tcq2daisp} shows that, similarly to the first three splits, the TCQ splits along the conventional/alternative distinction. Therefore, the items will be split into conventional and alternative scales and all analyses carried out seperately. 

<<tcq2dsplitscales, echo=FALSE, results=hide, cache=TRUE>>=
tcq2d.conv <- tcqall2d[,1:18]
tcq2d.alt <- tcqall2d[,19:36]
@ 

The first task to examine the TCQ conventional items and assess whether or not they meet the assumptions required for IRT modelling. The first assumption to be checked is the invariant item ordering assumption. 

<<tcq2dcheckiio, echo=FALSE, results=tex>>=
tcq2d.conv.iio <- check.iio(na.omit(tcq2d.conv))
print(xtable(tcq2d.conv.iio$violations, label="tab:tcq2dcheckiio", caption="Item Ordering Assumption Check, TCQ2 Conventional, Split D"))
@ 

As can be seen from Table \ref{tab:tcq2dcheckiio}, all of the items in the TCQ conventional scale met the IIO assumption. Next, the monotonicity assumption was examined for the conventional scale. 


<<tcq2dconvcheckmono, echo=FALSE, results=tex>>=
tcq2d.conv.mono <- check.monotonicity(na.omit(tcq2d.conv))
print(xtable(summary(tcq2d.conv.mono), label="tab:tcq2dconvcheckmono", caption="Monotonicity Check, TCQ 2 Conventional Split D"))
@ 

As can be seen from Table \ref{tab:tcq2dconvcheckmono}, all of the items in the conventional scale met this assumption. Next, the scale was checked for guttman scaling errors, and these were plotted. 

\begin{figure}
<<tcq2dconvguttman, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2d.conv.gutt <- check.errors(na.omit(tcq2d.conv))
tcq2d.conv.gutt.plot <- ggplot(as.data.frame(tcq2d.conv.gutt), aes(x=tcq2d.conv.gutt))+geom_histogram(binwidth=2)
print(tcq2d.conv.gutt.plot)
@   
  \caption{Histogram of Guttman errors for TCQ conventional items, Split D}
  \label{fig:tcq2dconvguttplot}
\end{figure}

As shown in Figure \ref{fig:tcq2dconvguttplot}, the majority of participants had no guttman errors, but there were some participants who made an extremely large number of scaling errors. This worrying feature of this split will be examined further when person and item fit indices are assessed in the context of parametric IRT modelling.


Next, the assumptions were checked for the alternative items. 

<<tcq2daltcheckiio, echo=FALSE, results=tex>>=
tcq2d.alt.iio <- check.iio(na.omit(tcq2d.alt))
print(xtable(tcq2d.alt.iio$violations, label="tab:tcq2daltcheckiio", caption="Item Ordering Assumption Check, TCQ 2 Alternative, Split D"))
@ 

As can be seen from Table \ref{tab:tcq2daltcheckiio}, there were no violations of the IIO assumption for the alternative items. 

Next, the monotonicity assumption was examined for the alternative scale.


<<tcq2daltcheckmono, echo=FALSE, results=tex>>=
tcq2d.alt.mono <- check.monotonicity(na.omit(tcq2d.alt))
print(xtable(summary(tcq2d.alt.mono), label="tab:tcq2daltcheckmono", caption="Monotonicity Check, TCQ 2 Alternative, Split D"))
@ 

As shown in Table \ref{tab:tcq2daltcheckmono}, there were no violations of the monotonicity assumption, and the itemH coefficients are quite high, which suggests that this is a well-devised scale. 


<<tcq2dconvgpcm, echo=FALSE, results=hide>>=
tcq2d.conv.gpcm.rasch <- gpcm(tcq2d.conv, constraint="rasch")
tcq2d.conv.gpcm.1PL <- gpcm(tcq2d.conv, constraint="1PL")
tcq2d.conv.gpcm.gpcm <- gpcm(tcq2d.conv, constraint="gpcm")
@ 

\begin{figure}
<<tcq2dconvgpcmraschplot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2d.conv.gpcm.rasch.plot <- ggplotGRM(tcq2d.conv.gpcm.rasch)
print(tcq2d.conv.gpcm.rasch.plot)
@   
  \caption{Item Parameter Plot for TCQ2D Conventional GPCM Rasch}
  \label{fig:tcq2dconvgpcmrasch}
\end{figure}

The next step was to examine the fit of three partial credit models, and in Figure \ref{fig:tcq2dconvgpcmrasch}, it can be seen that there are problems with category 3 responses in this split also. 

<<tcq2dconvgpcmraschprint, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2d.conv.gpcm.rasch), label="tab:tcq2dgpcmrasch", caption="Coefficient Estimates for TCQ Conventional Items, Rasch PCM, Split D"))
@ 

Table \ref{tab:tcq2dgpcmrasch} shows the estimated coefficients for the Rasch PCM for the conventional items in this split. Again, a similar pattern as was seen in other splits emerges, where the Pill items have the lowest threshold for category 1, while the injection items are the easiest to endorse at the category 4 level. Again, the difficulties of the cream items, especially at the higher level, is apparent. 

\begin{figure}
<<tcq2dconvgpcm1PLplot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2d.conv.gpcm.1PL.plot <- ggplotGRM(tcq2d.conv.gpcm.1PL)
print(tcq2d.conv.gpcm.1PL.plot)
@   
  \caption{Item Parameter Plot for TCQ2D Conventional GPCM}
  \label{fig:tcq2dconvgpcm1PLplot}
\end{figure}

Next, the fit of a one parameter PCM (one discrimination parameter estimated from the data) is examined (see Figure \ref{fig:tcq2dconvgpcm1PLplot}). 

<<tcq2dgpcm1plprint, echo=FALSE, results=tex>>=
print(xtable(  coef(tcq2d.conv.gpcm.1PL), label="tab:tcq2dconvgpcm1pl", caption="Coefficient Estimates for TCQ Conventional, One Parameter PCM, Split D"))
@ 


Table \ref{tab:tcq2dconvgpcm1pl} shows the estimated coefficients for this model. It can be seen that the discrimination parameter has risen, although the relative difficulties of the items have stayed the same, much like in the previous split. 


\begin{figure}
<<tcq2dconvgpcmgpcmplot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2d.conv.gpcm.gpcm.plot <- ggplotGRM(tcq2d.conv.gpcm.gpcm)
print(tcq2d.conv.gpcm.gpcm.plot)
@   
  \caption{Item Position Plot for Two Parameter GPCM (Split D)}
  \label{fig:tcq2dconvgpcm2plplot}
\end{figure}

Finally, the fit of a two parameter PCM is shown in Figure \ref{fig:tcq2dconvgpcm2plplot}. 


<<tcq2dconvgpcmgpcmprint, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2d.conv.gpcm.gpcm), label="tab:tcq2dconvgpcmgpcm", caption="Coefficient Estimates for Two Parameter PCM, TCQ Conventional, Split D"))
@ 

Table \ref{tab:tcq2dconvgpcmgpcm} shows the estimated coefficients for the two parameter model. It can be seen that the discrimination parameters for the pill and injection items have lowered, while those for the cream items have increased substantially, suggesting that these items are good for dividing the sample into low and high ability participants. 

The next step was to examine the fit of one and two parameter Graded Response Models (GRM). 

<<tcq2dconvgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2d.conv.grm.1pl <- grm(tcq2d.conv, constrained=TRUE)
tcq2d.conv.grm.2pl <- grm(tcq2d.conv, constrained=FALSE)
@ 



\begin{figure}
<<tcq2dconvgrm1plot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2d.convgrm1plot <- ggplotGRM(tcq2d.conv.grm.1pl)
print(tcq2d.convgrm1plot)
@   
  \caption{Item Parameter Plot for TCQ Conventional 1 parameter Graded Response Model (Split D)}
  \label{fig:tcq2dconvgrm1plot}
\end{figure}

From Figure \ref{fig:tcq2dconvgrm1plot} it can be seen that there are no obvious violations of model assumptions for the one parameter GRM. 


<<tcq2dconvgrm1plsumm, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2d.conv.grm.1pl), label="tab:tcq2dconvgrm1plsumm", caption="Coefficients for TCQ Conventional, Split D, One Parameter Graded Response Model"))
@ 

Table \ref{tab:tcq2dconvgrm1plsumm} shows the coefficient estimates for the one parameter GRM. It can be seen that there are no violations of monotonicity, and that the discrimination parameter is estimated as being 2.064. The Cream items appear to be the least endorsed at higher levels (reflected in their higher thresholds at Category 4), while the Injection items appear to be the easiest to endorse, which fits with their higher credibility as an analgesic treatment. 


\begin{figure}
<<tcq2dconvgrm2plot, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2donvgrm2plot <- ggplotGRM(tcq2d.conv.grm.2pl)
print(tcq2donvgrm2plot)
@   
  \caption{Item Parameter Plot for TCQ Conventional 2 parameter Graded Response Model (Split D)}
  \label{fig:tcq2dconvgrm2plot}
\end{figure}
@ 

Figure \ref{fig:tcq2dconvgrm2plot} shows the estimated thresholds for the conventional items under the Graded Response Model. This plot shows that there are no non-monotonic thresholds, and suggests that this model is appropriately applied to this data. 

<<tcq2dconv2plgrmsum, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2d.conv.grm.2pl), label="tab:tcq2dconv2plgrmsum", caption="Coefficients for TCQ2 Conventional Scale (Split D), Two Parameter Graded Response Model"))
@ 

Table \ref{tab:tcq2dconv2plgrmsum} shows the threshold estimates and the discrimination parameters for the two parameter graded response model. It can be seen that the Cream items have the highest discrimination parameters while the Injection items have the lowest. Item 3 has the highest ability threshold across all treatments, probably because this item asks about confidence that the treatment will completely eliminate the symptoms. 

<<tcq2dconvanova, echo=FALSE, results=hide, cache=TRUE>>=
tcq2d.conv.anova <- anova(tcq2d.conv.grm.1pl, tcq2d.conv.grm.2pl)
@ 

Finally, an ANOVA was carried out between the two graded response models, and this showed that there was no significant difference between the two models ($p=.593$), and the BIC and AIC were lower for the one parameter model, indicating better fit. 

Next, the performance of the models on unseen data is assessed. First, the performance of the partial credit models was examined for the conventional treatment credibility scale. 

<<tcq2dconvpcmmodtest, echo=FALSE, results=tex, cache=TRUE>>=
tcq2notd.irt <- tcq2notd[,17:34]
tcq2d.conv.gpcm.rasch.done <- testIRTModels(tcq2d.conv.gpcm.rasch, tcq2notd.irt, gpcmconstraint="rasch", grmconstraint=NULL)
tcq2d.conv.gpcm.1PL.done <- testIRTModels(tcq2d.conv.gpcm.1PL, tcq2notd.irt, gpcmconstraint="1PL", grmconstraint=NULL)
tcq2d.conv.gpcm.gpcm.done <- testIRTModels(tcq2d.conv.gpcm.gpcm, tcq2notd.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
tcq2d.conv.pcm.modcomp <- rbind(tcq2d.conv.gpcm.rasch.done, tcq2d.conv.gpcm.1PL.done, tcq2d.conv.gpcm.gpcm.done)
rownames(tcq2d.conv.pcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")

@ 
<<tcq2dconvgpcmmodcompprint, echo=FALSE, results=tex>>=
tcq2d.conv.gpcm.done.xtab <- xtable(tcq2d.conv.pcm.modcomp, caption="Performance of Split D Conventional TCQ Scale on Splits A, B and C", label="tab:tcq2dpcmmodcomp")
print(tcq2d.conv.gpcm.done.xtab)
@ 
As can be seen from Table \ref{tab:tcq2dpcmmodcomp}, the best performing model on unseen data was the one parameter PCM.

The same process was then repeated for the graded response models. 

<<tcq2dgrmmodcomp, echo=FALSE, results=tex, cache=TRUE>>=
tcq2d.conv.grm.1pl.done <- testIRTModels(tcq2d.conv.grm.1pl, tcq2notd.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2d.conv.grm.2pl.done <- testIRTModels(tcq2d.conv.grm.2pl, tcq2notd.irt, gpcmconstraint=NULL, grmconstraint=FALSE)
tcq2d.conv.grm.modcomp <- rbind(tcq2d.conv.grm.1pl.done, tcq2d.conv.grm.2pl.done)
rownames(tcq2d.conv.grm.modcomp) <- c("One Parameter GRM", "Two Parameter GRM")

@ 
<<tcq2dgrmmodcomp, echo=FALSE, results=tex>>=
print(xtable(tcq2d.conv.grm.modcomp, caption="Performance of Split D TCQ Conventional Graded Response Models on Splits A, B and C", label="tab:tcq2dconvgrmmodcomp"))
@ 
As can be seen from Table \ref{tab:tcq2dconvgrmmodcomp}, the one parameter Graded Response Model appears to provide the best fit to the unseen data. 


Next, the same procedure is repeated for the TCQ Alternative scale in this split. 

<<tca2daltpcm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2d.alt.pcm.rasch <- gpcm(tcq2d.alt, constraint="rasch")
tcq2d.alt.pcm.1PL <- gpcm(tcq2d.alt, constraint="1PL")
tcq2d.alt.pcm.gpcm <- gpcm(tcq2d.alt, constraint="gpcm")
@ 

<<tcq2daltpcmraschprint, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2d.alt.pcm.rasch), label="tab:tcq2daltpcmrasch", caption="Coefficient Estimates for TCQ Alternative, Rasch PCM, Split D"))
@ 

Table \ref{tab:tcq2daltpcmrasch} shows the estimated coefficients for the TCQ Alternative Rasch Partial Credit Model. It can be seen that the alternative items have much higher estimated thresholds than do the conventional items, with Acupuncture items being slightly easier to endorse than either Homeopathy or Reiki items. 

Next, a one parameter model was fit to this scale.

<<tcq2daltpcm1plprint, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2d.alt.pcm.1PL), label="tab:tcq2daltpcm1pl", caption="Coefficient Estimates, TCQ Alternative, One Parameter PCM, Split D"))
@ 

Table \ref{tab:tcq2daltpcm1pl} shows the estimated coefficients for this model. It can be seen that the discrimination parameter has risen quite signigicantly, while leave the relative ordering of the item sets much the same as it was in the Rasch model. 

Finally, a two parameter PCM was fit to this scale.

<<tcq2daltpcmgpcmprint, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2d.alt.pcm.gpcm), label="tab:tcq2daltpcm2pl", caption="Coefficient Estimates, TCQ Alternative, Two Parameter PCM, Split D"))
@ 

Table \ref{tab:tcq2daltpcm2pl} shows the estimated coefficients for the two parameter PCM. It can be seen that the Homeopathy and Reiki items have extremelty high discrimination parameters, while those for the Acupuncture items have lowered. Note that the Reiki items have much higher discrimination parameters in this split, unlike Split C. 

<<tcq2daltpcmmodcomp, echo=FALSE, results=tex, cache=TRUE>>=
tcq2notd.irt <- tcq2notd[,35:52]
tcq2d.alt.gpcm.rasch.done <- testIRTModels(tcq2d.alt.pcm.rasch, tcq2notd.irt, gpcmconstraint="rasch", grmconstraint=NULL)
tcq2d.alt.gpcm.1PL.done <- testIRTModels(tcq2d.alt.pcm.1PL, tcq2notd.irt, gpcmconstraint="1PL", grmconstraint=NULL)
tcq2d.alt.gpcm.gpcm.done <- testIRTModels(tcq2d.alt.pcm.gpcm, tcq2notd.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
tcq2d.alt.pcm.modcomp <- rbind(tcq2d.alt.gpcm.rasch.done, tcq2d.alt.gpcm.1PL.done, tcq2d.alt.gpcm.gpcm.done)
rownames(tcq2d.alt.pcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")

@ 

<<tcq2daltpcmmocompprint, echo=FALSE, results=tex>>=
tcq2d.alt.gpcm.done.xtab <- xtable(tcq2d.alt.pcm.modcomp, caption="Performance of Split D Alternative TCQ Scale on Splits A, B and C", label="tab:tcq2daltpcmmodcomp")
print(tcq2d.alt.gpcm.done.xtab)
@ 
As can be seen from Table \ref{tab:tcq2daltpcmmodcomp}, the Rasch PCM provided the best performance on the unseen data. 

Next, two graded response models were fit to the data. 

<<tcq2daltgrm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2d.alt.grm.1pl <- grm(tcq2d.alt, constrained=TRUE)
tcq2d.alt.grm.2pl <- grm(tcq2d.alt, constrained=FALSE)
@ 

<<tcq2daltgrm1pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2d.alt.grm.1pl), caption="Coefficients of TCQ Alternative (Split D) One Parameter Graded Response Model", label="tab:tcq2daltgrm1pl"))
@ 

As can be seen in Table \ref{tab:tcq2daltgrm1pl}, there are no obvious problems with this solution, as before the homeopathy and reiki questions tend to have higher ability estimates.



<<tcq2daltgrm2pl, echo=FALSE, results=tex>>=
print(xtable(coef(tcq2d.alt.grm.2pl), caption="Coefficients of TCQ Alternative (Split C) Two Parameter Graded Response Model", label="tab:tcq2daltgrm2pl"))
@ 

Table \ref{tab:tcq2daltgrm2pl} shows that the pattern of other splits is confirmed in that the discrimination parameters of the acupuncture items lowers, while that of the other sets of items rises, with a corresponding tradeoff in estimated difficulty parameters. 

Finally for this model, we examine its performance on unseen data. 

<<tcq2cgrmmodtest, echo=FALSE, results=tex>>=
tcq2notc.alt.irt <- tcq2notc[,35:52]
tcq2d.alt.grm.1pl.done <- testIRTModels(tcq2d.alt.grm.1pl, tcq2notc.alt.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2d.alt.grm.2pl.done <- testIRTModels(tcq2d.alt.grm.2pl, tcq2notc.alt.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
tcq2d.alt.grm.modcomp <- rbind(tcq2d.alt.grm.1pl.done, tcq2d.alt.grm.2pl.done)
rownames(tcq2d.alt.grm.modcomp) <- c("One Parameter GRM", "Two Parameter GRM")
print(xtable(tcq2d.alt.grm.modcomp, caption="Performance of Split C TCQ Alternative Graded Response Models, tested on Splits A, B and D", label="tab:tcq2daltgrmmodcomp"))
@ 

As can be seen from Table \ref{tab:tcq2caltgrmmodcomp}, the one parameter model provides a better fit to the unseen data. 

Next, the assumptions underlying the use of IRT modelling were applied to the Beliefs About Medicine Questionnaire. 

<<bam2daisp, echo=FALSE, results=tex>>=
bam2d.aisp <- aisp(na.omit(bamall2d))
print(xtable(bam2d.aisp, label="tab:bam2daisp", caption="Item Selection Procedure, Beliefs About Medicine Questionnaire, Split D"))
@ 

It can be seen from Table \ref{tab:bam2daisp} that again BAM1 and BAM2 form their own scale, while some of the other items do not appear on any scale. In line with previous practice, the small scale was not analysed, and so all analyses from this point on were carried out on the reduced scale (consisting of the items on scale 1 in Table \ref{tab:bam2daisp}).


<<bamscale2d,echo=FALSE, results=hide, cache=TRUE>>=
bamscale2d <- bamall2d[,c("BAM3","BAM6","BAM7","BAM9","BAM10","BAM13","BAM14", "BAM17")]
@ 



<<bam2dcheckiio, echo=FALSE, results=tex>>=
bam2d.iio <- check.iio(na.omit(bamscale2d))
print(xtable(bam2d.iio$violations, label="tab:bam2dheckiio", caption="Item Ordering Assumption Check, Beliefs About Medicine Questionnaire, Split D"))
@ 

Firstly, the invariant item ordering assumption was checked, and the results are shown in Table \ref{tab:bam2dheckiio}. As can be seen from this Table, there were no violations or issues with the IIO assumption.



<<bam2dcheckmono, echo=FALSE, results=tex>>=
bam2d.mono <- check.monotonicity(na.omit(bamscale2d))
print(xtable(summary(bam2d.mono), label="tab:bam2dcheckmono", caption="Monotonicity Check, Beliefs About Medicine Questionnaire, Split D"))
@ 

Next, the assumption of monotonicity was tested. The results of this test are shown in Table \ref{tab:bam2dcheckmono}, and it can be seen that there were no violations of this assumption, but the ItemH coefficients are quite low, suggesting that this scale is not entirely unproblematic. 


\begin{figure}
<<bam2dguttman, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
bam2d.guttman <- check.errors(na.omit(bamscale2d))
bam2d.guttplot <- ggplot(as.data.frame(bam2d.guttman), aes(x=bam2d.guttman))+geom_histogram(binwidth=2)
print(bam2d.guttplot)
@   
  \caption{Plot of Guttman errors for Beliefs about Medicine Scale, Split D}
  \label{fig:bam2dguttmanplot}
\end{figure}

Next, the scales were checked for guttman errors, and these were plotted in a histogram, shown in Figure \ref{fig:bam2dguttmanplot}. It can be seen from this plot that there were some participants who had quite a few guttman errors, as the distribution has a mode of approximately 10. However, the maximum number of Guttman errors was much lower than in Split C, where one participant had over 200 scaling errors. Again, this feature of the dataset needs to be investigated, and this will be carried out when person and item fit are assessed below.  

<<bam2dgpcm, echo=FALSE, results=hide, cache=TRUE>>=
bam2d.gpcm.rasch <- gpcm(bamscale2d, constraint="rasch")
bam2d.gpcm.1PL <- gpcm(bamscale2d, constraint="1PL")
bam2d.gpcm.gpcm <- gpcm(bamscale2d, constraint="gpcm")
@ 

Next, three generalised partial credit models were fitted to the scale, and the results of the Rasch fit are shown below. 


<<bam2dgpcmrasch, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2d.gpcm.rasch)), label="tab:bam2dgpcmrasch", caption="Coefficients for Beliefs About Medicine Questionnaire (Split D), Rasch Generalised Partial Credit Model"))
@ 

As can be seen from Table \ref{tab:bam2dgpcmrasch}, it can be seen that the majority of the categories have relatively low thresholds, with the exception of category 4. 

Next, a one parameter PCM was fitted to this scale. 

<<bam2dpcm1plprint, echo=FALSE, results=tex>>=
print(xtable(coef(bam2d.gpcm.1PL), label="tab:bam2dpcm1pl", caption="Coefficient Estimates for BAM Scale, One Parameter PCM, Split D"))
@ 

Table \ref{tab:bam2dpcm1pl} shows the estimated coefficients for the one parameter model. It can be seen that similarly to the Split C scale, the discrimination parameters have lowered in this model, while the estimated thresholds have risen slightly. 

Finally, a two parameter PCM was fitted to this scale.

<<bam2dpcm2plprint, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2d.gpcm.gpcm)), label="tab:bam2dpcm2pl", caption="Coefficient Estimates for BAM Scale, Two Parameter PCM, Split D"))
@ 

As can be seen from Table \ref{tab:bam2dpcm2pl}, the same pattern as was seen in Split C gas emerged, with some of the questions having quite high discrimination parameters, while others have rather low discriminations. Note in particular Q3, which has the huighest estimated threshold along with very low discrimination. 

<<bam2dgrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2d.grm.1pl <- grm(bamscale2d, constrained=TRUE)
bam2d.grm.2pl <- grm(bamscale2d, constrained=FALSE)
@ 

Next, two graded response models (one and two parameter) were fit to the data. 
<<bam2dgrm1sum, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2d.grm.1pl)), label="tab:bam2dgrm1sum", caption="Coefficients for Beliefs About Medicine Questionnaire (Split D), One Parameter Graded Response Model"))
@ 

Table \ref{tab:bam2dgrm1sum} shows the estimated coefficients and (averaged) discrimination parameter for the one parameter graded response model. This model appears to not have any problems with non-monotonicity, and the estimated discrimination parameter and thresholds are quite similar to those in previous splits. Again, BAM3 has the highest estimated threshold (with the exception of BAM6, where no participant picked the highest response alternative). 

Next, the two parameter GRM was fit to the Beliefs About Medicine Questionnaire. The results are shown in Table \ref{tab:bam2dgrm2sum}. The two parameter model is quite similiar to the one parameter model, the tradeoff between the discrimination parameter and the difficulty estimates can clearly be seen, as BAM3 has a lower discrimination parameter in this fit, but a much higher threshold. Most of the items appear to have made the opposite trade-off, with lower threshold values but a much higher discrimination parameter. 

<<bam2dgrm2sum, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2d.grm.2pl)), label="tab:bam2dgrm2sum", caption="Coefficients for Beliefs About Medicine Questionnaire, (Split D), Two Parameter Graded Response Model"))
@ 

After this process, an ANOVA was fit to the two graded response models, to determine which of them fit the data better. The LR test indicated that the two parameter model fit the data significanly better ($p\le0.001$), but the AIC indicated that the one parameter model was a better fit. This will be examined by looking at each of the models\' performance on unseen data. 

<<bam2danovagrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2dgrm.anova <- anova(bam2d.grm.1pl, bam2d.grm.2pl)
@

Next, the performance of each of these models on unseen data was assessed. 

<<bam2dpcmmodtest, echo=FALSE, results=tex, cache=TRUE>>=
bamnotd.irt <- tcq2notd[,c("BAM3","BAM6","BAM7","BAM9","BAM10","BAM13","BAM14", "BAM17")]
bam2d.gpcm.rasch.done <- testIRTModels(bam2d.gpcm.rasch, bamnotd.irt, gpcmconstraint="rasch", grmconstraint=NULL)
bam2d.gpcm.1PL.done <- testIRTModels(bam2d.gpcm.1PL, bamnotd.irt, gpcmconstraint="1PL", grmconstraint=NULL)
bam2d.gpcm.gpcm.done <- testIRTModels(bam2d.gpcm.gpcm, bamnotd.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
bam2d.pcm.modcomp <- rbind(bam2d.gpcm.rasch.done, bam2d.gpcm.1PL.done, bam2d.gpcm.gpcm.done)

@ 
<<bam2dpcmmodcompprint, echo=FALSE, results=tex>>=
print(xtable(bam2d.pcm.modcomp, caption="Performance of Split D Beliefs About Medicine Scale on Splits A, B and C", label="tab:bam2dpcmmodcomp"))

@ 
As can be seen from Table \ref{tab:bam2dpcmmodcomp}, the one parameter Partial Credit Model performed best on the unseen data. 

Next, the perfomance of the graded response models on unseen data was assessed. 

<<bam2dgrmmodtest, echo=FALSE, results=tex, cache=TRUE>>=
bam2d.grm.1pl.done <- testIRTModels(bam2d.grm.1pl, bamnotd.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
bam2d.grm.2pl.done <- testIRTModels(bam2d.grm.2pl, bamnotd.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
bam2d.grm.modcomp <- rbind(bam2d.grm.1pl.done, bam2d.grm.2pl.done)

@ 
<<bam2dgrmmodcomp, echo=FALSE, results=tex>>=
print(xtable(bam2d.grm.modcomp, captio="Performance of Split D Beliefs About Medicine Scale (Graded Response Model) on Splits A, B and C", label="tab:bam2dgrmmodcomp"))
@ 

As can be seen from Table \ref{tab:bam2dgrmmodcomp}, the one parameter Graded Response Model performed best on the unseen data. 

\subsubsection{Regression Analyses}
\label{sec:regression-analyses}

The next part of the analysis to be carried out was regression analysis. There were a number of demographic variables collected in the second sample, to allow for examination of their effects on the outcome variables (the treatment credibility scores). Gender, education, college of study or work, health, income and experience with the six forms of treatment were collected. The approach taken to the analysis was the following. Using the four splits that were used for the psychometric analysis. In this case, models were fit on 3 of the four splits, and the results of these analyses were predicted using the held out data. This allows for the use of step methods of regression while ensuring unbiased p values and standard errors. 

\subsubsection{Split A}
\label{sec:split}

The Split A sample consisted of Splits B, C and D, with Split A being used as held out data for testing. The first step was to examine the inter-relationships of the variables graphically, to give insights into which variables were the most important. 

\begin{figure}
<<splitApairs, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2.nota.tot <- tcq2nota[,71:77]
tcq2.nota.pairs <- pairs.panels(na.omit(tcq2.nota.tot))
@   
  \caption{Scatterplot Matrix for TCQ not A split. The upper diagonal has the correlations between the variables, the diagonal has a histogram of the values with density lines overlaid, and the lower diagonal has scatterplots for each pair of variables, with an overlaid locally weighted smoother regression line}
  \label{fig:splitApairs}
\end{figure}

Figure \ref{fig:splitApairs} shows the scatterplot matrix for the totals in Split A. It can clearly be seen that the conventional variables correlate well with one another, as do the alternative variables. Some evidence of convergent validity is also seen, as the Beliefs About Medicine Questionnaire correlates negatively with the conventional forms of treatment, and positively with the alternative forms of treatment, as predicted. 

Next, the relationships of the demographic variables with the totals were examined. 

<<tcq2notAdemo, echo=FALSE, results=hide, cache=TRUE>>=
tcq2.nota.demo <- tcq2nota[,2:16]
@ 

One examination of the data which was of interest was the relationship between the conventional and alternative scores and demographic variables. A mean was calculated for both the conventional and alternative items, and this was plotted against gender. The results are shown in Figure \ref{fig:convaltmeangender}. As can be seen, the patterns differ for men and women, though the effect is small and the error bars are quite large. For men, higher scores on the conventional forms of treatment tend to be associated with higher scores on the alternative forms of treatment, while for women, the opposite is true. 

\begin{figure}
<<convaltmeans, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE, eps=TRUE, pdf=TRUE, png=TRUE>>=
p <- ggplot(na.omit(tcq2nota), aes(x=ConvMean, y=AltMean, group=Gender))
p2 <- p+geom_smooth(method="lm")+facet_grid(.~Gender)
## p3 <- p2+facet_grid(.~Gender)
print(p2)
@   
  \caption{Regression line of Conventional treatment mean scores against Alternative treatment mean scores, stratified by Gender (regression line is a least squares fit)}
  \label{fig:convaltmeangender}
\end{figure}



\begin{figure}
<<ggplotconvaltcollege, echo=FALSE,fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
p <- ggplot(na.omit(tcq2nota), aes(x=ConvMean, y=AltMean))
p2 <- p+geom_smooth(method="lm")
p3 <- p2+facet_grid(.~College)
print(p3)
@   
  \caption{Conventional Means Regressed against Alternative treatment means, stratified based on College of study or work}
  \label{fig:convaltmeancollege}
\end{figure}


Figure \ref{fig:convaltmeancollege} shows a regression of alternative  treatment mean scores against conventional treatment mean scores, stratified based on college. It can be seen that for Arts, Science and Business and Law, increased scores on the alternative treatments were associated with increased scores on the conventional treatments, while for medicine and health, the reverse was true - which suggests that either these participants had a different relationship to these forms of treatment, or that their course of study had altered their perceptions. As can be seen from Figure \ref{fig:medhealthyear}, the second alternative appears to be the case, given that the relationship is positive in Year 1, but then turns sharply negative. 

\begin{figure}
<<medhealthyear, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
medhealth <- tcq2[with(tcq2, College=="Medicine and Health"),]
medyearplot <- ggplot(na.omit(medhealth), aes(x=ConvMean, y=AltMean))+geom_smooth(method="lm")+facet_grid(.~Year)
print(medyearplot)
@ 
  
  \caption{Relationship between Conventional and Alternative Treatment Scores in Medicine and Health Students}
  \label{fig:medhealthyear}
\end{figure}

\begin{figure}
<<ggplotpillincome, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
p <- ggplot(na.omit(tcq2nota), aes(x=ConvMean, y=AltMean))
p2 <- p+layer(geom="smooth", method="lm")
p3 <- p2+facet_grid(.~Health)
print(p3)
@   
  \caption{Regression of Alternative Treatment means against conventional treatment means, stratified by health status (where 1 is worst health and 5 is best health)}
  \label{fig:convaltmeanhealth}
\end{figure}

Figure \ref{fig:convaltmeanhealth} shows the regression of conventional treatment mean scores against alternative  treatment mean scores, stratified by Health status. It can be seen that for moderate levels of self rated health (2-4), higher scores on the conventional treatments were associated with higher scores on the alternative treatment. However, for participants who rated their health as ``Excellent'', the opposite pattern emerged. 



Next, summary scores for experience with conventional treatments and alternative treatments were calculated, and the relationships of these two variables to demographic variables were examined.

\begin{figure}
<<expconvaltgender, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
p <- ggplot(tcq2nota, aes(x=Expconv, y=Expalt))
p2 <- p+geom_smooth(method="lm")+facet_grid(.~Gender)
print(p2)
@   
  \caption{Experience with Alternative Treatments Regressed against Experience with Conventional Treatments, Stratified by Gender}
  \label{fig:expconvaltgender}
\end{figure}

\begin{figure}
<<expconvaltgender, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
p <- ggplot(tcq2nota, aes(x=Expconv, y=Expalt))
p2 <- p+layer(geom="smooth", method="lm")
p3 <- p2+facet_grid(.~College)
print(p3)
@ 
  \caption{Experience with Alternative Treatments Regressed against Experience with Conventional Treatments, Stratified by College}
  \label{fig:expconvaltgender}
\end{figure}


\begin{figure}
<<expconvaltgender, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
p <- ggplot(tcq2nota, aes(x=Expconv, y=Expalt))
p2 <- p+geom_smooth(method="lm")+facet_grid(.~Health)
print(p2)
@ 
  \caption{Experience with Alternative Treatments Regressed against Experience with Conventional Treatments, Stratified by College}
  \label{fig:expconvaltgender}
\end{figure}

Following on from the graphical exploration of the relationships between the variables, the next step was to fit a linear model on this data, eliminate variables based on the decrease in AIC, and test the model on the held out data. 

<<stepwiselm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2nota.full <- complete.cases(tcq2nota)
tcq2nota.complete <- tcq2nota[tcq2nota.full,]
pilltotlm1.nota <- lm(Pilltot~Creamtot+Injtot+Acutot+Homtot+Reitot+ Expalt+Expconv+Gender+Income+Health, data=tcq2nota.complete)
pilltot.step.nota <- stepAIC(object=pilltotlm1.nota, upper=pilltotlm1.nota,lower=~1, direction="both", k=3)

@

<<steppilla, echo=FALSE, results=tex>>=
print(xtable(summary(pilltot.step.nota), label="tab:tcq2stepnotA", caption="Results of Stepwise Regression Analysis on Splits B, C and D for Pill credibility scores"))
pilltot.pred <- predict(pilltotlm1.nota, newdata=tcq2a)
@ 

<<lmonheldoutdata, echo=FALSE, results=tex>>=
pilltotlm.holdout <- lm(Pilltot~Creamtot+Injtot+Homtot+Reitot, data=tcq2a)
print(xtable(summary(pilltotlm.holdout), label="tab:tcq2pillholdoutA", caption="Coefficients for Pill credibility Regression on Held Out Data"))
@ 


Rerunning the model on the held out data, the model was highly significant F(10,129)=28.95, $p\le 0.001$. The model had an adjusted $R^2$ of 0.4286, which equates to approximately 42\% of the variance in Pilltotal explained. The Cream and Injection variables were highly significant, while the Homeopathy and Reiki variables did not achieve significance on the held out data. 

Next, lasso and ridge regressions were performed on the Pill Total variable. 

<<pill2alasso, echo=FALSE, results=tex, cache=TRUE>>=
pill2a <- with(tcq2nota.complete, Pilltot)
predpill2a <- tcq2nota.complete[, 72:81]
predpill2a.test <- na.omit(tcq2a[,72:81])
pill2a.test <- with(na.omit(tcq2a), Pilltot)
pill2a.lasso <- penalisedRegression(predpill2a, pill2a, testdata=predpill2a.test, newy=pill2a.test, alpha=1, type="coefficients")
@

<<pill2alassoprint, echo=FALSE, results=tex>>=
print(xtable(as.matrix(pill2a.lasso), label="tab:tcq2apilllasso", caption="Coefficient Estimates for Lasso Regression using Pilltotal as a dependent variable"))
@ 

Table \ref{tab:tcq2apilllasso} shows the estimated coefficients for the lasso regression solution on held out data. As can be seen, there were small negative effects of Cream total and injection total (which is a little surprising) and a strong effect of Mean belief in conventional treatments, which is in line with expectations. 

<<pill2aridge, echo=FALSE, results=tex>>=
pill2a.ridge <- penalisedRegression(predpill2a, pill2a, predpill2a.test, alpha=0, newy=pill2a.test, type="coefficients")
print(xtable(as.matrix(pill2a.ridge), label="tab:tcq2apillridge", caption="Coefficient Estimates on Held Out Data for Pilltotal, Ridge Regression, Split A"))
@ 

Table \ref{tab:tcq2apillridge} shows the estimated coefficients for the ridge regression solution. It can be seen that the results are broadly in line with those from the lasso regression, except that ConvMean, while still important to the model has a coefficient of half the size. Note that ridge regression will not remove variables from the model, but if the coefficients are sufficiently close to zero, they can be regarded as adding little to no predictive power. 

The next step was to repeat this process using Cream total as a dependent variable.

<<stepwiselm, echo=FALSE, results=hide, cache=TRUE>>=
tcq2nota.full <- complete.cases(tcq2nota)
tcq2nota.complete <- tcq2nota[tcq2nota.full,]
creamtotlm1.nota <- lm(Creamtot~Pilltot+Injtot+Acutot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2nota.complete)
creamtot.step.nota <- stepAIC(object=creamtotlm1.nota, upper=creamtotlm1,lower=~1, direction="both", k=3)


@

<<creamstepa, echo=FALSE, results=tex>>=
print(xtable(summary(creamtot.step.nota), label="tab:creamtotlm1nota", caption="Coefficients for Cream Credibility Regression (Stepwise selection used (both forwards and backwards)"))
creamtot.pred <- predict(creamtotlm1.nota, newdata=tcq2a)
@ 

The results on the training sample are shown in Table \ref{tab:creamtotlm1nota}. The model was significant: $F(3,314)=34.24$, p-value of $p\le 0.001$. The adjusted $R^2$ for the model was 0.3861, which is extremely poor. Next the performance of the model on the held out data was assessed. 


<<lmonheldoutdatacream, echo=FALSE, results=tex>>=
creamtotlm.holdout <- lm(Creamtot~Pilltot+Injtot+Acutot+Gender+Health, data=tcq2a)
print(xtable(summary(creamtotlm.holdout), label="tab:creamlmholdoutnota", caption="Performance of Stepwise Selected Model on held out data, Cream credibility scores"))
@ 

The results for the held out data are shown in Table \ref{tab:creamlmholdoutnota}. The model was again signficiant, with an $F(6,144)=22.18$, and a p-value of $p\le 0.001$. The adjusted $R^2$ for the model increased in the holdout sample, and was equal to 0.4586. However, the demographic variables were not significant on the held out sample. 


Next, lasso and ridge regression models were fit to this variable. 

<<cream2alasso, echo=FALSE, results=tex>>=
cream2a <- with(tcq2nota.complete, Creamtot)
predcream2a <- tcq2nota.complete[, c(71, 73:81)]
predcream2a.test <- na.omit(tcq2a[,c(71, 73:81)])
cream2a.test <- with(na.omit(tcq2a), Creamtot)
cream2a.lasso <- penalisedRegression(predcream2a, cream2a, testdata=predcream2a.test, newy=cream2a.test, alpha=1, type="coefficients")
print(xtable(as.matrix(cream2a.lasso), label="tab:tcq2acreamlasso", caption="Coefficient Estimates for Creamtotal Lasso regression, Split A"))
@ 


As can be seen from Table \ref{tab:tcq2acreamlasso}, the only major preidctor was the mean belief in conventional treatments, with again a small negative effect of Pill and Injection credibility totals. This finding is strange, and it will be interesting to see if it replicates across the other splits. 

<<cream2aridge, echo=FALSE, results=tex>>=
cream2a.ridge <- penalisedRegression(predcream2a, cream2a, predcream2a.test, cream2a.test, alpha=0, type="coefficients")
print(xtable(as.matrix(cream2a.ridge), label="tab:tcq2acreamridge", caption="Coefficient Estimates for Ridge Regression on Cream Credibility, Split A"))
@ 

Table \ref{tab:tcq2acreamridge} shows a similar enough pattern to the results of the lasso regression, The coefficients have all been shrunken more, but their relative rank ordering has been retained. 

Next, the same modelling procedure was applied to the Injection credibility scores. 

<<stepwiselm, echo=FALSE, results=hide>>=
tcq2nota.full <- complete.cases(tcq2nota)
tcq2nota.complete <- tcq2nota[tcq2nota.full,]
injtotlm1.nota <- lm(Injtot~Creamtot+Pilltot+Acutot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2nota.complete)
injtot.step.nota <- stepAIC(object=injtotlm1.nota, upper=injtotlm1.nota,lower=~1, direction="both", k=3)

injtot.pred <- predict(injtotlm1.nota, newdata=tcq2a)
@ 

<<injstepa, echo=FALSE, results=tex>>=

print(xtable(summary(injtot.step.nota), label="tab:injtotlm1nota", caption="Coefficients for Injection Credibility, Selected using forwards and backwards selection (Splits B, C and D)"))
@ 
The model results shown in Table \ref{tab:injtotlm1nota} show that Cream and Pill credibility scores were excellent predictors, as were Experience with conventional treatments and Health. The model was independently significant: F(4,313)=68.35, $p\le 0.0001$, and the adjusted $R^2$ was equal to 0.4594. It is important to note that these p-values cannot be trusted due to the fact that the algorithm calculated them at each step, and so a multiple comparisions problem arises. 

This model was then applied to the held out data. 

<<lmonheldoutdatainj, echo=FALSE, results=tex>>=
injtotlm.holdout <- lm(Injtot~Creamtot+Pilltot+Expconv+Health, data=tcq2a)
print(xtable(summary(injtotlm.holdout), label="tab:injlmholdoutnota", caption="Coefficients for Injection Credibility Model on the Held Out Data (Split A)"))
@ 
Table \ref{tab:injlmholdoutnota} shows the results of the model on the hjeld out data. It can be seen that Cream credibility, Pill credibility and Health were all significant, while Experience with conventional treatments was almost significant. The model itself was significant: F(4,142)=21.4, with a p value of $p\le 0.001$, while the adjusted $R^2$ was equal to 0.3585, which is quite poor in comparison to some of the other results. 

<<inj2alasso, echo=FALSE, results=tex>>=
inj2a <- with(tcq2nota.complete, Injtot)
predinj2a <- tcq2nota.complete[, c(71:72, 74:77, 79:81)]
predinj2a.test <- na.omit(tcq2a[,c(71:72, 74:77, 79:81)])
inj2a.test <- with(na.omit(tcq2a), Injtot)
inj2a.lasso <- penalisedRegression(predinj2a, inj2a, testdata=predinj2a.test, newy=inj2a.test, alpha=1, type="coefficients")
print(xtable(as.matrix(inj2a.lasso), label="tab:tcq2ainjlasso", caption="Coefficient Estimates for Injtotal Lasso regression, Split A"))
@ 


Table \ref{tab:tcq2ainjlasso} shows the coefficient estimates for the lasso regression model. It can be seen that experience with conventional treatments had a small impact, and the two conventional treatments were retained by the model. Additionally, Reiki credibility was slightly negatively correlated. 

Next, a ridge model was fit to the same data. 

<<inj2aridge, echo=FALSE, results=tex>>=
inj2a.ridge <- penalisedRegression(predinj2a, inj2a, predinj2a.test, inj2a.test, alpha=0, type="coefficients")
print(xtable(as.matrix(inj2a.ridge), label="tab:inj2aridge", caption="Coefficient Estimates, Injection Credibility Ridge Regression Model, Split A"))
@ 

Table \ref{tab:inj2aridge} shows the estimated coefficients for the ridge regression model Injection credibility scores. It can be seen that the model is quite similar to that obtained from the lasso regression, even the coefficients are of similar magnitude. 

Next, the same procedure was applied to the Acupuncture credibility scores. 

<<stepwiselmacunota, echo=FALSE, results=hide, cache=TRUE>>=
tcq2nota.full <- complete.cases(tcq2nota)
tcq2nota.complete <- tcq2nota[tcq2nota.full,]
acutotlm1.nota <- lm(Acutot~Creamtot+Pilltot+Injtot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2nota.complete)
acutot.step.nota <- stepAIC(object=acutotlm1.nota, upper=acutotlm1.nota,lower=~1, direction="both", k=3)

acutot.pred <- predict(acutotlm1.nota, newdata=tcq2a)
@ 

<<acustepa, echo=FALSE, results=tex>>=
print(xtable(summary(acutot.step.nota), label="tab:acutotlm1nota", caption="Coefficients for Acupuncture Credibility selected using Stwpwise Forward and Back Selection"))
@ 

Table \ref{tab:acutotlm1nota} shows the estimated coefficients on the training sample. It can be seen that Cream credibility, Homeopathy credibility and Reiki credibility were the only variables retained by the procedure. The model was independently significant; F(3,314)=76.69, p=value $p\le 0.001$. The adjusted $R^2$ was equal to 0.4173. This model was then applied to the validation set.

<<lmonheldoutdataacu, echo=FALSE, results=tex>>=
Acutotlm.holdout <- lm(Acutot~Creamtot+Homtot+Reitot, data=tcq2a)
print(xtable(summary(Acutotlm.holdout), label="tab:aculmholdoutnota", caption="Coefficients for Acupuncture Credibility Scores on Held Out Data (Split A)"))
@ 

It can be seen from Table \ref{tab:aculmholdoutnota} that all of the variables remained significant in the validation set. The model was independently significant; $F(3,146)=23.89$, $p\le 0.0001$, and the adjusted $R^2$ was equal to 0.3154.


<<acu2alasso, echo=FALSE, results=tex>>=
acu2a <- with(tcq2nota.complete, Acutot)
predacu2a <- tcq2nota.complete[, c(71:73, 75:78, 80:81)]
predacu2a.test <- na.omit(tcq2a[,c(71:73, 75:78, 80:81)])
acu2a.test <- with(na.omit(tcq2a), Acutot)
acu2a.lasso <- penalisedRegression(predacu2a, acu2a, testdata=predacu2a.test, newy=acu2a.test, alpha=1, type="coefficients")
print(xtable(as.matrix(acu2a.lasso), label="tab:tcq2aaculasso", caption="Coefficient Estimates for Acutotal Lasso regression, Split A"))
@ 

Table \ref{tab:tcq2aaculasso} shows the coefficients estimated from the lasso regression procedure. It can be seen that all of the other alternative treatments had relatively large coefficients, along with Bam totals. Additionally, there was a small effect for experience with alternative treatments. 


<<acu2aridge, echo=FALSE, results=tex>>=
acu2a.ridge <- penalisedRegression(predacu2a, acu2a, predacu2a.test, acu2a.test, alpha=0, type="coefficients")
print(xtable(as.matrix(acu2a.ridge), label="tab:tcq2aacuridge", caption="Coefficient Estimates for Acupuncture Ridge Regression, Split A"))
@ 

As can be seen from Table \ref{tab:tcq2aacuridge}, the coefficient estimates for the ridge regression procedure are relatively similar to those obtained from the lasso solution, suggesting that this is a useful model. 

Next, the same procedure was applied to the Homeopathy credibility totals. 

<<stepwiselm, echo=FALSE, results=hide>>=
tcq2nota.full <- complete.cases(tcq2nota)
tcq2nota.complete <- tcq2nota[tcq2nota.full,]
homtotlm1.nota <- lm(Homtot~Creamtot+Pilltot+Injtot+Acutot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2nota.complete)
homtot.step.nota <- stepAIC(object=homtotlm1.nota, upper=homtotlm1.nota,lower=~1, direction="both", k=3)

acutot.pred <- predict(acutotlm1.nota, newdata=tcq2a)
@ 

<<homstepwise2aprint, echo=FALSE, results=tex>>=
print(xtable(summary(homtot.step.nota), label="tab:homtotlm1.nota", caption="Coefficients for Homeopathy Credibility Scores selected by Stepwise Selection (Splits B, C and D)"))
@ 

Table \ref{tab:homtotlm1nota} shows the estimated coefficients on the training set. It can be seen that Cream, Pill, Acupuncture and Reiki credibility scores were retained by the algorithm. The model was independently significant: $F(4,313)=138.4$, $p\le 0.001$. The adjusted $R^2$ for the model was equal to 0.6342. Next, the model was examined on the validation set. 

<<lmonheldoutdatacream, echo=FALSE, results=tex>>=
Homtotlm.holdout <- lm(Homtot~Creamtot+Pilltot+Acutot+Reitot, data=tcq2a)
print(xtable(summary(Homtotlm.holdout), label="tab:homlmholdoutnota", caption="Coefficients for Homeopathy Credibility on Heldout data (Splits B, C and D"))
@ 
Table \ref{tab:homlmholdoutnota} shows the performance of the model on the validation set. It can be seen that Pill and cream credibility scores are no longer significant, suggesting that their inclusion was an artifact of the selection algorithm. The model was significant: F(4,144)=29.09, $p\le 0.001$, and the adjusted $R^2$ was equal to 0.4316. 



<<hom2alasso, echo=FALSE, results=tex>>=
hom2a <- with(tcq2nota.complete, Homtot)
predhom2a <- tcq2nota.complete[, c(71:72, 76:78, 80:81)]
predhom2a.test <- na.omit(tcq2a[,c(71:74, 76:78, 80:81)])
hom2a.test <- with(na.omit(tcq2a), Homtot)
hom2a.lasso <- penalisedRegression(predhom2a, hom2a, testdata=predhom2a.test, newy=hom2a.test, alpha=1, type="coefficients")
print(xtable(as.matrix(hom2a.lasso), label="tab:tcq2ahomlasso", caption="Coefficient Estimates for Homtotal Lasso regression, Split A"))
@ 

Table \ref{tab:tcq2ahomlasso} shows the estimated coefficients derived from the lasso model. It can be seen that Reiki credibility and Bamtotal were related to the outcome, along with experience of alternative treatments.

Next, a ridge regression model was fit to the same dataset. 


<<hom2aridge, echo=FALSE, results=tex>>=
hom2a.ridge <- penalisedRegression(predhom2a, hom2a, predhom2a.test, hom2a.test, alpha=0, type="coefficients")
print(xtable(as.matrix(hom2a.ridge), label="tab:tcq2ahomridge", caption="Coefficient Estimates for Hompuncture Ridge Regression, Split A"))
@ 

Table \ref{tab:tcq2ahomridge} shows the estimated coefficients from the ridge model. It can be seen that these are extremely similar to those obtained from the lasso model, suggesting that these coefficients are associated with the response variable in this sample. 

Next, the selection and testing procedure was applied to the Reiki totals. 
<<stepwiselm, echo=FALSE, results=hide>>=
tcq2nota.full <- complete.cases(tcq2nota)
tcq2nota.complete <- tcq2nota[tcq2nota.full,]
reitotlm1.nota <- lm(Reitot~Creamtot+Pilltot+Injtot+Acutot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2nota.complete)
reitot.step.nota <- stepAIC(object=reitotlm1.nota, upper=reitotlm1.nota,lower=~1, direction="both", k=3)

reitot.pred <- predict(reitotlm1.nota, newdata=tcq2a)
@ 

<<rei2astepwiseprint, echo=FALSE, results=tex>>=
print(xtable(summary(reitot.step.nota), label="tab:reitotlm1nota", caption="Coefficients for Reiki Credibility Selected using Stepwise Selection"))
@ 

Table \ref{tab:reitotlm1nota} shows the estimated coefficients on the training set. The algorithm retained Injection total, Acupuncture and the Experience with alternative treatments variables. The model was significant; F(3,314)=67.98, $p\le 0.001$. The adjusted $R^2$ for the model was equal to 0.388. Next, the performance of these  variables was examined on the validation set. 

<<lmonheldoutdatacream, echo=FALSE, results=tex>>=
Reitotlm.holdout <- lm(Reitot~Injtot+Expalt+Acutot, data=tcq2a)
print(xtable(summary(Reitotlm.holdout), label="tab:reilmholdoutnota", caption="Coefficients for Reiki Linear Regression on Heldout Data"))
@ 

Table \ref{tab:reilmholdoutnota} shows the estimated coefficients on the validation set. It can be seen that all variables remain significant. The model itself was significant:F(3,139)=17.71, $p\le 0.001$. The adjusted $R^2$ value for the model on the validation set was equal to 0.2609.

<<rei2alasso, echo=FALSE, results=tex>>=
rei2a <- with(tcq2nota.complete, Reitot)
predrei2a <- tcq2nota.complete[, c(71:75, 77:78, 80:81)]
predrei2a.test <- na.omit(tcq2a[,c(71:75, 77:78, 80:81)])
rei2a.test <- with(na.omit(tcq2a), Reitot)
rei2a.lasso <- penalisedRegression(predrei2a, rei2a, testdata=predrei2a.test, newy=rei2a.test, alpha=1, type="coefficients")
print(xtable(as.matrix(rei2a.lasso), label="tab:tcq2areilasso", caption="Coefficient Estimates for Reitotal Lasso regression, Split A"))
@ 

Table \ref{tab:tcq2areilasso} shows the estimated coefficients for the lasso model in this split. It can be seen that Homeopathy credibility totals have a large impact on the variable, while acupuncture totals are not related. No other variable has an major impact on the model. 

<<rei2aridge, echo=FALSE, results=tex>>=
rei2a.ridge <- penalisedRegression(predrei2a, rei2a, predrei2a.test, rei2a.test, alpha=0, type="coefficients")
print(xtable(as.matrix(rei2a.ridge), label="tab:tcq2areiridge", caption="Coefficient Estimates for Reipuncture Ridge Regression, Split A"))
@ 

Table \ref{tab:tcq2areiridge} shows the estimated coefficients obtained from the ridge regression model. It can be seen that they are relatively similiar in pattern to those obtained from the lasso regression method. 

Finally, the stepwise variable selection procedure was applied to the Beliefs about Medicine Total (long form).

<<stepwiselm, echo=FALSE, results=hide>>=
tcq2nota.full <- complete.cases(tcq2nota)
tcq2nota.complete <- tcq2nota[tcq2nota.full,]
## tcq2nota.complete$bamscale <- apply(bam2ascale, 1, mean, na.rm=TRUE)
## tcq2a$bamscale look at using reduced bam scale
bamtotlm1.nota <- lm(Bamtot~Creamtot+Pilltot+Injtot+Acutot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2nota.complete)
bamtot.step.nota <- stepAIC(object=bamtotlm1.nota, upper=bamtotlm1.nota,lower=~1, direction="both", k=3)

bamtot.pred <- predict(bamtotlm1.nota, newdata=tcq2a)
@ 
<<bamtot2aprint, echo=FALSE, results=tex>>=
print(xtable(summary(bamtot.step.nota), label="tab:bamtotlm1nota", caption="Coefficients for Beliefs About Medicine Totals Selected using Stepwise Selection"))
@ 
As can be seen from Table \ref{tab:bamtotlm1nota}, the algorithm kept six variables in the model. Of these conventional items have a negative loading, and the Acupuncture item has a positive loading. Interestingly enough, the experience with conventional treatments variable has a negative loading on the dependent variable also, as do income and Health. Next, the fit of the model on the held out data was examined. 

<<lmonheldoutdatabam, echo=FALSE, results=tex>>=
Bamtotlm.holdout <- lm(Bamtot~Creamtot+Pilltot+Expconv+Acutot+Income+Health, data=tcq2a)
print(xtable(summary(Bamtotlm.holdout), label="tab:Bamlmholdoutnota", caption="Coefficients for BAM totals on held out data (Splits B, C and D)"))
@ 

Of the six variables selected by the algorithm, only Cream total and Income remain significant, as can be seen from Table \ref{tab:Bamlmholdoutnota}. The model was not significant, $F(6,130)=1.887$, $p=0.0877$, while the adjusted $R^2$ was equal to 0.037. 

\subsubsection{Split B}
\label{sec:split-2}

Next, the same procedure was repeated for all totals using the data from Splits A,C and D, while holding out Split B as a validation set. 

<<pilltotlmnotb, echo=FALSE, results=hide>>=
tcq2notb.full <- complete.cases(tcq2notb)
tcq2notb.complete <- tcq2notb[tcq2notb.full,]
pilltotlm1.notb <- lm(Pilltot~Creamtot+Injtot+Acutot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notb.complete)
pilltot.step.notb <- stepAIC(object=pilltotlm1.notb, upper=pilltotlm1.notb,lower=~1, direction="both", k=3)
pilltot.pred <- predict(pilltotlm1.notb, newdata=tcq2b)

@ 

<<pillstepb, echo=FALSE, results=tex>>=
print(xtable(summary(pilltot.step.notb), label="tab:pilltotnotbsteplm", caption="Coefficients for Pill Credibility Scores selected using Stepwise Selection on Splits A, C and D"))
@ 

Table \ref{tab:pilltotnotbsteplm} shows the performance of the stepwise algorithm on the training sample. It can be seen that with a penalisation factor of three for the parameters in the model (as opposed to the classic AIC penalty of two), only four variables (Creamtot, Injtot, Acutot, and Experience with conventional treatments) are retained by the algorithm. Both Acutot and Expconv have a negative sign, which would be expected for acupuncture scores, but the negative coefficient for the experience with conventional treatments is surprising. It may be that having more experience with conventional forms of painkilling treatments is linked to a history of problems with pain, as as pills tend to be the most readily available pain treatment, they may be regarded as less effective. The $R^2$ adjusted for parameters was equal to 0.4491, which is lower than the previous training set. The model was independently significant, with an $F(4,313)=65.61$, $p\le 0.0001$. Next, the performance of this model on the held out data was assessed. 

<<pilltotnotbheldout, echo=FALSE, results=tex>>=
pilltotnotb.heldout.lm <- lm(Pilltot~Creamtot+Injtot+Acutot+Expconv, data=tcq2b)
print(xtable(summary(pilltotnotb.heldout.lm), label="tab:pilltotnotbheldout", caption="Coefficients for Pill Credibility Scores, on held out data (Splits A, C and D)"))
@ 

It can be seen from Table \ref{tab:pilltotnotbheldout} that this model performs extremely well on the held out data, with a highly significant model - F(4,162)=65.79, $p\le 0.0001$, and an adjusted $R^2$ of .6096, indicating that 60\% of the variance in the Pilltotals can be explained by the predictor variables. Its worth noting that the sign of the Experience with conventional treatments variable has reversed, and is now in line with expectations. 

<<pill2blasso, echo=FALSE, results=tex>>=
pill2b <- with(tcq2notb.complete, Pilltot)
predpill2b <- tcq2notb.complete[, 72:77,79:81]
predpill2b.test <- na.omit(tcq2b[,72:77, 79:81])
pill2b.test <- with(na.omit(tcq2b), Pilltot)
pill2b.lasso <- penalisedRegression(predpill2b, pill2b, testdata=predpill2b.test, newy=pill2b.test, alpha=1, type="coefficients")
print(xtable(as.matrix(pill2b.lasso), label="tab:tcq2bpilllasso", caption="Coefficient Estimates for Lasso Regression using Pilltotal as a dependent variable, Split B"))
@ 

Table \ref{tab:tcq2bpilllasso} shows the estimated coefficients for this model. It can be seen that Cream and Injection credibility have a large impact on the outcome, and there are small negative coefficients for the BAM scale and the alternative credibility scores. 

Next, a ridge regression model was fit to the data. 

<<pill2bridge, echo=FALSE, results=tex>>=
pill2b.ridge <- penalisedRegression(predpill2b, pill2b, predpill2b.test, alpha=0, newy=pill2b.test, type="coefficients")
print(xtable(as.matrix(pill2b.ridge), label="tab:tcq2bpillridge", caption="Coefficient Estimates on Held Out Data for Pilltotal, Ridge Regression, Split B"))
@ 

Table \ref{tab:tcq2bpillridge} shows the estimated coefficients for the ridge regression model. It can be seen that they are mostly in line with the coefficients obtained from the lasso regression method. 

<<creamtotlmnotb, echo=FALSE, results=hide>>=
tcq2notb.full <- complete.cases(tcq2notb)
tcq2notb.complete <- tcq2notb[tcq2notb.full,]
creamtotlm1.notb <- lm(Creamtot~Pilltot+Injtot+Acutot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notb.complete)
creamtot.step.notb <- stepAIC(object=creamtotlm1.notb, upper=creamtotlm1notb,lower=~1, direction="both", k=3)
creamtot.pred <- predict(creamtotlm1.notb, newdata=tcq2b)

@ 

<<creamstepb, echo=FALSE, results=tex>>=
print(xtable(summary(creamtot.step.notb), label="tab:creamtotnotbsteplm", caption="Coefficients for Cream Credibility selected by Stepwise cirtierion, Splits A, C and D"))
@ 

Table \ref{tab:creamtotnotbsteplm} shows the estimated coefficients for the regression of Creamtot on the other variables. Only four variables were retained. All other variables appear to relate in the expected fashion, as above in Split A with the exception of the coefficient on gender which suggest that being either male or female lowers levels of Cream credibility. Next, this model was tested on the validation set. 

<<creamtotnotbheldout, echo=FALSE, results=tex>>=
creamtotnotb.heldout.lm <- lm(Creamtot~Pilltot+Injtot+Acutot+Gender, data=tcq2b)
print(xtable(summary(creamtotnotb.heldout.lm), label="tab:creamtotnotbheldout", caption="Regression Coefficients for Cream Credibility Scores on held out data (Split B)"))
@ 


Table \ref{tab:creamtotnotbheldout} shows the performance of the model on the validation set. It can be seen that Pilltot and Acutot, along with Health, remain significant, but overall performance is worse than on the training set.  The model was significant; F(8,156)=13.02, $p\le 0.001$. The adjusted $R^2$ value was 0.3696.  

<<cream2blasso, echo=FALSE, results=tex>>=
cream2b <- with(tcq2notb.complete, Creamtot)
predcream2b <- tcq2notb.complete[, c(71,73:77,79:81)]
predcream2b.test <- na.omit(tcq2b[,c(71,73:77, 79:81)])
cream2b.test <- with(na.omit(tcq2b), Creamtot)
cream2b.lasso <- penalisedRegression(predcream2b, cream2b, testdata=predcream2b.test, newy=cream2b.test, alpha=1, type="coefficients")
print(xtable(as.matrix(cream2b.lasso), label="tab:tcq2bcreamlasso", caption="Coefficient Estimates for Lasso Regression using Creamtotal as a dependent variable, Split B"))
@ 

Table \ref{tab:tcq2bcreamlasso} shows the estimated coefficients for the lasso regression on the cream data in this split. It can be seen that not many variables got removed from the model, suggesting that none of them are particularly important to the response. 

Next, a ridge regression model was fit to this dataset. 

<<cream2bridge, echo=FALSE, results=tex>>=
cream2b.ridge <- penalisedRegression(predcream2b, cream2b, predcream2b.test, alpha=0, newy=cream2b.test, type="coefficients")
print(xtable(as.matrix(cream2b.ridge), label="tab:tcq2bcreamridge", caption="Coefficient Estimates on Held Out Data for Creamtotal, Ridge Regression, Split B"))
@ 

Table \ref{tab:tcq2bcreamridge} shows the estimated coefficients for the ridge regression model. It can be seen that they are mostly in line with those achieved from the lasso regression method. 

Next, the stepwise selection procedure was carried out for the Injection credibility total.

<<injtotlmnotb, echo=FALSE, results=hide>>=
tcq2notb.full <- complete.cases(tcq2notb)
tcq2notb.complete <- tcq2notb[tcq2notb.full,]
injtotlm1.notb <- lm(Injtot~Pilltot+Creamtot+Acutot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notb.complete)
injtot.step.notb <- stepAIC(object=injtotlm1.notb, upper=injtotlm1notb,lower=~1, direction="both", k=3)
injtot.pred <- predict(injtotlm1.notb, newdata=tcq2b)

@ 
<<injtot2bstepwise, echo=FALSE, results=tex>>=
print(xtable(summary(injtot.step.notb), label="tab:injtotnotbsteplm", caption="Coefficients for Injection Credibility Scores using Stepwise Selection, Splits A, C and D"))
@ 
Table \ref{tab:injtotnotbsteplm} shows the performance of the model on the training data. It can be seen that Pill, Cream, Acupuncture and Reiki credibility totals are retained by the algorithm, along with experience with conventional treatments. This model's performance on the held out data was now assessed. 

<<injtotnotbheldout, echo=FALSE, results=tex>>=
injtotnotb.heldout.lm <- lm(Injtot~Pilltot+Creamtot+Acutot+Reitot+Expconv, data=tcq2b)
print(xtable(summary(injtotnotb.heldout.lm), label="tab:injtotnotbheldout", caption="Coefficients for Injection Credibility Scores on Held out data (Split B)"))
@ 

Table \ref{tab:injtotnotbheldout} shows the estimated coefficients on the held out data. It can be seen that only Pill credibility remains significant. The model is significant; F(5,159)=30.37, $p\le 0.0001$, and has an adjusted $R^2$ of .4724, which is excellent performance on the validation set. This is not really that surprising, as the Factor Analyses carried out earlier did reduce Pills and Injections to one factor in all of the five factor solutions to the TCQ. 

<<inj2blasso, echo=FALSE, results=tex>>=
inj2b <- with(tcq2notb.complete, Injtot)
predinj2b <- tcq2notb.complete[, c(71:72,74:77,79:81)]
predinj2b.test <- na.omit(tcq2b[,c(71:72,74:77, 79:81)])
inj2b.test <- with(na.omit(tcq2b), Injtot)
inj2b.lasso <- penalisedRegression(predinj2b, inj2b, testdata=predinj2b.test, newy=inj2b.test, alpha=1, type="coefficients")
print(xtable(as.matrix(inj2b.lasso), label="tab:tcq2binjlasso", caption="Coefficient Estimates for Lasso Regression using Injtotal as a dependent variable, Split B"))
@ 

Table \ref{tab:tcq2binjlasso} shows the estimated coefficients for the lasso model on injection credibility scores. It can be seen that the other two conventional treatments show a strong association with the outcome, while there is an effect of experience with conventional treatments and no real impact of the alternative credibility scores. 

<<inj2bridge, echo=FALSE, results=tex>>=
inj2b.ridge <- penalisedRegression(predinj2b, inj2b, predinj2b.test, alpha=0, newy=inj2b.test, type="coefficients")
print(xtable(as.matrix(inj2b.ridge), label="tab:tcq2binjridge", caption="Coefficient Estimates on Held Out Data for Injtotal, Ridge Regression, Split B"))
@ 

Table \ref{tab:tcq2binjridge} shows the estimated coefficients for the ridge regression model on injection totals. It can be seen that the coefficients are quite similar to those from the lasso regression shown above. 

Next, the stepwise selection and validation procedure was carried out on the Acupuncture total.

<<acutotlmnotb, echo=FALSE, results=hide>>=
tcq2notb.full <- complete.cases(tcq2notb)
tcq2notb.complete <- tcq2notb[tcq2notb.full,]
acutotlm1.notb <- lm(Acutot~Pilltot+Creamtot+Injtot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notb.complete)
acutot.step.notb <- stepAIC(object=acutotlm1.notb, upper=acutotlm1notb,lower=~1, direction="both", k=3)
acutot.pred <- predict(acutotlm1.notb, newdata=tcq2b)

@ 

<<acustepb, echo=FALSE, results=tex>>=
print(xtable(summary(acutot.step.notb), label="tab:acutotnotbsteplm", caption="Coefficients for Acupuncture Credibility Scores, Selected using Stepwise criterion (k=3)"))
@ 

Table \ref{tab:acutotnotbsteplm} shows the retained coefficients following stepwise selection. Pills, Creams, Injections, Homeopathy and Reiki are left in the model by the algorithm. This model was then tested on the held out data. 

<<acutotnotbheldout, echo=FALSE, results=tex>>=
acutotnotb.heldout.lm <- lm(Acutot~Pilltot+Creamtot+Injtot+Reitot+Homtot, data=tcq2b)
print(xtable(summary(acutotnotb.heldout.lm), label="tab:acutotnotbheldout", caption="Coefficients for Stepwise Model on held out data (Split B)"))
@ 

Table \ref{tab:acutotnotbheldout} shows the estimated coefficients on the validation set. It can be seen that only the other alternative treatment variables have remained significant. The model was significant; $F(5,164)=27.91$, $p\le 0.0001$, and the adjusted $R^2$ was equal to 0.4433. 

<<acu2blasso, echo=FALSE, results=tex>>=
acu2b <- with(tcq2notb.complete, Acutot)
predacu2b <- tcq2notb.complete[, c(71:73,75:78,80:81)]
predacu2b.test <- na.omit(tcq2b[,c(71:73,75:78,80:81)])
acu2b.test <- with(na.omit(tcq2b), Acutot)
acu2b.lasso <- penalisedRegression(predacu2b, acu2b, testdata=predacu2b.test, newy=acu2b.test, alpha=1, type="coefficients")
print(xtable(as.matrix(acu2b.lasso), label="tab:tcq2baculasso", caption="Coefficient Estimates for Lasso Regression using Acutotal as a dependent variable, Split B"))
@ 

Table \ref{tab:tcq2baculasso} shows the coefficients for the lasso regression on the acupuncture credibility totals. It can be seen that the coefficients for the other alternative treatments are quite high, as is the coefficient for cream. This, along with some of the IRT analyses suggesting that cream is the least credible of the conventional treatments would seem to suggest that what is being measured here is the absence of faith in a treatment rather than its presence. 


<<acu2bridge, echo=FALSE, results=tex>>=
acu2b.ridge <- penalisedRegression(predacu2b, acu2b, predacu2b.test, alpha=0, newy=acu2b.test, type="coefficients")
print(xtable(as.matrix(acu2b.ridge), label="tab:tcq2bacuridge", caption="Coefficient Estimates on Held Out Data for Acutotal, Ridge Regression, Split B"))
@ 

It can be seen from Table \ref{tab:tcq2bacuridge} that the ridge regression is quite similar to the lasso fit. Interestingly enough, pilltotal did not get shrunk as much in this model and shows a negative correlation with Acupuncture credibility (as would be expected). The strange positive correlation with Cream credibility remains.

Next, the Homeopathy total was regressed on the other predictors using stepwise selection and tested against the held out data.

<<homtotlmnotb, echo=FALSE, results=hide>>=
tcq2notb.full <- complete.cases(tcq2notb)
tcq2notb.complete <- tcq2notb[tcq2notb.full,]
homtotlm1.notb <- lm(Homtot~Pilltot+Creamtot+Injtot+Acutot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notb.complete)
homtot.step.notb <- stepAIC(object=homtotlm1.notb, upper=homtotlm1notb,lower=~1, direction="both", k=3)
homtot.pred <- predict(homtotlm1.notb, newdata=tcq2b)

@ 

<<homstepb, echo=FALSE, results=tex>>=
print(xtable(summary(homtot.step.notb), label="tab:homtotnotbsteplm", caption="Coefficients for Homeopathy Credibility Scores, stepwise selection method"))
@ 

Table \ref{tab:homtotnotbsteplm} shows the estimates for the regression coefficients on the training set. It can be seen that again, Acupuncture and Reiki appear to be the best predictors, though the Cream total is strongly negatively associated with the response variable.

<<homtotnotbheldout, echo=FALSE, results=tex>>=
homtotnotb.heldout.lm <- lm(Homtot~Pilltot+Creamtot++Reitot+Acutot, data=tcq2b)
print(xtable(summary(homtotnotb.heldout.lm), label="tab:homtotnotbheldout", caption="Coefficients for Stepwise homeopathy credibility model on held out data"))
@ 

Table \ref{tab:homtotnotbheldout} shows the estimated coefficients on the validation set. It can be seen that the alternative treatments are the only ones which have remained significant. Note that the intercept is not significant, which suggests that the mean level of the response variable was not significantly different from 0 (conditional on the other variables in the model). The model itself was significant; F(4,165)=60.48, $p\le 0.0001$, and the adjusted $R^2$ of the model was equal to 0.5847. 

<<hom2blasso, echo=FALSE, results=tex>>=
hom2b <- with(tcq2notb.complete, Homtot)
predhom2b <- tcq2notb.complete[, c(71:74,76:78,80:81)]
predhom2b.test <- na.omit(tcq2b[,c(71:74,76:78,80:81)])
hom2b.test <- with(na.omit(tcq2b), Homtot)
hom2b.lasso <- penalisedRegression(predhom2b, hom2b, testdata=predhom2b.test, newy=hom2b.test, alpha=1, type="coefficients")
print(xtable(as.matrix(hom2b.lasso), label="tab:tcq2bhomlasso", caption="Coefficient Estimates for Lasso Regression using Homtotal as a dependent variable, Split B"))
@ 

Table \ref{tab:tcq2bhomlasso} shows the estimated coefficients for the lasso regression on homeopathy. Interestingly, the signs of Pill and Cream credibility have reversed in this mode. The largest coefficient is for Reiki, and the coefficient for Beliefs About Medicine is also quite large. 

Next, a ridge regression fit was carried out for this dataset. 

<<hom2bridge, echo=FALSE, results=tex>>=
hom2b.ridge <- penalisedRegression(predhom2b, hom2b, predhom2b.test, alpha=0, newy=hom2b.test, type="coefficients")
print(xtable(as.matrix(hom2b.ridge), label="tab:tcq2bhomridge", caption="Coefficient Estimates on Held Out Data for Homtotal, Ridge Regression, Split B"))
@ 

It can be seen from Table \ref{tab:tcq2bhomridge} that the ridge regression model gives almost the same coefficients as did the lasso fit above. 

Next, the same procedure was applied to the Reiki credibility score. 

<<reitotlmnotb, echo=FALSE, results=hide>>=
tcq2notb.full <- complete.cases(tcq2notb)
tcq2notb.complete <- tcq2notb[tcq2notb.full,]
reitotlm1.notb <- lm(Reitot~Creamtot+Injtot+Acutot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notb.complete)
reitot.step.notb <- stepAIC(object=reitotlm1.notb, upper=reitotlm1notb,lower=~1, direction="both", k=3)
reitot.pred <- predict(reitotlm1.notb, newdata=tcq2b)

@

<<reistepb, echo=FALSE, results=tex>>=
print(xtable(summary(reitot.step.notb), label="tab:reitotnotbsteplm", caption="Coefficients for Reiki Credibility Scores, stepwise selection method"))
@ 

Table \ref{tab:reitotnotbsteplm} shows the estimated best model from the training set. The model is smaller than usual, but all the coefficients have the expected sign. The performance of this model was then applied to the training set. 

<<reitotnotbheldout, echo=FALSE, results=tex>>=
reitotnotb.heldout.lm <- lm(Reitot~Injtot+Acutot+Homtot, data=tcq2b)
print(xtable(summary(reitotnotb.heldout.lm), label="tab:reitotnotbheldout", caption="Regression Coefficients for Reiki Credibility Scores on Held out data (Split B)"))
@ 
Table \ref{tab:reitotnotbheldout} shows the model's performance on the held out data. All predictors remain significant, and the model was significant as a whole; $F(3,167)=78.23$, $p\le 0.0001$, and the adjusted $R^2$ was equal to 0.5768. 

<<rei2blasso, echo=FALSE, results=tex>>=
rei2b <- with(tcq2notb.complete, Reitot)
predrei2b <- tcq2notb.complete[, c(71:75,77:78,80:81)]
predrei2b.test <- na.omit(tcq2b[,c(71:75,77:78,80:81)])
rei2b.test <- with(na.omit(tcq2b), Reitot)
rei2b.lasso <- penalisedRegression(predrei2b, rei2b, testdata=predrei2b.test, newy=rei2b.test, alpha=1, type="coefficients")
print(xtable(as.matrix(rei2b.lasso), label="tab:tcq2breilasso", caption="Coefficient Estimates for Lasso Regression using Reitotal as a dependent variable, Split B"))
@ 

Table \ref{tab:tcq2breilasso} shows the estimated coefficients for this model. It can be seen that Homeopathy credibility has the largest coefficient, while almost all of the conventional credibility scores have been shrunken to zero (or almost, in the case of Injection credibility). 

Next, a ridge regression model was applied to this dataset. 

<<rei2bridge, echo=FALSE, results=tex>>=
rei2b.ridge <- penalisedRegression(predrei2b, rei2b, predrei2b.test, alpha=0, newy=rei2b.test, type="coefficients")
print(xtable(as.matrix(rei2b.ridge), label="tab:tcq2breiridge", caption="Coefficient Estimates on Held Out Data for Reitotal, Ridge Regression, Split B"))
@ 

Table \ref{tab:tcq2breiridge} shows the estimated  coefficients for a ridge regression on Reiki credibility. It can be seen that the coefficients are quite similar to those of the lasso model, further validating this solution. 



\subsubsection{Split C}
\label{sec:split-3}

Next, the same series of analyses was performed using the data from Splits A, B and D, and retaining Split C as a hold out sample. 

<<pilltotlmnotc, echo=FALSE, results=hide>>=
tcq2notc.full <- complete.cases(tcq2notc)
tcq2notc.complete <- tcq2notc[tcq2notc.full,]
pilltotlm1.notc <- lm(Pilltot~Creamtot+Injtot+Acutot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notc.complete)
pilltot.step.notc <- stepAIC(object=pilltotlm1.notc, upper=pilltotlm1notc,lower=~1, direction="both", k=3)
#pilltot.pred <- predict(pilltotlm1.notc, newdata=tcq2c)


@ 

<<pillstepc, echo=FALSE, results=tex>>=
print(xtable(summary(pilltot.step.notc), label="tab:pilltotnotcsteplm", caption="Coefficients for Pill Credibility Scores, stepwise selection (Splits A, B and D)"))
@ 

The model shown in Table \ref{tab:pilltotnotcsteplm} contains almost the same four variables that were observed in Split 2 (with the inclusion of the Reiki total and the dropping of the Acupuncture total).  This suggests that these variables are likely to be truly related to Pill total credibility scores, as it is unlikely that random variation would account for the same set of four variables coming from the procedure twice in a row.  The $R^2$ for this model was equal to 0.4717, and the model was highly significant: F(4,299)=68.65, $p\le 0.0001$. These p values and test statistics are likely to be biased due to the automated inclusion and exclusion of variables for the model, and the true test is in the performance of the model on held-out data. 

<<pilltotnotbheldout, echo=FALSE, results=tex>>=
pilltotnotc.heldout.lm <- lm(Pilltot~Creamtot+Injtot+Acutot+Expconv, data=tcq2c)
print(xtable(summary(pilltotnotc.heldout.lm), label="tab:pilltotnotcheldout", caption="Performance of Stepwise Model on Held Out Data (split C)"))
@ 

This model did not fit quite as well as that in Split 2, but nonetheless, performance was acceptable. Table \ref{tab:pilltotnotcheldout} shows the estimated regression coefficients. While Cream and Injection credibility scores are still highly significant, Reiki and Experience with Conventional Treatments do not perform well on the held out data. The model itself is still highly significant; F(4,154)=34.53, $p\le 0.001$ and the adjusted $R^2$ is equal to 0.4591. 

<<pill2classo, echo=FALSE, results=tex>>=
pill2c <- with(tcq2notb.complete, Pilltot)
predpill2c <- tcq2notb.complete[, 72:77,79:81]
predpill2c.test <- na.omit(tcq2c[,72:77, 79:81])
pill2c.test <- with(na.omit(tcq2c), Pilltot)
pill2c.lasso <- penalisedRegression(predpill2c, pill2c, testdata=predpill2c.test, newy=pill2c.test, alpha=1, type="coefficients")
print(xtable(as.matrix(pill2c.lasso), label="tab:tcq2cpilllasso", caption="Coefficient Estimates for Lasso Regression using Pilltotal as a dependent variable, Split C"))
@ 



Table \ref{tab:tcq2cpilllasso} shows the estimated coefficients for the lasso model in this split. It can be seen that the other conventional treatments have quite high coefficients, while those of the alternative treatments have quite small negative coefficients, in line with expectations. 

Next, a ridge regression model was fit to this variable. 

<<pill2cridge, echo=FALSE, results=tex>>=
pill2c.ridge <- penalisedRegression(predpill2c, pill2c, predpill2c.test, alpha=0, newy=pill2c.test, type="coefficients")
print(xtable(as.matrix(pill2c.ridge), label="tab:tcq2cpillridge", caption="Coefficient Estimates on Held Out Data for Pilltotal, Ridge Regression, Split C"))
@ 

Table \ref{tab:tcq2cpillridge} shows the estimated coefficients for the ridge model, and there are quite similar to those of the lasso model. 


<<creamtotlmnotc, echo=FALSE, results=hide>>=
tcq2notc.full <- complete.cases(tcq2notc)
tcq2notc.complete <- tcq2notc[tcq2notc.full,]
creamtotlm1.notc <- lm(Creamtot~Creamtot+Injtot+Acutot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notc.complete)
creamtot.step.notc <- stepAIC(object=creamtotlm1.notc, upper=creamtotlm1notc,lower=~1, direction="both", k=3)
#creamtot.pred <- predict(creamtotlm1.notc, newdata=tcq2c)

@ 

<<creamstepc, echo=FALSE, results=tex>>=
print(xtable(summary(creamtot.step.notc), label="tab:creamtotnotcsteplm", caption="Coefficients for Cream Credibility Stepwise Selection Method (Splits A, B and D)"))
@ 

Table \ref{tab:creamtotnotcsteplm} shows the estimated coefficients for the regression of cream total against the other predictor variables, using a forwards and backwards stepwise algorithm.  It can be seen that Injection, Acupuncture, Experience with Alternative Treatments and Health all appear to be good predictors on the basis of this model. Next, the model is tested against the validation set. 

<<creamtotnotbheldout, echo=FALSE, results=tex>>=
creamtotnotc.heldout.lm <- lm(Creamtot~Injtot+Acutot+Expalt+Health, data=tcq2c)
print(xtable(summary(creamtotnotc.heldout.lm), label="tab:creamtotnotcheldout", caption="Performance of Stepwise Model for Cream Credibility Scores on Held Out Data (Split C)"))
@ 

Table \ref{tab:creamtotnotcheldout} shows that only Injection total remains significant on the validation set. The model was significant; F(4,153)=18.22, $p\le 0.00001$. The adjusted $R^2$ for the model was equal to 0.3049. 

<<cream2classo, echo=FALSE, results=tex>>=
cream2c <- with(tcq2notb.complete, Creamtot)
predcream2c <- tcq2notb.complete[, c(71,73:77,79:81)]
predcream2c.test <- na.omit(tcq2c[,c(71,73:77,79:81)])
cream2c.test <- with(na.omit(tcq2c), Creamtot)
cream2c.lasso <- penalisedRegression(predcream2c, cream2c, testdata=predcream2c.test, newy=cream2c.test, alpha=1, type="coefficients")
print(xtable(as.matrix(cream2c.lasso), label="tab:tcq2ccreamlasso", caption="Coefficient Estimates for Lasso Regression using Creamtotal as a dependent variable, Split B"))
@ 


Table \ref{tab:tcq2ccreamlasso} shows the estimated coefficients for the lasso regression model in this split. It can be seen that the other conventional treatments appear to exert a strong impact on the scores, and there are some negative correlations between Cream credibility and and the alternative treatments, which is to be expected. 

<<cream2cridge, echo=FALSE, results=tex>>=
cream2c.ridge <- penalisedRegression(predcream2c, cream2c, predcream2c.test, alpha=0, newy=cream2c.test, type="coefficients")
print(xtable(as.matrix(cream2c.ridge), label="tab:tcq2ccreamridge", caption="Coefficient Estimates on Held Out Data for Creamtotal, Ridge Regression, Split C"))
@ 


Table \ref{tab:tcq2ccreamridge} shows the estimated coefficients from the ridge regression model. It can be seen that these are quite similar to the coefficients from the lasso regression. 

Next, the stepwise selection and validation procedure was applied to the Injection credibility scores.

<<injtotlmnotc, echo=FALSE, results=hide>>=
tcq2notc.full <- complete.cases(tcq2notc)
tcq2notc.complete <- tcq2notc[tcq2notc.full,]
injtotlm1.notc <- lm(Injtot~Creamtot+Pilltot+Acutot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notc.complete)
injtot.step.notc <- stepAIC(object=injtotlm1.notc, upper=injtotlm1notc,lower=~1, direction="both", k=3)
#injtot.pred <- predict(injtotlm1.notc, newdata=tcq2c)

@ 


<<injstepc, echo=FALSE, results=tex>>=
print(xtable(summary(injtot.step.notc), label="tab:injtotnotcsteplm", caption="Coefficients for Injection Credibility Scores, stepwise Selection, Splits A, B and D"))
@ 

Table \ref{tab:injtotnotcsteplm} shows that the algorithm retained three variables, Creamtotal, Pilltotal and Experience with conventional treatments, all with positive loadings as expected. Next, the fit of this model was examined on the validation data. 

<<injtotnotbheldout, echo=FALSE, results=tex>>=
injtotnotc.heldout.lm <- lm(Injtot~Creamtot+Pilltot+Expconv, data=tcq2c)
print(xtable(summary(injtotnotc.heldout.lm), label="tab:injtotnotcheldout", caption="Coefficients from Stepwise model, Injection Credibility on Held out data (Split C)"))
@ 

Table \ref{tab:injtotnotcheldout} shows that all three variables remained significant when tested on the validation set. The model was significant; $F(3,159)=46.77$, $p\le 0.0001$ and had an adjusted $R^2$ of 0.4587. 


<<inj2classo, echo=FALSE, results=tex>>=
inj2c <- with(tcq2notb.complete, Injtot)
predinj2c <- tcq2notb.complete[, c(71:72,74:77,79:81)]
predinj2c.test <- na.omit(tcq2c[,c(71:72,74:77,79:81)])
inj2c.test <- with(na.omit(tcq2c), Injtot)
inj2c.lasso <- penalisedRegression(predinj2c, inj2c, testdata=predinj2c.test, newy=inj2c.test, alpha=1, type="coefficients")
print(xtable(as.matrix(inj2c.lasso), label="tab:tcq2cinjlasso", caption="Coefficient Estimates for Lasso Regression using Injtotal as a dependent variable, Split C"))
@ 

Table \ref{tab:tcq2cinjlasso} shows the estimates for the injection credibility model. Ity can be seen that there are large coefficients for the othe two conventional treatments, while those for the alternative treatments have been sunk nearly to zero. 

Next a ridge regression model was applied to this dataset.

<<inj2cridge, echo=FALSE, results=tex>>=
inj2c.ridge <- penalisedRegression(predinj2c, inj2c, predinj2c.test, alpha=0, newy=inj2c.test, type="coefficients")
print(xtable(as.matrix(inj2c.ridge), label="tab:tcq2cinjridge", caption="Coefficient Estimates on Held Out Data for Injtotal, Ridge Regression, Split C"))
@ 

Table \ref{tab:tcq2cinjridge} shows the estimated coefficients for the ridge regression model. It can be seen that the estimated coefficients and patterns are quite similar to that seen with the lasso regression model. 
Note that experience with alternative treatments correlated negatively with the credibility scores for injections in both models, which is interesting. 

Next, this procedure was applied to the Acupuncture mean score in Split C. 

<<acutotlmnotc, echo=FALSE, results=hide>>=
tcq2notc.full <- complete.cases(tcq2notc)
tcq2notc.complete <- tcq2notc[tcq2notc.full,]
acutotlm1.notc <- lm(Acutot~Creamtot+Pilltot+Injtot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notc.complete)
acutot.step.notc <- stepAIC(object=acutotlm1.notc, upper=acutotlm1notc,lower=~1, direction="both", k=3)
#acutot.pred <- predict(acutotlm1.notc, newdata=tcq2c)

@ 

<<acustepc, echo=FALSE, results=tex>>=
print(xtable(summary(acutot.step.notc), label="tab:acutotnotcsteplm", caption="Coefficients for Acupuncture Credibility Scores, Stepwise Selection (Splits A, B and D)"))
@ 

Table \ref{tab:acutotnotcsteplm} shows the best model as selected by the algorithm. It consists of three predictors, which will now be tested on the validation set. 

<<acutotnotbheldout, echo=FALSE, results=tex>>=
acutotnotc.heldout.lm <- lm(Acutot~Creamtot+Homtot+Reitot, data=tcq2c)
print(xtable(summary(acutotnotc.heldout.lm), label="tab:acutotnotcheldout", caption="Coefficients for Stepwise Model Acupuncture Credibility on Held out data (Split C)"))
@ 
As shown in Table \ref{tab:acutotnotcheldout}, the fit on the validation set was extremely similiar to that observed on the training set. The model was significant, $F(3,158)=35.94$, $p\le 0.0001$, and the model had an adjusted $R^2$ of 0.3943. 

<<acu2classo, echo=FALSE, results=tex>>=
acu2c <- with(tcq2notb.complete, Acutot)
predacu2c <- tcq2notb.complete[, c(71:73,75:78,80:81)]
predacu2c.test <- na.omit(tcq2c[,c(71:73,75:78,80:81)])
acu2c.test <- with(na.omit(tcq2c), Acutot)
acu2c.lasso <- penalisedRegression(predacu2c, acu2c, testdata=predacu2c.test, newy=acu2c.test, alpha=1, type="coefficients")
print(xtable(as.matrix(acu2c.lasso), label="tab:tcq2caculasso", caption="Coefficient Estimates for Lasso Regression using Acutotal as a dependent variable, Split C"))
@ 
Table \ref{tcq2caculasso} shows the coefficient estimates for the lasso regression on Acupuncture credibility. Again, in common with previous splits, the cream credibility total has a positive correlation with the response variable. This coefficient is similar in magnitude to those of the alternative treatments, so it suggests that there is a pattern of similarity to how these treatments are perceived by participants. Again, like in previous splits, there is a negative coefficient for pill credibility on this outcome measure. 

Next a ridge regression model was applied to this split. 

<<acu2cridge, echo=FALSE, results=tex>>=
acu2c.ridge <- penalisedRegression(predacu2c, acu2c, predacu2c.test, alpha=0, newy=acu2c.test, type="coefficients")
print(xtable(as.matrix(acu2c.ridge), label="tab:tcq2cacuridge", caption="Coefficient Estimates on Held Out Data for Acutotal, Ridge Regression, Split C"))
@ 

Table \ref{tab:tcq2cacuridge} shows the estimated coefficients from the ridge regression model. It can be seen that the cream coefficient is still of similar magnitude as are the other coefficients. Experience with alternative treatments has a large coefficient, which is what would be expected. 

<<homtotlmnotc, echo=FALSE, results=hide>>=
tcq2notc.full <- complete.cases(tcq2notc)
tcq2notc.complete <- tcq2notc[tcq2notc.full,]
homtotlm1.notc <- lm(Homtot~Creamtot+Pilltot+Injtot+Acutot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notc.complete)
homtot.step.notc <- stepAIC(object=homtotlm1.notc, upper=homtotlm1notc,lower=~1, direction="both", k=3)
## homtot.pred <- predict(homtotlm1.notc, newdata=tcq2c)

@ 

<<homstepc, echo=FALSE, results=tex>>=
print(xtable(summary(homtot.step.notc), label="tab:homtotnotcsteplm", caption="Coefficients for Homeopathy Credibility Scores, stepwise selection method (Splits A, B and D)"))
@ 

Table \ref{tab:homtotnotcsteplm} shows the selected model output from the stepwise procedure. This model was then fit to the validation set, and its fit examined. 

<<homtotnotbheldout, echo=FALSE, results=tex>>=
homtotnotc.heldout.lm <- lm(Homtot~Acutot+Reitot+Expalt, data=tcq2c)
print(xtable(summary(homtotnotc.heldout.lm), label="tab:homtotnotcheldout", caption="Performance of Stepwise Selected Model Acupuncture Credibility on Held out data (Split C)"))
@ 

Table \ref{tab:homtotnotcheldout} shows that all the variables remained significant on the validation set (with the exception of the intercept). The model was significant; $F(3,152)=57$, $p\le 0.0001$ and had an adjusted $R^2$ of 0.5201.

<<hom2classo, echo=FALSE, results=tex>>=
hom2c <- with(tcq2notb.complete, Homtot)
predhom2c <- tcq2notb.complete[, c(71:74,76:78,80:81)]
predhom2c.test <- na.omit(tcq2c[,c(71:74,76:78,80:81)])
hom2c.test <- with(na.omit(tcq2c), Homtot)
hom2c.lasso <- penalisedRegression(predhom2c, hom2c, testdata=predhom2c.test, newy=hom2c.test, alpha=1, type="coefficients")
print(xtable(as.matrix(hom2c.lasso), label="tab:tcq2chomlasso", caption="Coefficient Estimates for Lasso Regression using Homtotal as a dependent variable, Split C"))
@ 

Table \ref{tab:tcq2chomlasso} shows the estimated coefficients for the lasso model on acupuncture credibility in this split. It can be seen that, consistent with previous splits, cream credibility now has a negative coefficient while Pilltotal has a positive one. Again, however, the two other forms of alternative treatment make a much greater contribution to the model. 



<<hom2cridge, echo=FALSE, results=tex>>=
hom2c.ridge <- penalisedRegression(predhom2c, hom2c, predhom2c.test, alpha=0, newy=hom2c.test, type="coefficients")
print(xtable(as.matrix(hom2c.ridge), label="tab:tcq2chomridge", caption="Coefficient Estimates on Held Out Data for Homtotal, Ridge Regression, Split C"))
@ 

Table \ref{tab:tcq2chomridge} shows the estimated coefficients for the ridge regression model in this split. It can be seen that the major patterns from the lasso fit above remain unchanged. 


<<reitotlmnotc, echo=FALSE, results=hide>>=
tcq2notc.full <- complete.cases(tcq2notc)
tcq2notc.complete <- tcq2notc[tcq2notc.full,]
reitotlm1.notc <- lm(Reitot~Creamtot+Pilltot+Injtot+Acutot+Homtot+Expalt+Expconv+Gender+Income+Health, data=tcq2notc.complete)
reitot.step.notc <- stepAIC(object=reitotlm1.notc, upper=reitotlm1.notc,lower=~1, direction="both", k=3)
## reitot.pred <- predict(reitot.step.notc, newdata=tcq2c)

@ 

<<reistepc, echo=FALSE, results=tex>>=
print(xtable(summary(reitot.step.notc), label="tab:reitotnotcsteplm", caption="Coefficients on Reiki Credibility Model, stepwise selection (Splits A, B and D"))
@ 

Table \ref{tab:reitotnotcsteplm} shows the selected model and the predictor's estimated coefficients. It can be seen that Injections, Homeopathy and Reiki were the only retained coefficients. Next, this model was tested on the validation set. 

<<reitotnotbheldout, echo=FALSE, results=tex>>=
reitotnotc.heldout.lm <- lm(Reitot~Acutot+Injtot+Homtot, data=tcq2c)
print(xtable(summary(reitotnotc.heldout.lm), label="tab:reitotnotcheldout", caption="Performance of Reiki Credibility Model on Held out data, Split C"))
@ 
As Table \ref{tab:reitotnotcheldout} shows, all of the coefficients selected on the training set remained significant on the validation set. The model was significant; F(3,158)=68.36, $p\le 0.0001$. The adjusted $R^2$ was equal to 0.5566.

<<rei2classo, echo=FALSE, results=tex>>=
rei2c <- with(tcq2notb.complete, Reitot)
predrei2c <- tcq2notb.complete[, c(71:75,77:78,80:81)]
predrei2c.test <- na.omit(tcq2c[,c(71:75,77:78,80:81)])
rei2c.test <- with(na.omit(tcq2c), Reitot)
rei2c.lasso <- penalisedRegression(predrei2c, rei2c, testdata=predrei2c.test, newy=rei2c.test, alpha=1, type="coefficients")
print(xtable(as.matrix(rei2c.lasso), label="tab:tcq2creilasso", caption="Coefficient Estimates for Lasso Regression using Reitotal as a dependent variable, Split C"))
@ 

Table \ref{tab:tcq2creilasso} shows the estimated coefficients for a lasso regression on Reiki credibility scores. Ity can be seen that, similarly to previous splits, homeopathy credibility scores have the largest coefficient, while Pills and Injections have small negative coefficients. Strangely, the beliefs about medicine totals are negatively associated with the response variable, which is unexpected. 

<<rei2cridge, echo=FALSE, results=tex>>=
rei2c.ridge <- penalisedRegression(predrei2c, rei2c, predrei2c.test, alpha=0, newy=rei2c.test, type="coefficients")
print(xtable(as.matrix(rei2c.ridge), label="tab:tcq2creiridge", caption="Coefficient Estimates on Held Out Data for Reitotal, Ridge Regression, Split C"))
@ 

Table \ref{tab:tcq2creiridge} that the two alternative treatments have large  positive coefficients, while the conventional treatments have small negative ones. The overall pattern is quite similar to the lasso fit shown above. 

<<bamtotlmnotc, echo=FALSE, results=hide>>=
tcq2notc.full <- complete.cases(tcq2notc)
tcq2notc.complete <- tcq2notc[tcq2notc.full,]
bamtotlm1.notc <- lm(Bamtot~Creamtot+Pilltot+Injtot+Acutot+Homtot+Expalt+Expconv+Gender+Income+Health, data=tcq2notc.complete)
bamtot.step.notc <- stepAIC(object=bamtotlm1.notc, upper=bamtotlm1notc,lower=~1, direction="both", k=3)
## bamtot.pred <- predict(bamtot.step.notc, newdata=tcq2c)

@ 
<<bam2cstepwiseprint, echo=FALSE, results=tex>>=
print(xtable(summary(bamtot.step.notc), label="tab:bamtotnotcsteplm", caption="Coefficients on Beliefs About Medicine Questionnaire Model, stepwise selection (Splits A, B and D)"))
@ 
Table \ref{tab:bamtotnotcsteplm} shows the estimated best model for the BAM total. This model's fit was then tested on the validation  set.

<<bamtotnotbheldout, echo=FALSE, results=tex>>=
bamtotnotc.heldout.lm <- lm(Bamtot~Creamtot+Pilltot+Homtot+Expconv+Income+Health, data=tcq2c)
print(xtable(summary(bamtotnotc.heldout.lm), label="tab:bamtotnotcheldout", caption="Performance of Beliefs About Medicine Model on Held out data, SplitC"))
@ 

Table \ref{tab:bamtotnotcheldout} shows the model's performance on the held out data. It can be seen that Homeopathy, experience with conventional treatments and Income are no longer significant. The model itself was significant; F(6,145)=7.059, $p\le 0.0001$, and the adjusted $R^2$ was equal to 0.194. 


\subsubsection{Split D}
\label{sec:split-4}

Finally, the same procedure was repeated on Split D, which uses Splits A, B and C as the training data, and Split D as the held out validation set. 

<<pilltotlmnotd, echo=FALSE, results=hide>>=
tcq2notd.full <- complete.cases(tcq2notd)
tcq2notd.complete <- tcq2notd[tcq2notd.full,]
pilltotlm1.notd <- lm(Pilltot~Creamtot+Injtot+Acutot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notd.complete)
pilltot.step.notd <- stepAIC(object=pilltotlm1.notd, upper=pilltotlm1.notd,lower=~1, direction="both", k=3)
pilltot.pred <- predict(pilltotlm1.notd, newdata=tcq2d)

@ 

<<pillstepd, echo=FALSE, results=tex>>=
print(xtable(summary(pilltot.step.notd), label="tab:pilltotnotdsteplm",caption="Coefficients on Pill Credibility Model, stepwise selection (Splits A, B and C"))
@ 

Table \ref{tab:pilltotnotdsteplm} shows the estimated coefficients on the training data. The same core group of predictors are seen in the results, and Gender appears to be a useful predictor on this sub-sample of the data. This is the first appearance of a demographic variable in the final set, although the coefficients are quite small, as are the estimated t values. The model is significant: F(6,283)=48.4, with an adjusted $R^2$ of 0.496, which is line with results on previous splits.

Next, this model is tested on the held out data set. 

<<pilltotnotbheldout, echo=FALSE, results=tex>>=
pilltotnotd.heldout.lm <- lm(Pilltot~Creamtot+Injtot+Acutot+Expconv+Gender, data=tcq2d)
print(xtable(summary(pilltotnotd.heldout.lm), label="tab:pilltotnotdheldout", caption="Performance of Pill Credibility Model on Held out data, Split D"))
@ 
Table \ref{tab:pilltotnotdheldout} shows the results of fitting the trained model to the heldout data. It can be seen that Creams, Injections and Acupuncture are significant, while Experience and Gender are not. The adjusted $R^2$ value is equal to 0.3822, the lowest of all the splits, while the model is significant; F(6,201)=22.34, with a p-value of $p\le 0.001$. 

<<pill2dlasso, echo=FALSE, results=tex>>=
pill2d <- with(tcq2notb.complete, Pilltot)
predpill2d <- tcq2notb.complete[, 72:77,79:81]
predpill2d.test <- na.omit(tcq2d[,72:77, 79:81])
pill2d.test <- with(na.omit(tcq2d), Pilltot)
pill2d.lasso <- penalisedRegression(predpill2d, pill2d, testdata=predpill2d.test, newy=pill2d.test, alpha=1, type="coefficients")
print(xtable(as.matrix(pill2d.lasso), label="tab:tcq2dpilllasso", caption="Coefficient Estimates for Lasso Regression using Pilltotal as a dependent variable, Split D"))
@ 

Table \ref{tab:tcq2dpilllasso} shows the estimated coefficients for a lasso regession on pill credibility in this split. It can be seen that a similar pattern emerges as was seen in previous splits, with large positive coefficients from the other conventional treatments, and small negative ones for the alternative treatments. 


<<pill2dridge, echo=FALSE, results=tex>>=
pill2d.ridge <- penalisedRegression(predpill2d, pill2d, predpill2d.test, alpha=0, newy=pill2d.test, type="coefficients")
print(xtable(as.matrix(pill2d.ridge), label="tab:tcq2dpillridge", caption="Coefficient Estimates on Held Out Data for Pilltotal, Ridge Regression, Split D"))
@ 

Table \ref{tab:tcq2dpillridge} shows the estimates coefficients for the ridge regression model on Pill Credibility scores. It can be seen that the model is extremely similar to that of the lasso fit referenced earlier. 

<<creamtotlmnotd, echo=FALSE, results=hide>>=
tcq2notd.full <- complete.cases(tcq2notd)
tcq2notd.complete <- tcq2notd[tcq2notd.full,]
creamtotlm1.notd <- lm(Creamtot~Pilltot+Injtot+Acutot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notd.complete)
creamtot.step.notd <- stepAIC(object=creamtotlm1.notd, upper=creamtotlm1.notd,lower=~1, direction="both", k=3)
creamtot.pred <- predict(creamtotlm1.notd, newdata=tcq2d)

@ 

<<creamstepd, echo=FALSE, results=tex>>=
print(xtable(summary(creamtot.step.notd), label="tab:creamtotnotdsteplm",caption="Coefficients on Cream Credibility Model, stepwise selection (Splits A, B and C)"))
@ 

Table \ref{tab:creamtotnotdsteplm} shows the estimated coefficients on the regression of Cream credibility scores on the training set. It can be seen that six predictors were retained, Pills, Injections, Acupcunture, Experience with alternative treatment, experience with conventional treatments and Gender. The next step was to examine the performance of the model on the held-out data.

<<creamtotnotbheldout, echo=FALSE, results=tex>>=
creamtotnotd.heldout.lm <- lm(Creamtot~Pilltot+Injtot+Acutot+Expconv+Expalt+Gender, data=tcq2d)
print(xtable(summary(creamtotnotd.heldout.lm), label="tab:creamtotnotdheldout", caption="Performance of Cream Credibility Model on Held out data, Split D"))
@ 

Table \ref{tab:creamtotnotdheldout} shows the performance of the model on the held out data. It can be seen that Injections, Acupuncture, Experience with Treatments are no longer significant, while Pill credibility still is.The model is significant; F(7,193)=12.49, $p\le 0.0001$ and has an adjusted $R^2$ value of 0.2868, which is quite poor. 

<<cream2dlasso, echo=FALSE, results=tex>>=
cream2d <- with(tcq2notb.complete, Creamtot)
predcream2d <- tcq2notb.complete[, c(71,73:77,79:81)]
predcream2d.test <- na.omit(tcq2d[,c(71,73:77, 79:81)])
cream2d.test <- with(na.omit(tcq2d), Creamtot)
cream2d.lasso <- penalisedRegression(predcream2d, cream2d, testdata=predcream2d.test, newy=cream2d.test, alpha=1, type="coefficients")
print(xtable(as.matrix(cream2d.lasso), label="tab:tcq2dcreamlasso", caption="Coefficient Estimates for Lasso Regression using Creamtotal as a dependent variable, Split D"))
@ 

Table \ref{tab:tcq2dcreamlasso} shows the estimated coefficients for the lasso fit on the cream credibility totals. It can be seen that the major contributions come from the other conventional treatments, along with acupuncture. There's quite a large negative coefficient for BAM totals, also. 

<<cream2dridge, echo=FALSE, results=tex>>=
cream2d.ridge <- penalisedRegression(predcream2d, cream2d, predcream2d.test, alpha=0, newy=cream2d.test, type="coefficients")
print(xtable(as.matrix(cream2d.ridge), label="tab:tcq2dcreamridge", caption="Coefficient Estimates on Held Out Data for Creamtotal, Ridge Regression, Split D"))
@ 

Table \ref{tab:tcq2dcreamridge} shows the estimated coefficients for the ridge regression model on this variable. It can be seen that the coefficients are extremely similar to those obtained from the lasso fit above. 

Next, the same procedure was applied to the Injection credibility totals for this split. 

<<injtotlmnotd, echo=FALSE, results=hide>>=
tcq2notd.full <- complete.cases(tcq2notd)
tcq2notd.complete <- tcq2notd[tcq2notd.full,]
injtotlm1.notd <- lm(Injtot~Pilltot+Creamtot+Acutot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notd.complete)
injtot.step.notd <- stepAIC(object=injtotlm1.notd, upper=injtotlm1.notd,lower=~1, direction="both", k=3)
injtot.pred <- predict(injtotlm1.notd, newdata=tcq2d)

@ 

<<injstepd, echo=FALSE, results=tex>>=
print(xtable(summary(injtot.step.notd), label="tab:injtotnotdsteplm",caption="Coefficients on Injection Credibility Model, stepwise selection (Splits A, B and C)"))
@ 

It can be seen from Table \ref{tab:injtotnotdsteplm} that the algorithm retained five predictor variables, which is greater than has been seen in previous splits. Next, the performance of this model on the held out data was assessed. 

<<injtotnotbheldout, echo=FALSE, results=tex>>=
injtotnotd.heldout.lm <- lm(Injtot~Pilltot+Creamtot+Acutot+Expconv+Reitot, data=tcq2d)
print(xtable(summary(injtotnotd.heldout.lm), label="tab:injtotnotdheldout", caption="Performance of Injection Credibility Model on Held out data, Split D"))
@ 

Table \ref{tab:injtotnotdheldout} shows the estimated coefficients for this model on the held-out data. It can be seen that Pill credibility scores and Experience with conventional treatments are the only variables that remain significant. The model was significant: F(5,201)=13.46, $p\le 0.0001$, and the adjusted $R^2$ was equal to 0.2321, which is extremely poor. 

<<inj2dlasso, echo=FALSE, results=tex>>=
inj2d <- with(tcq2notb.complete, Injtot)
predinj2d <- tcq2notb.complete[, c(71:72,74:77,79:81)]
predinj2d.test <- na.omit(tcq2d[,c(71:72,74:77, 79:81)])
inj2d.test <- with(na.omit(tcq2d), Injtot)
inj2d.lasso <- penalisedRegression(predinj2d, inj2d, testdata=predinj2d.test, newy=inj2d.test, alpha=1, type="coefficients")
print(xtable(as.matrix(inj2d.lasso), label="tab:tcq2dinjlasso", caption="Coefficient Estimates for Lasso Regression using Injtotal as a dependent variable, Split D"))
@ 

As can be seen from Table \ref{tab:tcq2dinjlasso}, the conventional variables both had large coefficients, while those for the alternative treatments were shrunk almost entirely towards zero. Experience with conventional treatments also had a relatively large coefficient. 

<<inj2dridge, echo=FALSE, results=tex>>=
inj2d.ridge <- penalisedRegression(predinj2d, inj2d, predinj2d.test, alpha=0, newy=inj2d.test, type="coefficients")
print(xtable(as.matrix(inj2d.ridge), label="tab:tcq2dinjridge", caption="Coefficient Estimates on Held Out Data for Injtotal, Ridge Regression, Split D"))
@ 

As shown in Table \ref{tab:tcq2dinjridge}, the coefficients for the ridge fit were almost identical to those from the lasso fit, reinforcing our belief in the model. 

Next, a model was built and tested on the Acupuncture credibility scores. 

<<acutotlmnotd, echo=FALSE, results=hide>>=
tcq2notd.full <- complete.cases(tcq2notd)
tcq2notd.complete <- tcq2notd[tcq2notd.full,]
acutotlm1.notd <- lm(Acutot~Pilltot+Creamtot+Injtot+Homtot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notd.complete)
acutot.step.notd <- stepAIC(object=acutotlm1.notd, upper=acutotlm1.notd,lower=~1, direction="both", k=3)
acutot.pred <- predict(acutotlm1.notd, newdata=tcq2d)

@ 


<<acustepd, echo=FALSE, results=tex>>=
print(xtable(summary(acutot.step.notd), label="tab:acutotnotdsteplm",caption="Coefficients on Acupuncture Credibility Model, stepwise selection (Splits A, B and C)"))
@ 

Table \ref{tab:acutotnotdsteplm} shows that the algorithm retained five predictors in this case. Their fit was then examined on the held out data.

<<acutotnotdheldout, echo=FALSE, results=tex>>=
acutotnotd.heldout.lm <- lm(Acutot~Pilltot+Creamtot+Injtot+Homtot+Reitot, data=tcq2d)
print(xtable(summary(acutotnotd.heldout.lm), label="tab:acutotnotdheldout", caption="Performance of Acupuncture Credibility Model on Held out data, Split D"))
@ 

Table \ref{tab:acutotnotdheldout} shows the performance of the model on the held out data. It can be seen that only Homeopathy and Reiki credibility scores remain significant on this data set. The model was significant: F(5,203)=18.78, $p\le 0.0001$, and the adjusted $R^2$ of the model was equal to 0.2995, which is quite poor. 

<<acu2dlasso, echo=FALSE, results=tex>>=
acu2d <- with(tcq2notb.complete, Acutot)
predacu2d <- tcq2notb.complete[, c(71:73,75:78,80:81)]
predacu2d.test <- na.omit(tcq2d[,c(71:73,75:78, 80:81)])
acu2d.test <- with(na.omit(tcq2d), Acutot)
acu2d.lasso <- penalisedRegression(predacu2d, acu2d, testdata=predacu2d.test, newy=acu2d.test, alpha=1, type="coefficients")
print(xtable(as.matrix(acu2d.lasso), label="tab:tcq2daculasso", caption="Coefficient Estimates for Lasso Regression using Acutotal as a dependent variable, Split D"))
@ 

Table \ref{tab:tcq2daculasso} shows the estimated coefficients for the lasso model on Acupuncture credibility scores. It can be seen that there is a positive coefficient for cream credibility again, along with a negative coefficient for Pill credibility. As per usual, the two other alternative treatments had positive coefficients. 

<<acu2dridge, echo=FALSE, results=tex>>=
acu2d.ridge <- penalisedRegression(predacu2d, acu2d, predacu2d.test, alpha=0, newy=acu2d.test, type="coefficients")
print(xtable(as.matrix(acu2d.ridge), label="tab:tcq2dacuridge", caption="Coefficient Estimates on Held Out Data for Acutotal, Ridge Regression, Split D"))
@ 

Table \ref{tab:tcq2dacuridge} shows the estimated coefficients for the ridge regression model on this dataset. It can be seen that the fit is quite similar to the lasso fit reported earlier, and consistent with what was seen in other splits. 

Next, the model development and validation procedure was applied to the Homeopathy credibility scores. 

<<homtotlmnotd, echo=FALSE, results=hide>>=
tcq2notd.full <- complete.cases(tcq2notd)
tcq2notd.complete <- tcq2notd[tcq2notd.full,]
homtotlm1.notd <- lm(Homtot~Pilltot+Creamtot+Injtot+Acutot+Reitot+Expalt+Expconv+Gender+Income+Health, data=tcq2notd.complete)
homtot.step.notd <- stepAIC(object=homtotlm1.notd, upper=homtotlm1.notd,lower=~1, direction="both", k=3)
homtot.pred <- predict(homtotlm1.notd, newdata=tcq2d)

@ 

<<homstepd, echo=FALSE, results=tex>>=
print(xtable(summary(homtot.step.notd), label="tab:homtotnotdsteplm",caption="Coefficients on Homeopathy Credibility Model, stepwise selection (Splits A, B and C)"))
@ 

Table \ref{tab:homtotnotdsteplm} shows the retained predictors from the procedure for the Homeopathy credibility scores. It can be seen that only three were retained in this regression. Next, this model was fitted to the held out data.

<<homtotnotbheldout, echo=FALSE, results=tex>>=
homtotnotd.heldout.lm <- lm(Homtot~Acutot+Reitot+Expalt, data=tcq2d)
print(xtable(summary(homtotnotd.heldout.lm), label="tab:homtotnotdheldout", caption="Performance of Homeopathy Credibility Model on Held out data, Split D"))
@ 

Table \ref{tab:homtotnotdheldout} shows the performance of the model on the heldout data. It can be seen that both Acupuncture and Reiki remain extremely significant, but experience with alternative treatments does not. The model was significant: F(3,200)=75.17, $p\le 0.0001$, and the adjusted $R^2$ for the model was equal to 0.5229, which is extremely good performance. 

<<hom2dlasso, echo=FALSE, results=tex>>=
hom2d <- with(tcq2notb.complete, Homtot)
predhom2d <- tcq2notb.complete[, c(71:74,76:78,80:81)]
predhom2d.test <- na.omit(tcq2d[,c(71:74,76:78, 80:81)])
hom2d.test <- with(na.omit(tcq2d), Homtot)
hom2d.lasso <- penalisedRegression(predhom2d, hom2d, testdata=predhom2d.test, newy=hom2d.test, alpha=1, type="coefficients")
print(xtable(as.matrix(hom2d.lasso), label="tab:tcq2dhomlasso", caption="Coefficient Estimates for Lasso Regression using Homtotal as a dependent variable, Split D"))
@ 

Table \ref{tab:tcq2dhomlasso} shows the estimated coefficients for a lasso regression fit on the Homeopathy credibility scores in this split. It can be seen that the pattern with cream and pill scores has again replicated, suggesting that it is not due to random sampling. In fact, all of the coefficients are very similar to what was seen in the other splits. 

<<hom2dridge, echo=FALSE, results=tex>>=
hom2d.ridge <- penalisedRegression(predhom2d, hom2d, predhom2d.test, alpha=0, newy=hom2d.test, type="coefficients")
print(xtable(as.matrix(hom2d.ridge), label="tab:tcq2dhomridge", caption="Coefficient Estimates on Held Out Data for Homtotal, Ridge Regression, Split D"))
@ 

Table \ref{tab:tcq2dhomridge} shows the estimated coefficients for the ridge regression fit on the Homeopathy credibility scores. It can be seen that the same pattern as was seen with the lasso fit has emerged from this data. 

Next, the model selection and validation procedure was applied to the Reiki credibility scores. 

<<reitotlmnotd, echo=FALSE, results=hide>>=
tcq2notd.full <- complete.cases(tcq2notd)
tcq2notd.complete <- tcq2notd[tcq2notd.full,]
reitotlm1.notd <- lm(Reitot~Pilltot+Creamtot+Injtot+Acutot+Homtot+Expalt+Expconv+Gender+Income+Health, data=tcq2notd.complete)
reitot.step.notd <- stepAIC(object=reitotlm1.notd, upper=reitotlm1.notd,lower=~1, direction="both", k=3)
reitot.pred <- predict(reitotlm1.notd, newdata=tcq2d)

@ 

<<reikinotd, echo=FALSE, results=tex>>=
print(xtable(summary(reitot.step.notd), label="tab:reitotnotdsteplm",caption="Coefficients on Reiki Credibility Model, stepwise selection (Splits A, B and C)"))
@ 

Table \ref{tab:reitotnotdsteplm} shows the retained coefficients for the Reiki credibility scores regression. The algorithm has only retained three predictors, which is a little lower than in previous splits. Next, the fit of these predictors was examined on the held out data. 

<<reitotnotdheldout, echo=FALSE, results=tex>>=
reitotnotd.heldout.lm <- lm(Reitot~Acutot+Homtot+Injtot, data=tcq2d)
print(xtable(summary(reitotnotd.heldout.lm), label="tab:reitotnotdheldout", caption="Performance of Reiki Credibility Model on Held out data, Split D"))
@ 

Table \ref{tab:reitotnotdheldout} shows the performance of these predictors on the heldout data. It can be seen that both acupuncture and homeopathy remain significant, but Injections does not. The model was significant: F(3,206)=75.43, $p\le 0.0001$, and the adjusted $R^2$ was equal to 0.5165, which is extremely good. 

<<rei2dlasso, echo=FALSE, results=tex>>=
rei2d <- with(tcq2notb.complete, Reitot)
predrei2d <- tcq2notb.complete[, c(71:75,77:78,80:81)]
predrei2d.test <- na.omit(tcq2d[,c(71:75,77:78, 80:81)])
rei2d.test <- with(na.omit(tcq2d), Reitot)
rei2d.lasso <- penalisedRegression(predrei2d, rei2d, testdata=predrei2d.test, newy=rei2d.test, alpha=1, type="coefficients")
print(xtable(as.matrix(rei2d.lasso), label="tab:tcq2dreilasso", caption="Coefficient Estimates for Lasso Regression using Reitotal as a dependent variable, Split D"))
@ 
Table \ref{tab:tcq2dreilasso} shows the estimated coefficients for the lasso fit on Reiki credibility scores. It can be seen that most of the conventional treatment scores have been removed from the model and that the only major predictors were the other alternative credibility scores, in contrast to previous splits. 

<<rei2dridge, echo=FALSE, results=tex>>=
rei2d.ridge <- penalisedRegression(predrei2d, rei2d, predrei2d.test, alpha=0, newy=rei2d.test, type="coefficients")
print(xtable(as.matrix(rei2d.ridge), label="tab:tcq2dreiridge", caption="Coefficient Estimates on Held Out Data for Reitotal, Ridge Regression, Split D"))
@ 

Table \ref{tab:tcq2dreiridge} shows the estimated coefficients for the ridge regression model, and as can be seen these are quite similar to those seen for the lasso fit above.


Finally, this model selection and validation procedure was applied to the Beliefs About Medicine Total. 

<<bamtotlmnotd, echo=FALSE, results=hide>>=
tcq2notd.full <- complete.cases(tcq2notd)
tcq2notd.complete <- tcq2notd[tcq2notd.full,]
bamtotlm1.notd <- lm(Bamtot~Pilltot+Creamtot+Injtot+Acutot+Homtot+Expalt+Expconv+Gender+Income+Health, data=tcq2notd.complete)
bamtot.step.notd <- stepAIC(object=bamtotlm1.notd, upper=bamtotlm1.notd,lower=~1, direction="both", k=3)
bamtot.pred <- predict(bamtotlm1.notd, newdata=tcq2d)

@ 

<<bamstepd, echo=FALSE, results=tex>>=
print(xtable(summary(bamtot.step.notd), label="tab:bamtotnotdsteplm",caption="Coefficients on Beliefs About Medicine Questionnaire Model, stepwise selection (Splits A, B and C)"))
@ 

Table \ref{tab:bamtotnotdsteplm} shows the retained predictors from the algorithm. It can be seen that seven predictors were retained. Next, the fit of these predictors was examined on the held out data.

<<bamtotnotbheldout, echo=FALSE, results=tex>>=
bamtotnotd.heldout.lm <- lm(Bamtot~Pilltot+Creamtot+Homtot+Expalt+Expconv+Income+Health, data=tcq2d)
print(xtable(summary(bamtotnotd.heldout.lm), label="tab:bamtotnotdheldout", caption="Performance of Beliefs About Medicine Questionnaire Model on Held out data, Split D"))
@ 

Table \ref{tab:bamtotnotdheldout} shows the performance of the model on the validation set. It can be seen that Pilltotal, Homeopathy total and Experience with conventional treatments remain significant, but the other variables do not. The model was significant: F(7,182)=5.448, $p\le 0.0001$, and the adjusted $R^2$ for the model was equal to 0.1414, which is extremely poor but in line with previous splits. 

%% \subsubsection{Final Regression Models}
%% \label{sec:final-regr-models}

%% The next step in the data analysis procedure was to determine which of the models developed on each of the splits were the best fit to the data. As all of the data has been used in previous test and validation splits, the following approach was taken. Firstly, a random sample of 75 observations was drawn from each of the four splits, and then these samples were combined. The chosen models from each of the splits were then fitted to this new data set, and were compared using AIC and likelihood ratio tests. This approaches balances the advantages of cross-validation and avoids the problems of multiple comparison endemic to stepwise variable selection and repeated model fitting. 

%% <<tcq2new, echo=FALSE, results=hide>>=
%% set.seed(23)
%% ptcq2a.finalsamp <- tcq2nota.complete[sample(1:nrow(tcq2nota.complete), 75),]
%% tcq2b.finalsamp <- tcq2notb.complete[sample(1:nrow(tcq2nota.complete), 75),]
%% tcq2c.finalsamp <- tcq2notc.complete[sample(1:nrow(tcq2nota.complete), 75),]
%% tcq2d.finalsamp <- tcq2notd.complete[sample(1:nrow(tcq2nota.complete), 75),]
%% tcq2final <- as.data.frame(rbind(tcq2a.finalsamp,tcq2b.finalsamp,tcq2c.finalsamp,tcq2d.finalsamp))
%% @ 

%% <<pillfinalfits, echo=FALSE, results=hide>>=
%% pilltotlm.nota <- lm(Pilltot~Creamtot+Injtot+Homtot+Reitot, data=tcq2final)
%% pilltotnotb <- lm(Pilltot~Creamtot+Injtot+Acutot+Expconv, data=tcq2final)
%% pilltotnotc <- lm(Pilltot~Creamtot+Injtot+Acutot+Expconv, data=tcq2final)
%% pilltotnotd <- lm(Pilltot~Creamtot+Injtot+Acutot+Expconv+Gender, data=tcq2final)
%% pillaandbtest <- jtest(pilltotlm.nota, pilltotnotb)
%% pillcanddtest <- jtest(pilltotnotc, pilltotnotd)
%% pillaandctest <- jtest(pilltotlm.nota, pilltotnotc)
%% pillaanddtest <- jtest(pilltotlm.nota, pilltotnotd)
%% @ 

%% <<ABcompprint, echo=FALSE, results=tex>>=
%% print(xtable(pillaandbtest, label="tab:pillAandBtest", caption="Model Comparison between Pill Credibility Models, Splits A and B"))
%% @ 

%% <<ABcompprint, echo=FALSE, results=tex>>=
%% print(xtable(pillcanddtest, label="tab:pillCandDtest",caption="Model Comparison between Pill Credibility Models, Splits C and D"))
%% @ 

%% As shown in Tables \ref{tab:pillAandBtest} and \ref{tab:pillCandDtest}, the model developed on Split A appears to preovide the best fit on this resampled data. The model tested on split A was also significantly better than C and D, therefore we can regard this model as the best for the Pill credibility scores. The model was significant: $F(4,283)=68.81$, $p\le 0.0001$, and had an adjusted $R^2$ of 0.4859. 

%% Next, the models for cream credibility scores were assessed. 

%% <<creamfinal, echo=FALSE, results=hide>>=
%% creamtotlm.nota <- lm(Creamtot~Pilltot+Injtot+Acutot+Gender+Health, data=tcq2final)
%% creamtotlm.notb <- lm(Creamtot~Pilltot+Injtot+Acutot+Gender, data=tcq2final)
%% creamtotlm.notc <- lm(Creamtot~Injtot+Acutot+Expalt+Health, data=tcq2final)
%% creamtotlm.notd <- lm(Creamtot~Pilltot+Injtot+Acutot+Expconv+Expalt+Gender, data=tcq2final)
%% creamaandbtest <- jtest(creamtotlm.nota, creamtotlm.notb)
%% creamcanddtest <- jtest(creamtotlm.notc, creamtotlm.notd)
%% creamdanbctest <- jtest(creamtotlm.notd, creamtotlm.notc)
%% creamaanddtest <- jtest(creamtotlm.nota, creamtotlm.notd)
%% @ 

%% The results for this split were a little more ambiguous, as Models A and B were equivalent in terms of model testing. Model D was better than Model C, but Model A was better than Model D. Therefore we can regard Model D as the best fitting model for the Cream credibility scores. The model was significant: F(5,282)=43.51, $p\le 0.0001$, with an adjusted $R^2$ of 0.4255, which is acceptable. 

%% Next, the same procedure was repeated for the Injection credibility scores. 

%% <<injfinal, echo=FALSE, results=hide>>=
%% injtotnota.final <- lm(Injtot~Creamtot+Pilltot+Expconv+Health, data=tcq2final)
%% injtotnotb.final <- lm(Injtot~Pilltot+Creamtot+Acutot+Reitot+Expconv, data=tcq2final)
%% injtotnotc.final <- lm(Injtot~Creamtot+Pilltot+Expconv, data=tcq2final)
%% injtotnotd.final <- lm(Injtot~Pilltot+Creamtot+Acutot+Expconv+Reitot, data=tcq2final)
%% inj.aandb.test <- jtest(injtotnota.final, injtotnotb.final)
%% inj.candd.test <- jtest(injtotnotc.final, injtotnotd.final)
%% inj.bandd.test <- jtest(injtotnotb.final, injtotnotd.final)
%% @ 

%% <<modeldshow, echo=FALSE, results=tex>>=
%% print(xtable(summary(injtotnotd.final), label="tab:injnotdfinal", caption="Final Model for Injection Credibility Scores"))
%% @ 

%% Following repeated tests of the fit of the models, Model D appears to be the best fitting on this data. The model was significant: $F(5,282)=48.56$, $p\le 0.0001$ and the adjusted $R^2$ for the model was equal to 0.3955. The coefficients for the model are shown in Table \ref{tab:injnotdfinal}. 

%% Next, this procedure was repeated for the Acupuncture models. 

%% <<acufinaltest, echo=FALSE, results=hide>>=
%% acutotnota.final <- lm(Acutot~Creamtot+Homtot+Reitot, data=tcq2final)
%% acutotnotb.final <- lm(Acutot~Pilltot+Creamtot+Injtot+Reitot+Homtot, data=tcq2final)
%% acutotnotc.final <- lm(Acutot~Creamtot+Homtot+Reitot, data=tcq2final)
%% acutotnotd.final <- lm(Acutot~Pilltot+Creamtot+Injtot+Homtot+Reitot, data=tcq2final)
%% acu.aandb.test <- jtest(acutotnota.final, acutotnotb.final)
%% acu.candd.test <- jtest(acutotnotc.final, acutotnotd.final)
%% acu.aandc.test <- jtest(acutotnota.final, acutotnotc.final)
%% @ 
%% Following fitting of each of the four models to the final dataset, Models A and C emerged as the best fit to the data. This equivalence between them was not surprising, as they were exactly the same model. 

%% <<acutotfinalprint, echo=FALSE, results=tex>>=
%% print(xtable(summary(acutotnotc.final), label="tab:acutotfinal", caption="Final Model for Acupuncture Credibility Scores"))
%% @ 

%% The coefficients and p values for the individual terms in the model can be seen in Table \ref{tab:acutotfinal}. The model was significant: $F(3,284)=79.31$, $p\le 0.0001$, and had an adjusted $R^2$ of 0.4501. 

%% Next, this procedure was applied to the homeopathy models developed on each of the splits. 

%% <<hommodfinal, echo=FALSE, results=tex>>=
%% homtotnota.final <- lm(Homtot~Creamtot+Pilltot+Acutot+Reitot, data=tcq2final)
%% homtotnotb.final <- lm(Homtot~Pilltot+Creamtot++Reitot+Acutot, data=tcq2final)
%% homtotnotc.final <- lm(Homtot~Acutot+Reitot+Expalt, data=tcq2final)
%% homtotnotd.final <- lm(Homtot~Acutot+Reitot+Expalt, data=tcq2final)
%% hom.aandb.test <- jtest(homtotnota.final, homtotnotb.final)
%% hom.candd.test <- jtest(homtotnotc.final, homtotnotb.final)
%% hom.bandc.test <- jtest(homtotnotb.final, homtotnotc.final)
%% @ 

%% Following assessment of all four models, Model C was determined to be marginally the best.

%% <<homfinalshow, echo=FALSE, results=tex>>=
%% print(xtable(summary(homtotnotc.final), label="tab:homtotfinal", caption="Final Model for Homeopathy Credibility Scores"))
%% @ 

%% Table \ref{tab:homtotfinal} shows the estimated coefficients and p values for each of the predictors on the final dataset. The model was significant: $F(3,284)=177.7$, $p\le 0.0001$ and the adjusted $R^2$ for the model was equal to 0.6487. 

%% Next, the same procedure was applied to the Reiki credibility models. 

%% <<reikimodfinal, echo=FALSE, results=hide>>=
%% reitotnota.final <- lm(Reitot~Injtot+Expalt+Acutot, data=tcq2final)
%% reitotnotb.final <- lm(Reitot~Injtot+Acutot+Homtot, data=tcq2final)
%% reitotnotc.final <- lm(Reitot~Acutot+Injtot+Homtot, data=tcq2final)
%% reitotnotd.final <- lm(Reitot~Acutot+Homtot+Injtot, data=tcq2final)
%% rei.aandb.test <- jtest(reitotnota.final, reitotnotb.final)
%% rei.candd.test <- jtest(reitotnotc.final, reitotnotd.final)
%% rei.bandd.test <- jtest(reitotnotb.final, reitotnotd.final)
%% @ 

%% Following fitting and testing of the four models, Model D was determined to be the best fit to this new data. 

%% <<reifinalshow, echo=FALSE, results=tex>>=
%% print(xtable(summary(reitotnotd.final), label="tab:reitotfinal", caption="Final Model for Reiki Credibility Scores"))
%% @ 

%% Table \ref{tab:reitotfinal} shows the estimated coefficients for the Reiki credibility scores regression on the resampled data. The model was significant: $F(3,284)=167.7$, $p\le 0.0001$, with an adjusted $R^2$ of 0.6354, which is excellent. 

\subsection{Discussion}

\subsubsection{Study One}
\label{sec:study-1}


A number of issues have become clear from this first sample taken to validate the Treatment Credibility Questionnaire. Firstly, the measure appears to have the expected factor structure, with four factors, one for each set of six questions. Secondly, an item response theory analysis has suggested that while the Pills, Cream and Injection questions can be conceptualised with one latent trait, this does not appear to work for acupuncture. This would seem to suggest that ratings of complementary and western medicine are somewhat independent. The second version of this survey added two more sections on complementary therapies, Homeopathy and Reiki, in order to both balance the kinds of treatments, and to examine whether the assumption of bi-dimensionality would hold in another student and UCC staff sample. 

 Very few demographic variables were collected in this survey. This limited what could be done with the ability estimates, and their relation to other factors. Therefore, for the second and third surveys, more demographics were added.  A question on experience with each of the treatments involved would seem like a useful check on what percentage of the respondents have experiential knowledge of these methods would prove useful. Given the cost of CAM and its unavailability to those of lower incomes, a question on income would also be useful.
% Both of these changes were made to the survey, which has since been emailed to all staff and students for further validation. 

In addition, the General sub-scale of the Beliefs about Medicines Questionnaire was appended to V2 of the survey, in order to assess the extent to which the two instruments correlate (or fail to). This is a preliminary attempt to assess construct validity, which of course is but a prelude towards testing the instrument with clinical samples and in experimental settings.

\subsubsection{Study Two}
\label{sec:study-2}



This paper has demonstrated a number of matters with regards to this new instrument. Firstly, it appears to have the predicted factor structure. Secondly, this factor structure has been replicated over two samples. Thirdly, all the major hypotheses (from Study 2) have been confirmed. The measure appears to be stable, possesses good reliability, and seems to correlate in the expected ways with the Beliefs About Medicine Questionnaire. 

That being said, there are some important limitations to the study. Firstly, there was no behavioural or observational outcome to benchmark the test against. Secondly, although we sampled twice from the student population and once from the staff population, this test still relies entirely on the responses of staff and students at one particular university. Further replication of the factor structure in heterogenous groups is warranted before extensive use of the instrument takes place. 

<<saveimage, echo=FALSE, results=hide>>=
pill.all <- c(with(tcq1, PillTot), with(tcq2, Pilltot))
cream.all <- c(with(tcq1, CreamTot), with(tcq2, Creamtot))
inj.all <- c(with(tcq1, InjTot), with(tcq2, Injtot))
acu.all <- c(with(tcq1, AcuTot), with(tcq2, Acutot))
hom.all <- with(tcq2, Homtot)
rei.all <- with(tcq2, Reitot)
all.cred <- list(pill.all, cream.all, inj.all, acu.all, hom.all, rei.all)
all.cred <- lapply(all.cred, as.data.frame)
names(all.cred) <- c("PillCredibility", "CreamCredibility", "InjectionCredibility", "AcupunctureCredibility", "HomeopathyCredibility", "ReikiCredibility")
credtotals <- tcq2[,c("Pilltot", "Creamtot", "Injtot", "Acutot", "Homtot", "Reitot")]
save.image("tcqthesis.rda")
@   

%%% Local Variables:
%%% TeX-master: "PlaceboMeasurementByMultipleMethods"
%%% End:
