\subsection{Scoring of the IAT}
\label{sec:scoring-iat}



Some controversy has surrounded the use of difference scores as a metric \cite{Blanton2006d}. Blanton \textit{et al} argue that the only condition under which difference scores make sense is when positive and negative stimuli are equally valenced, and they further argue that this condition is not met for many of the most popular implicit association tests (specifically, the racism IAT). They further argue that, unless the IAT score can be linked to an observable outcome, then it is an arbitrary metric \cite{Blanton2006}.

 This contention of Blanton and Jaccard rests on modelling the IAT as two seperate measures which are then combined. In addition, they appear to argue that successive responses within an IAT trial are independent, which seems like an unjustified assumption. Given that the procedure requires participants to respond to multiple stimuli in quick succession, the responses within blocks are likely to be auto-correlated \cite{mccleary1980applied,craigmile2010hierarchical}, and even the independence of responses across a single IAT is in doubt.

Blanton and Jaccard note that the model's of Greenwald require a rational zero point, and that this phenomenon has not been demonstrated. However, more recent research \cite{Karpinski2005} showed that amongst participants who did not drink soda, the average IAT score was approximately zero, suggesting that at least in the domain of drink choice, this rational zero point does exist. 

One major issue with the use of difference scores is that reaction times tend to slow with age, causing older participants to have more extreme IAT scores. However, the use of the new $D$ measure \cite{Greenwald2003} which divides the mean difference in response time by the pooled standard deviation, should reduce the influence of these extraneous factors. 

The psychometric characteristics of the IAT are still not completely defined, and no single model has provided a coherent explanation for how and why the effects will occur. However, the measure does appear to have predictive validity (see Section \ref{sec:pred-valid-iat}) so the proper question for psychometric analysis is not whether the IAT has any effects, but rather how these effects occur.


\subsection{IAT, Controllability and Faking}
\label{sec:iat-contr-faking}

While it appears that while the IAT resists demand characteristics, it does not prevent them entirely \cite{DeHouwer2007b}. De Houwer's research demonstrated that the IAT procedure can be faked when applied to novel attitudes. This research  demonstrated a large IAT effect when participants were given positive or negative information about fictitious social groups. 

De Houwer \textit{et al} also obtained IAT effects when participants were asked to respond in the opposite way from the information which they had been given, although the effects were smaller, and not all participants were capable of this feat.  

The major contribution of this research is that it demonstrates that participants can alter IAT effects by choice, at least when applied to novel or unfamiliar attitudes. The authors suggest that this may restrict the ability of the IAT to study the development of novel attitudes, but it would not affect the study of well developed attitudes, as are looked at in most IAT research.

However, there is a more serious problem, as the research on training participants to fake the IAT indicates \cite{Fiedler2005}. This research carried out three experiments, one on-line and two in a controlled experimental set-up. The results indicated that given prior experience with the IAT, and some instructions on how the measure works, participants were capable of reversing the sign of the IAT effect (which equates to showing an attitude opposite to their own). 

Clearly, this is an issue for researchers, especially with such well known IAT measures as the Race IAT. However, the results of this study also showed that mere experience was not enough to allow faking. Participants who were given no information on how to fake were not able to change the direction of their IAT effect. Worse still the authors sent the faked data to a number of researchers in the field, and only one of them was able to identify the faked results, and this was done with an accuracy of 58\% using an algorithmic procedure.   

That being said, the results of Foroni and others \cite{Foroni2005}  suggest that there are some interesting features involved in the modulation of IAT effects. This experiment utilised a flower-insect IAT \cite{Greenwald1998} and two conditions. In the first, participants read a story about how the world had changed and insects were now a major source of nutrition for humans, while flowers were poisonous. 

The other condition presented the same information, but not in narrative form. The story proved successful at changing the IAT effect to insects positive and flower negative, while the same information presented in a descriptive fashion was unable to induce these changes. This study also examined the effects of telling participants to fake the IAT, and noted that this was not effective at all. 

These two contradictory results present us with a problem to explain. There are two possible explanations which I will address in this paragraph. The first is that without instructions, the IAT is very difficult to fake. The second is that participants may be better able to fake attitudes towards social groups rather than flowers and insects. 

The first explanation runs into difficulties as the Fiedler \textit{et al}  study showed small effects of faking even without instructions. The second seems intuitively plausible, as people may have more incentive to conceal negative attitudes towards out-groups rather than insects, and thus may learn how to do so more quickly. Neither of these explanations are particularly satisfying however, so the issue of how and when the IAT can be faked remains and open question for future research. 

 \subsection{Modelling the IAT}
 \label{sec:modelling-iat}

 Some have claimed that the lack of a coherent model for why the IAT works is an indictment of standards of psychometrics within psychology \cite{borsboom2006attack}. Without entirely endorsing this position, it does have some merit. The spread of the IAT across social psychological research and into other areas of psychology came without any serious attempt at understanding exactly what the tool was measuring. It does appear that many of the researchers exposed to the tool were surprised at how difficult they found it to respond quickly on the inconsistent trials (insect and pleasant, for example) and appear to have taken this as evidence for the validity of the tool. In this sense, the IAT can be said to possess extremely high face validity (at least for psychological researchers). 

Nonetheless, in more recent years, there have been some psychometric examinations of the properties of the IAT. One major flaw in almost all these investigations is that they focus on the relationships between self report instruments and IAT scores. While this is important, as both of these methods are used by psychologists to assess individual traits, it does not serve the purpose of relating these measures to behaviours and outcomes in the world, which is (or should be) the major aim of psychological research. Indeed, self report instruments are typically created based on other self-report instruments \cite{borsboom2006attack}, and as this lattice of validation continues, the constructs measured become ever more abstract and less connected to independently verifiable outcomes, which is presumably the overall aim. 

Despite this flaw (which this thesis aims to redress within the domain of the placeo effect), there has been some interesting psychometric analyses of the IAT, much of either critical or in response to criticism. Typically, a Structural Equation Modelling (SEM) approach is used, where the self report and implicit measures are taken to be imperfect measures of the same or similiar latent constructs, and a theoretical model is used to develop relationships which are then tested against the data. 

Meirke and Klauer examined a SEM of the IAT, and found evidence that a two factor correlated model fit the data quite well \cite{Mierke2003}. However, these authors only fitted one model to the data, and traditionally SEM is used to compare different models rather than to examine the fit of one (for which is it ill-suited). 

One pair of studies that did examine the impacts of different models for the IAT and its relationships with explicit measures were the study of Blanton et al \cite{Blanton2006a} where they argued that the two different blocks of the IAT (insect and pleasant and flower and unpleasant) represented two independent factors and used this model and its subsequent poor fit to refute the theory of Greenwald et al \cite{greenwald2002}. However, there is a great deal of evidence that reaction time measures exhibit strong auto-correlations from trial to trial \cite{craigmile2010hierarchical} as well as time trends, so this argument from Blanton and Jaccard is flawed. 

However, the refutation of this argument by Nosek et al \cite{Nosek2007} which argued that the IAT was best modelled as two correlated indicators of one construct is also flawed. This is true as far as it goes, but in both of these comments there seems to be a studied indifference to the problems of treating reaction time data as independent both within and across trials. It can be argued that as the models typically only use the mean and variance of the $D$ measure that this is not as much of an issue, but the variance will be artifically reduced by the auto-correlations, and this will lead to biased parameter estimates and tests of significance. 

Greenwald et al \cite{Greenwald2000} found that a two factor model provided a better fit to the data than did a one factor model, but this model was developed and tested on the same dataset so these findings must be treated with caution. It is also worth noting that assuming that the second factor is not pure noise, a more complex model will almost always fit the data better than a less complex model, especially if some kind of penalty for extra parameters is not used. 

Blanton \textit{et al} \cite{Blanton2006} fitted a number of models to an IAT dataset to support their theory that general processing speed was the major driver of the effects. Leaving aside the issues with serial dependence and trends, they found that a four factor model including general processing speed fitted the data best. Again, the model was both developed and tested on the same dataset, so these conclusions are not as strong as they would be had the model been tested on a different dataset (or had cross-validation been used, see Section \ref{sec:regress-models}). Additionally, the greater number of factors will often provide a better fit, even in the absence of any real multiple factor structure. 

Additionally, Nosek et al, in their reply argue that the IAT score is a relative judgment, and is not reducible to an additive function of two independent attitudes. In a separate article \cite{Nosek2007a}, the authors conduct a Multi-Trait Multi-Method evaluation of the relationships between implicit and explicit attitudes, and conclude that a two factor model provides the best fit. This is a good article, especially as they use the MTMM design to partial out method variance to allow for more accurate assessment of the individual contributions of the measurement tools. Additionally, this article used an extremely large internet collected dataset to develop and test their models, making it less susceptible to the problems of over-fitting described above. 

\subsection{Arkes and Tetlock: Prejudice or Rationality?}
\label{sec:arkes-tetl-prej}

In 2004, Psychological Inquiry published a criticism of the IAT procedure \cite{Arkes2004}. The remainder of the issue was devoted to articles either supporting the original critique or arguing against it, with about equal contributors on either side. Their criticisms have three major strands. The first is that the IAT results may reflect cultural stereotypes rather than personal associations, the second is that these negative associations may not be due to prejudice, and finally, that these negative associations may be the result of perfectly rational behaviour. They also make the point that many researchers have moved too quickly from the discovery of implicit associations to the notion of implicit prejudice, which is a position that has some merit. 

Their first strand of argument is that the associations revealed by the IAT represent cultural stereotypes. They argue that since some African Americans show implicit prejudice against their own race, then this cannot be the result of a personal attitude, but must be the result of a culturally held belief. They do, however, fail to account for the similar percentage of White IAT participants who show similar negative associations to their own race, and the explanation of shared cultural stereotypes does not seem to hold water in this case. 

An article responding to the criticisms \cite{Sears2004} presents the results of survey research which indicates that approximately ten percent of respondents show a preference to a race other than their own. These figures are similar to those obtained with implicit association research, and would seem to cast doubt upon the arguments of Arkes \& Tetlock in this case. 

Arkes  \textit{et al} also argue that the low correlations between implicit and explicit measures of attitudes are the result of this shared cultural stereotype, while the explicit measures look at the extent to which the participant agrees with this cultural stereotype. The authors suggest that the time limit in IAT experiments forces participants to rely upon these shared cultural stereotypes, and that this factor is responsible for the effects. This seems like a plausible explanation, however there has been work which has linked individual Race IAT scores onto prejudiced behaviour \cite{Heider2007}, which argues against this interpretation of the IAT scores. The only possible way in which these two ideas can be reconciled is if we assume that knowledge of a cultural stereotype is correlated with prejudiced behaviour, which would presumably make prejudice researchers the most discriminatory people in the world. 

The next part of their argument relies upon the Olson \textit{et al} \cite{Olson2004} study where the authors examined a  personalised  IAT. They then argue from analogy that this metric could cause Jesse Jackson to fail the IAT. This argument is somewhat unconvincing, and seems to fly in the face of research that indicates that IAT measures personal associations better than cultural ones \cite{Nosek2008a}. Arkes and Tetlock also argue against the studies which use body language as a measure of prejudice  claiming that these behaviours could also be interpreted as shame or sorrow. Unfortunately, they provide no evidence in support of their claims. 

% Their final argument is perhaps the most seductive, especially to readers of a statistical nature. Briefly, they argue that because most crime in America is committed by black people, it is perfectly rational for White Americans to associate negative words with Black Americans, and thus the associations revealed with the IAT are not prejudiced, because they are rational. Leaving aside the matter of whether individuals untrained in higher level mathematics are capable of assessing utility in this fashion, and if so, whether or not they do, this argument neglects to mention that class and income are also significantly influential in crime statistics and we do not have IAT results suggesting that poor people are prejudiced against rich people, and vice versa. Their rational calculation of crime statistics is also fatally flawed by the use of convictions, given the expense of lawyers and the likelihood that most poorer people will plead guilty in America in order to gain a reduced sentence (plea-bargaining). 

In summation, the Arkes and Tetlock article appears to present no new research or evidence against the IAT but merely restate old problems and argue for doubt on the issue. The two points they do make cogently is that the leap from associations to attitudes has been made too quickly, and their argument that participants in the dispute make reputational bets following design of experimental studies to conclude the disagreement in a Bayesian fashion. Unfortunately, this offer does not appear to have been taken up at this point. 

\subsection{Rothermund and Wentura: Salience or Associations?}
\label{sec:roth-went-sali}
In 2004, perhaps the most compehensive critique of the IAT was published \cite{Rothermund2004}. This critique focused on the validity of the association model presumed to underlie the observed IAT effects \cite{Greenwald1998}. Rothermund and Wentura proposed another model which they claimed could account for the effects and they called this the figure-ground model. 

They argue that salience asymmetries between the different stimuli could be driving the observed effects. They claim that negatively valent words are more noticeable and thus become the figure, while positively valent words become the ground. This then drives the observed  effect. In the paper noted above, Rothermund and Wentura produce results which appear to confirm this model, using non-words and strings of numbers as stimuli and producing typical IAT effects. 

They note that this cannot be due to pre-existing associations, and claim that these results support the salience asymmetries model of the IAT. This paper is extremely well conducted, and has  cast a shadow over  IAT research. These criticisms have some merit, however, they note in passing that valence and familiarity probably drive these effects, so logically, these effects of salience can be controlled for by controlling the valence and familiarity in IAT research, which has since become common practice. 

They also recommend that all IAT research should involve a word non-word task in order to assess the extent to which salience asymmetries contribute to the observed IAT effects. Greenwald  et al \cite{Greenwald2005} responded to this critique, and argued that the salience asymmetry explanation conflicted with the literature showing impressive correlations with explicit behaviour in known groups studies and meta-analyses \cite{Greenwald2009}. 

While this is a very important point, nonetheless this does not rule out a salience asymmetry explanation totally. Perhaps the most important element to take from this debate is that salience asymmetries need to be controlled for (by making sure valence and familiarity are matched across stimuli) so that we can be certain that any associations revealed are not spurious and reflect real differences in people's conceptions of the matters under study. 

\subsection{Blanton and Jaccard: Associations versus Attitudes}
\label{sec:blant-jacc-assoc}

The most recent scrutiny has mostly emanated from Hart Blanton and James Jaccard, along with some of their associates. The first critique began as a commentary on Greenwald's \cite{greenwald2002}  \textit{Unified theory of implicit attitudes, stereotypes, self esteem and self concept}, and expanded into a critique of multiplicative models within psychology more generally. 

The major problems for Blanton and Jaccard \cite{Blanton2006a} were the following. Greenwald's theory posits that attitudes are associated with the self through a network comprising discrete concepts, many of which are either positively or negatively associated with one another. So far, so good. However, as a result of the theory, Greenwald makes a number of predctions which he proposes to test using multiple regression. It is here that problems arise in the view of Blanton and Jaccard. 

Multiple regression and multiplicative models tend to require a rational zero point on the scale used. Blanton and Jaccard argue that this requirement has not been met for either the explicit or implicit measures used by Greenwald et al. They point out that Greenwald et al \cite{greenwald2002} assumes that the mid point of a scale measuring explicit attitudes represents a zero point. This requires that the scale be a perfect representation of the underlying construct, which seems somewhat unlikely. Greenwald often uses difference scores to avoid this kind of problem, but Blanton and Jaccard argue that this is only permissible if the positive and negative items on a scale are equally valent, which is an assumption which cannot be met for most scales used. However, it is an assumption that can be met for much of Greenwald's work, where stimuli are matched for valence. 

Greenwald also tends to use identical stimuli for self report and IAT instruments so at least this assumption is met across both methods \cite{Farnham1999,Greenwald1998}. Blanton and Jaccard conclude by suggesting an alternative method of analysis for the data reported in Greenwald et al's (2002) article. This led to a reply by Greenwald et al \cite{Greenwald2006b}, which used his acquired data to test against the model suggested by Blanton and Jaccard. He discerned some problems with his own model, but also serious flaws with the strategy suggested by Blanton and Jaccard. Following simulation and meta analysis, he produces evidence which supports his multiplicative model, at least in a somewhat weaker form. 

% If this were the limit of the issues raised by Blanton and Jaccard, it would seem not much more than an abtruse debate about relevant statistical models, with little to no relevance for practical use of the instrument, except perhaps for a greater awareness of its limitations. 


Later that year Blanton and Jaccard released an article \cite{Blanton2006} in which they claimed to have identified a number of important confounds in the entire IAT procedure. The first, and perhaps most important of these, was a problem with general processing speed. They re-analysed previous data supplied by Greenwald, and using the practice steps as a measure for general processing speed, found that implicit preferences were strongly correlated with one another across different domains. However, when processing speed was controlled for, there were no significant associations. This raises the disturbing possibility that previous associations reported using the IAT may have been the result of processing speed rather than true effects of implicit attitudes.

One major flaw in this argument presented by Gonzalez \textit{et al}  is that they assume that all responses in the IAT are independent of one another, across blocks. This is an important assumption as if the blocks were not independent, then blocks 2 and 4 could not be used as an index of general processing speed, as these authors did. Given the design of the IAT (a speeded response task where one block follows another almost immediately), this independence appears to be an assumption which needs further empirical testing. 

Another major problem identified by this re-analysis concerned the definition of the IAT as an instrument which measured relative attitudes rather than absolute preferences \cite{Greenwald1998} . This assumption was so important that it was reflected in the scoring, where an IAT effect is defined as the difference between response latencies in the two conditions. 

Re-analysing previous studies on the preference for maths over arts, Blanton et al discovered that the attitudes towards maths and arts were independent of one another, suggesting that the IAT may not be measuring relative preferences but rather independent attitudes. In the specific case above this may seem intuitively obvious, but this finding was replicated for the Race and Gender IAT's, where this result may seem a little less likely. Again, this re-analysis relies on the idea that the responses to one category are independent of one another, which is an even less jusitfiable assumption than that the responses of different blocks are independent. 

However, Nosek \& Srinam \cite{Nosek2007} replied to this analysis with a spirited critique of their own. They argue that Blanton et al's (2006) conception of the two IAT conditions as representing parallel measures of an underlying construct is faulty, and that the true conception of them is as interdependent measures, like a Stroop task. 

They re-analysed the data provided by Blanton et al, and found that when this assumption was made, they could produce models of the phenomenon which had good fit, and did not show noticeable effects even when processing speed was assumed to cause an effect. Blanton et al critiqued this comment mercilessly (though very politely) \cite{Blanton2007}, when they observed that many of the assumptions they had made had also been made by Nosek in the past. 

Essentially, Blanton and Jaccard argue that the IAT is poorly understood and an arbitrary metric, and also believe that general processing speed of individuals may be contaminating the results. 

These critiques have some merit, and will probably result in some changes to the methodology, as the problems seem to arise from the use of attitudes as bi-polar constructs. This, despite, the flaws in the analysis of Blanton \textit{et al}  may be an issue for future research. % This would mean that variations of the IAT such as the Go/No Go Association Test and the Single Category IAT would be unaffected, but much previous research would need to be re-confirmed.

However, it is worth noting that many psychometric scales can be regarded as arbitrary in Blanton and Jaccard's sense, yet they do not condemn the use of these measures. 


\subsection{IAT: Personal or Cultural?}
\label{sec:iat:-personal-or}


Another issue in the field of IAT research has been the relationship between implicit attitudes and cultural knowledge. Some have claimed that it is these extra-personal associations which influence response on the IAT \cite{Olson2004}. However, a recent study \cite{Nosek2007a} casts doubt on this interpretation. They found that consistently across domains measured by the IAT the relationship between cultural knowledge and implicit attitudes was almost completely accounted for by variability in explicit attitudes. Using a sample size of over 100,000 they found weak relationships between cultural knowledge and IAT effects. This would seem to indicate that whatever the IAT measures, it is more personal than extra-personal. 


Although it was proposed as a potential ``true pipeline'' to the attitudes of persons, the IAT seems as sensitive to social desirability concerns and the presence of others as explicit measures. Finally, although the measure is not perfect, it has noticeably increased our understanding of human social cognition and is still stimulating new and interesting research, which of course is the major criterion of success for any measure. 

\section{Uses of the IAT}%%this title needs to be changed
\label{sec:uses-iat}

The IAT is a useful measure, and we have touched upon some of these uses in previous sections. In this section, we will look at some of the major areas to which it has been applied over the last decade. While the IAT began as a tool to assess attitudes towards social groups, its uses have broadened to include measurement of personality, pain associations and evaluative conditioning. We will look at the success or otherwise of these attempts in the following section. 

\subsection{Consumer Research and the IAT}
\label{sec:cons-rese-iat}

One area where the IAT has seen much use is in the area of consumer research \cite{Lane2007,Maison2001}. Research in this area has focused on the effects of implicit attitudes on consumer choices. The IAT has shown some predictive validity here \cite{Maison2004}  but not significantly above the predictive power of explicit attitudes \cite{Greenwald2009}. One area where the IAT has proven useful is in examining the effects of evaluative conditioning on mature brand preferences \cite{Gibson2008} which reported that the conditioning could change attitudes (as measured with the IAT) towards brands for which the consumer had no pre-existing preference.


\subsection{Clinical Use of the IAT}
\label{sec:clinical-use-iat}

The IAT has been applied to clinical psychological research recently enough, and this has been somewhat successful \cite{DeHouwer2002}. However, the test retest reliability of the IAT averages around 0.6, which is far too low to be used in clinical decision making. This has not stopped many researchers however, but these results should be treated with caution as the precision of measurement may not be adaquete for the purposes for which the IAT is being used. 

One interesting study \cite{Grumm2008} points to a useful area in which the IAT has been applied. In this Grumm study, participants were recruited with chronic pain conditions. Their associations were measured using a self +pain design for the IAT, and they then underwent psychotherapy coupled with mindfulness programs to examine if these treatments were capable of changing their implicit associations. 

The study found that they did, with the authors reporting significant drops in self+pain associations over the course of the treatment. This finding is important as it provides validity for the conception of the IAT as measuring something useful, as the scores on the measure tracked the progress of patients through the treatment program, and this is unlikely to have occurred by chance.  

 The IAT has also been successful in distinguishing between spider and snake phobics and the general population \cite{Egloff2002,Lane2007}, and one interesting avenue of research would be a conceptual replication of the Grumm et al 2008 study using phobia sufferers and CBT to examine whether or not the same pattern of changes in automatic responses would be found. 

% Another area where the IAT has been applied is that of evaluative conditioning \cite{Mitchell2003}. This area has not received that much attention, as the results tend to be less spectacular than some of those in social cognition. 

A recent paper \cite{Boschen2007} used an IAT and measures of skin conductance to look at the development of fear responses in phobics. 

These authors found that while the skin conductance measures responded immediately to the intervention, this change was not reflected in the implicit associations until quite some time afterwards. This would seem to suggest that different mechanisms unerlie the information processing biases (measured by the IAT) and the autonomic responses (measured by SCR), which is a useful finding that may contribute to our understanding of the genesis of phobias. 

\subsection{Task Switching and the IAT}
\label{sec:task-switching-iat}



One psychometric characteristic correlated with IAT responses appears to be task-switching ability \cite{Mierke2003}. Mierke and Klauer established that IAT's which should not have been correlated showed substantial variance in common.  Through a series of experiments they demonstrated that task switching abilities appear to be the cause for this. They also reviewed this work in later research, and established that these differences could be controlled for by using the new $D$ algorithm developed by Greenwald et al \cite{Greenwald2003,Klauer2005}. 

The important question for future research in this area is whether or not task switching ability is independent of IAT scores, in that the distribution of IAT scores is similiar across all levels of the trait, or whether or not it affects the IAT scores significantly. If the former, then if this variable is controlled for, then there should be no problems, whereas if task switching ability is not independent of IAT scores, then the measure and scoring methods will need to be revised.  



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "PlaceboMeasurementByMultipleMethods"
%%% End: 

