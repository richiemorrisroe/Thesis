
\section{Introduction}

\section{Methodology}

\subsection{Experimental Procedure}
<<healthenv, echo=FALSE, results=hide>>=
load("healthforthesis.rda")
hom.data <- hom
load("tcqthesis.rda")
@ 

All participants were met at the entrance to the building by the primary researcher. They were given the informed consent documentation, and after they signed it, they completed three questionnaires (the MAAS, the LOT-R and the TCQ).The majority of participants also completed a scrambled sentence task which aimed to prime them for cooperation in the experiment. Such manipulations have been shown to be effective at increasing the size of placebo effects.  
Following this, they completed both an Optimism IAT and the Treatment Credibility IAT, where order of administration was counterbalanced across participants. Following this, the participants sat down next to the Biopac physiological monitoring data, and baseline data was recorded for five minutes.  Then, a blood pressure gauge was wrapped around the upper part of the non-dominant hand of the participant, and they were asked to squeeze a hand exerciser twenty times for two seconds each time. One minute after this, and every minute thereafter, participants were asked to rate their pain on a VAS from 1 to 10. If the participant was in the treatment or placebo group, then when they rated their pain as 7 or higher, the placebo cream was applied. The experiment continued until the participant either decided to withdraw, their pain rating reached 10 or 45 minutes elapsed  from when the bandage was applied. ECG and EDA recordings were taken 1000 times per second using the Biopac equipment and VAS ratings were recorded on paper by the experimenter. The placebo cream consisted of a  moisturising cream. 

Participants in the treatment group were told that the cream was a potent painkiller, recently approved, which would take effect almost immediately. Participants in the placebo group were told that they were receiving a placebo and that placebos have been clinically proven to reduce pain, and that it would take effect almost immediately. 


\section{Results}




<<importdata, echo=FALSE, results=hide>>=
setwd("./ExperimentDataforR/FullStudy/")
expmeasures <- read.csv("explicitmeasuresfixed.csv")
expmeasures[,"LOTR"] <- with(expmeasures, LOTR/6)
vasscores <- read.csv("VASscores.csv"       )
optiat <- read.csv("optiatres.csv" )
tcqiat <- read.csv("tcqiatres.csv")
setwd("../..")
@ 

<<loadpackages, echo=FALSE, results=hide>>=
require(psych)
require(xtable)
require(arm)
require(ggplot2)
require(reshape2)
require(eRm)
require(ltm)
require(boot)
require(plyr)
require(caret)
require(survival)
source("func.R")
@ 

<<iatsort, echo=FALSE, results=hide>>=
tcqiatsorted <- tcqiat[,c("Participant", "Date", "Time", "Block", "Accurate", "Actual", "Real", "Truth", "Fake", "Illusory", "Inaccurate", "Lies", "Cream", "Injections", "Pills", "Surgery", "Acupuncture", "FlowerEssence", "Homeopathy", "Reiki", "Correct", "BlockTime")]
optiatsorted <- optiat[, c("Participant", "Date", "Time", "Block", "Me", "Mine", "Myself", "Theirs", "Them", "Themselves", "Better", "Happy", "Improving", "Succeeding", "Disimproving", "Failing", "Sad", "Worse", "Correct", "BlockTime")]
@ 

<<optiatscore, echo=FALSE, results=hide>>=
optiatsorted[,"Block"] <- with(optiatsorted, gsub(":", "", x=Block))
optiatscore.mean <- calcIatScores(optiatsorted,Code="Participant", method="mean", words=c("Me", "Mine", "Myself", "Theirs", "Them", "Themselves", "Better", "Happy", "Improving", "Succeeding", "Disimproving", "Failing", "Sad", "Worse"))
names(optiatscore.mean)[1] <- "Participant"
names(optiatscore.mean)[6] <- "OptIAT.Mean"
optiatscore.median <- calcIatScores(optiatsorted,Code="Participant", method="median", words=c("Me", "Mine", "Myself", "Theirs", "Them", "Themselves", "Better", "Happy", "Improving", "Succeeding", "Disimproving", "Failing", "Sad", "Worse"))
names(optiatscore.median)[1] <- "Participant"
names(optiatscore.median)[6] <- "OptIAT.Median"
optiatscore <- merge(optiatscore.mean[c(1,6)], optiatscore.median[,c(1,6)], by="Participant")
@ 

\subsection{Analysis of IAT data}

The first step in the analysis of IAT data is to examine the differential impact of using the mean versus the median as the measure of central tendency for the calculation of IAT scores (the $D$ measure). The results for the Optimism IAT are shown in Figure \ref{fig:meanmedoptiatplot}. As can be seen from this figure, there were no major changes attributable to this difference (the correlation between the two scores was $r=0.91$). 

\begin{figure}
<<meanmedoptiatplot, echo=FALSE, fig=TRUE>>=
meanmedoptiatplot <- ggplot(optiatscore, aes(x=OptIAT.Mean, y=OptIAT.Median))+geom_point()+geom_smooth(method="lm")
print(meanmedoptiatplot)
@   
  \caption{Scatterplot with Linear Regression Smooth of IAT score for Optimism IAT calculated with mean (x) and median (y)}
  \label{fig:meanmedoptiatplot}
\end{figure}



<<optiatboot, echo=FALSE, results=hide>>=
optcritblocks <- merge(optiatblock3, optiatblock5, by="Participant")
Iatcalcopt <- function (data, indices=rep(0.00885, 113)) {
  d <- data[sample(indices, replace=TRUE),]
  b3mean <- apply(d[5:18], 1, mean, na.rm=TRUE)
  b3sd <- apply(d[5:18], 1, sd, na.rm=TRUE)
  b5mean <- apply(d[24:37], 1, mean, na.rm=TRUE)
  b5sd <- apply(d[,24:37], 1, sd, na.rm=TRUE)
  ovsd <- (b3sd+b5sd)/2
  Iatscore <- (b5mean-b3mean)/ovsd
}
optboot <- boot(data=optcritblocks, statistic=Iatcalcopt, R=1000)
optci <- boot.ci(optboot)
optmeanconf <- as.data.frame(optci[["normal"]])
names(optmeanconf) <- c("confidence level", "lower quantile", "upper quantile")
@ 



<<optmeanconfprint, echo=FALSE, results=tex>>=
optmeanconf.xtab <- xtable(optmeanconf, label="tab:optmeanconfprint", caption="Summary of Bootstrapped (n=1000) Calculations of IAT Optimism Score")
print(optmeanconf.xtab)
@ 

As can be seen from the Table \ref{tab:optmeanconfprint}, the mean score on the Optimism IAT is relatively unstable, even with quite a large sample. However, as shown in Figure \ref{fig:optbootplot}, the normal approximation used in the bootstrap seems appropriate. 

% <<optbootplot, echo=FALSE, fig=TRUE>>=
% print(plot(optboot))
% @ 


<<optstimboot, echo=FALSE, results=hide>>=
optmeanboot <- function (data, indices=rep(0.00885, 113)) {
  d <- data[sample(indices, replace=TRUE),]
  optmeans <- apply(d[,5:18], 2, mean, na.rm=TRUE)
}
optstimboot <- boot(optiatsorted, statistic=optmeanboot, R=1000)
optstimbootci <- boot.ci(optstimboot)
optstimbootplot <- plot(optstimboot)
@ 

<<tcqtestblocks, echo=FALSE, results=hide>>=
tcqiatsorted[,"Block"] <- with(tcqiatsorted, gsub(":", "", x=Block))
tcqiatscore.mean <- calcIatScores(tcqiatsorted, Code="Participant", method="mean", words=c("Accurate", "Actual", "Real", "Truth", "Fake", "Illusory", "Inaccurate", "Lies", "Cream", "Injections", "Pills", "Surgery", "Acupuncture", "FlowerEssence", "Homeopathy", "Reiki"))
names(tcqiatscore.mean)[1] <- "Participant"
names(tcqiatscore.mean)[6] <- "TCQIAT.Mean"
tcqiatscore.median <- calcIatScores(tcqiatsorted, Code="Participant", method="median", words=c("Accurate", "Actual", "Real", "Truth", "Fake", "Illusory", "Inaccurate", "Lies", "Cream", "Injections", "Pills", "Surgery", "Acupuncture", "FlowerEssence", "Homeopathy", "Reiki"))
names(tcqiatscore.median)[1] <- "Participant"
names(tcqiatscore.median)[6] <- "TCQIAT.Median"
tcqiatscore <- merge(tcqiatscore.mean[,c(1,6)], tcqiatscore.median[,c(1,6)], by="Participant")
IATscores <- merge(optiatscore, tcqiatscore, by="Participant")
@

Next, we examine the difference between the mean and median scores for the TCQ IAT. As can be seen from Figure \ref{fig:meanmedtcqiat}, the same pattern as emerged from the Optimism IAT scores is apparent, with little difference between the two measures of central tendency ($r=0.89$). 

\begin{figure}
<<meanmedtcqiat, echo=FALSE, figure=TRUE>>=
meanmedtcqpl <- ggplot(tcqiatscore, aes(x=TCQIAT.Median, y=TCQIAT.Mean))+geom_point()+geom_smooth(method="lm")
print(meanmedtcqpl)
@   
  \caption{Scatterplot of TCQIAT Median Scores against TCQ IAT mean scores with a linear regression smooth line}
  \label{fig:meanmedtcqiat}
\end{figure}



<<tcqiatboot, echo=FALSE, results=hide>>=
tcqcritblocks <- merge(tcqiatblock3, tcqiatblock5, by="Participant")
Iatcalctcq <- function (data=tcqcritblocks, indices=rep(0.00885, 113)) {
  d <- data[sample(indices, replace=TRUE),]
  b3mean <- apply(d[5:20], 1, mean, na.rm=TRUE)
  b3sd <- apply(d[5:20], 1, sd, na.rm=TRUE)
  b5mean <- apply(d[26:41], 1, mean, na.rm=TRUE)
  b5sd <- apply(d[,26:41], 1, sd, na.rm=TRUE)
  ovsd <- (b3sd+b5sd)/2
  Iatscore <- (b5mean-b3mean)/ovsd
}
tcqboot <- boot(tcqcritblocks, Iatcalctcq, R=1000)
tcqci <- boot.ci(tcqboot)
tcqmeanconf <- as.data.frame(tcqci[["normal"]])
names(tcqmeanconf) <- c("confidence level", "lower quantile", "upper quantile")
tcqmeanconf.xtab <- xtable(tcqmeanconf, label="tab:tcqmeanconf", caption="TCQ IAT mean D scores bootstrap confidence estimates")
tcqbootplot <- plot(tcqboot)
@ 

<<tcqmeanconf, echo=FALSE, results=tex>>=
print(tcqmeanconf.xtab)
@ 

As can be seen in Table \ref{tab:tcqmeanconf} the estimated mean IAT score on the treatment credibility IAT is also quite unstable, however as shown below in Figure, the normal approximation seems appropriate. 

<<tcqbootplot, echo=FALSE, fig=TRUE>>=
print(tcqbootplot)
@ 


<<tcqstimboot, echo=FALSE, results=hide>>=
tcqmeanboot <- function (data, indices=rep(0.00885, 113)) {
  d <- data[sample(indices, replace=TRUE),]
  tcqmeans <- apply(d[,5:20], 2, mean, na.rm=TRUE)
}
tcqstimboot <- boot(tcqiatsorted, statistic=tcqmeanboot, R=1000)
tcqstimbootci <- boot.ci(tcqstimboot)
tcqstimbootplot <- plot(tcqstimboot)
@ 

The next question is whether or not the IAT's have been contaminated by method variance. This can be assessed in a preliminary fashion by examining the correlations between the Treatment Credibility and Optimism IAT. The correlation between the two mean scored IAT measures was ($r=0.003$), while the correlation between the two median scored IAT measures was r=0.08, thus showing that method variance does not appear to have contaminated the results. 


\begin{figure}
<<tcqstimblock3, echo=FALSE, fig=TRUE>>=
print(plotmatrix(tcqstimblock3[,10:17])+geom_smooth())
@  
  \caption{TCQ IAT Stimuli Response Times in Block 3. The Diagonal shows a histogram of response times, while the off-diagonal elements show the pairwise scatterplots}
  \label{fig:tcqstimblock3}
\end{figure}


As can be seen from Figure \ref{fig:tcqstimblock3} above, the conventional stimuli appear to split into two blocks, the first consisting of Pills and Cream, and the second consisting of Injections and Surgery. The Alternative medicine stimuli seem to correlate reasonably well together, with the exception of Reiki and Homeopathy. The majority of responses are relatively fast, but there are a number of extreme outliers (the dots at the extreme right and top of each of the scatterplots). 

<<tcqstimblock5, echo=FALSE, fig=TRUE>>=
print(plotmatrix(tcqstimblock5[,10:17])+geom_smooth())
@ 

Again, a similiar pattern as above emerges, with the exception that surgery correlates extremely well with almost all of the other stimuli. Those relationships appear to be driven by a number of extremely large outliers which are visible in the plot and the correlations lowered significantly once these were excluded. 

<<optstimblock3, echo=FALSE, fig=TRUE>>=
print(plotmatrix(optstimblock3[,8:15])+geom_smooth(method="lm"))
@ 

Again a similiar pattern emerges from the Optimism Block 3 results. There are some strange correlations, but these appear to be accounted for by a number of outliers. These will be downweighted and the data re-analysed.

<<optstimblock5, echo=FALSE, fig=TRUE>>=
print(plotmatrix(optstimblock5[,8:15])+geom_smooth())
@ 

The results from Block 5 appear to be more in line with expectations, as all of the positive words and negative words correlate reasonably highly amongst themselves. 
\begin{figure}
<<optiatplotself, echo=FALSE, fig=TRUE>>=
print(plotmatrix(optiatsorted[5:10])+geom_smooth())
@   
 \caption{Plot of Optimism IAT self versus other words. Top triangle shows the correlations scaled by absolute value, bottom triangle shows scatterplots of each variable against the others, and diagonal line shows histograms with density estimation.}
 \label{fig:optiatplotself}
\end{figure}



 As can be seen in Figure \ref{fig:optiatplotself} the three self related words correlated weakly amongst themselves, as did the three other related words. The distributions of the responses (on the diagonal) shows that the reaction times followed a typical long tailed distribution common to reaction time measures. The lower triangle (scatterplots with loess line fitted) show that in general, reaction times were quicker for the self related words, which is typical in IAT research. 
 
 Next, the correlation between the different block times is assessed. As discussed in Chapter \ref{cha:literature-review}, some correlation would be expected given the nature of the IAT task, but the aim here is to quantify what effect, if any it would have had on the results. 
 
 \begin{figure}
<<tcqmeanresp, echo=FALSE, figure=TRUE>>=
tcqiat.mean.resp <- ddply(tcqiatsorted, .(Block, Participant), summarise, Correlations=mean(BlockTime, na.rm=TRUE))
## tcqmeanresp.pl <- ggplot(tcqiat.mean.resp, aes(x=MeanResponseTime))+geom_histogram+facet_grid(.~Block)
## print(tcqmeanresp.pl)
tcqiat.mean.m <- melt(tcqiat.mean.resp, id.vars=c("Participant", "Block"))
tcq.iat.c <- dcast(tcqiat.mean.m, Participant+...~Block)
tcq.block.corr.pl <- plotmatrix(tcq.iat.c[,3:length(tcq.iat.c)])+geom_smooth(method="lm")
print(tcq.block.corr.pl)
@    
   \caption{Correlations between Block Scores for Treatment Credibility IAT with linear regression smooth line}
   \label{fig:tcqblockcorr}
 \end{figure}

As can be seen from Figure \ref{fig:tcqblockcorr}, the correlations are relatively low between most of the blocks, though somewhat higher between blocks 3 and 5. Table \ref{tab:tcqcormat} gives the exact Kendall\'s $\tau$ between each of the blocks. As can be seen the correlations hover between 0.3 and 0.4, which is in line with expectations prior to the experiment. 

<<cormatrixtcqiat, echo=FALSE, results=tex>>=
cormat <- corr.test(tcq.iat.c[,3:length(tcq.iat.c)], method="kendall")[["r"]]
print(xtable(cormat, label="tab:tcqcormat", caption="Correlations between the blocks of the treatment credibility IAT (Kendall\'s $\tau$. All correlations are significant at the p<0.001 level"))
@ 
 

Next, the same process is repeated for the Optimism IAT. 

<<tcqmeanresp, echo=FALSE, figure=TRUE>>=
optiat.mean.resp <- ddply(optiatsorted, .(Block, Participant), summarise, Correlations=mean(BlockTime, na.rm=TRUE))
## optmeanresp.pl <- ggplot(optiat.mean.resp, aes(x=MeanResponseTime))+geom_histogram+facet_grid(.~Block)
## print(optmeanresp.pl)
optiat.mean.m <- melt(optiat.mean.resp, id.vars=c("Participant", "Block"))
opt.iat.c <- dcast(optiat.mean.m, Participant+...~Block)
opt.block.corr.pl <- plotmatrix(opt.iat.c[,3:length(opt.iat.c)])+geom_smooth(method="lm")
print(opt.block.corr.pl)
@    
   \caption{Correlations between Block Scores for Optimism IAT with linear regression smooth line}
   \label{fig:optblockcorr}
 \end{figure}

As shown in Figure \ref{fig:optblockcorr}, the correlations between blocks are moderate, though highest in blocks 3 and 5, as was seen for the Treatment Credibility IAT. Table \ref{tab:optcormat}. The correlations are a little higher than for the Treatment Credibility IAT, but still within an acceptable range. Its interesting to note that (with the exception of Block 5), the correlations are strongest between adjacent blocks, and drop off as the blocks move further apart, suggesting that the autocorrelation theory has some merit. 

<<cormatrixtcqiat, echo=FALSE, results=tex>>=
opt.cormat <- corr.test(opt.iat.c[,3:length(tcq.iat.c)], method="kendall")[["r"]]
print(xtable(opt.cormat, label="tab:optcormat", caption="Correlations between the blocks of the Optimism IAT (Kendalls $\tau$. All correlations are significant at the p<  0.001 level"))
@ 

The next question with regard to the IAT's is whether or not the non-critical blocks (that is, Blocks 1, 2 and 4) will be correlated. Given that these were administered in counterbalanced order and there was a small gap between them one would expect there to be much lower correlations between these blocks of the IAT's. These correlations (if present) should provide an index of general processing speed, and may be useful as predictor variables for some of the other measures. 

<<opttcqiatcorr, echo=FALSE, results=hide>>=
curnames <- names(opt.iat.c)
curnames.bl <- curnames[3:length(curnames)]
curnames.bl2 <- paste("Opt", curnames.bl, sep="")
curnames.d <- c(curnames[1:2], curnames.bl2)
names(opt.iat.c) <- curnames.d
curnames.tcq <- names(tcq.iat.c)
curnames.bl.tcq <- curnames[3:length(curnames)]
curnames.bl2.tcq <- paste("TCQ", curnames.bl.tcq, sep="")
curnames.d.tcq <- c(curnames.tcq[1:2], curnames.bl2.tcq)
names(tcq.iat.c) <- curnames.d.tcq
iat.block.merge <- merge(tcq.iat.c, opt.iat.c, by="Participant")
iat.block.merge2 <- iat.block.merge[, -1*c(2, 5,7,8,11,13)]
@ 

\begin{figure}
<<corriattcqopt, echo=FALSE, figure=TRUE>>=
corr.iat.tcq.opt.pl <- plotmatrix(iat.block.merge2[,2:length(iat.block.merge2)])+geom_smooth(method="lm")+geom_smooth(method="lm")
print(corr.iat.tcq.opt.pl)
@   
  \caption{Correlations between Non Critical Blocks of Optimism and Treatment Credibility IAT}
  \label{fig:corriattcqopt}
\end{figure}

As can be seen from Figure \ref{fig:corriattcqopt}, there were correlations between the two IAT's. These correlations, while significant, were quite low ($r\bar =0.20$) which equates to about 4\% of the variance. Therefore the two explicit measures can be safely be regarded as not being contaminated by method variance. 



<<selfreportcleanup, echo=FALSE, results=hide>>=
names(vasscores)[1] <-  "Participant"
names(expmeasures)[1] <- "Participant"
vasscores.test <- vasscores[,1:8]
expmeasurescomp <- merge(vasscores.test, expmeasures)
Iatandexpmeasures <- merge(expmeasurescomp, IATscores, by="Participant")
iatexp <- Iatandexpmeasures[,14:23]
Iatandexpmeasures[,"meanconv"] <- with(Iatandexpmeasures, (Pill+Cream+Inj)/3)
Iatandexpmeasures[,"meanalt"] <- with(Iatandexpmeasures, (Acu+Hom+Rei)/3)
Iatandexpmeasures[,"convaltcomp"] <- with(Iatandexpmeasures, meanconv -meanalt)
## Iatandexpmeasures[,"Date"] <- with(Iatandexpmeasures, dmy(Date))
@
 
Next, the relationship between overall response time in each block (total time to complete the block, including interstimulus intervals) was examined in terms of the demographic variables. 

<<optiatdemo, echo=FALSE, results=tex>>=
optiatdemographics <- merge(expmeasures, optiatsorted, by="Participant")
opt.demo <- xtable(summary(lm(BlockTime~Block+Age+Gender, data=optiatdemographics)), label="tab:optblocktimedemo", caption="Summary of Linear Regression of Block Time by Block, Age and Gender")
print(opt.demo)
@  
As can be seen from Table, the major influence on Block Time comes from Block, which is as expected given that Blocks 3 and 5 had three times as many trials as the other blocks. However, there is also an effect of gender, with males tending to respond somewhat quicker than females. This is interesting, as there are typically no gender based effects on IAT's (except for those which measure gender attitudes). 

<<tcqiatdemo, echo=FALSE, results=tex>>=
tcqiatdemographics <- merge(expmeasures, tcqiatsorted, by="Participant")
tcq.demo <- xtable(summary(lm(BlockTime~Block+Age+Gender, data=optiatdemographics), caption="Summary of Linear Rehression on Age, Gender and Individual Block Times.", label="tab:tcqblocktimedemo")) 
print(tcq.demo)
@ 

\begin{figure}
<<tcqiatgender, echo=FALSE, fig=TRUE>>=
tcqiatgender <- ggplot(na.omit(Iatandexpmeasures), aes(x=Gender, y=TCQIAT.Mean))+geom_boxplot()
print(tcqiatgender)
@   
  \caption{Treatment Credibility IAT Scores by Gender}
  \label{fig:tcqiatgend}
\end{figure}



As can be seen from Figure \ref{fig:tcqiatgend} above, there were no significant differences ($t=-0.4973, p=0.6211$) between men and women in  the sample with regards to their scores on the Treatment Credibility Questionnaire. However, the variance was much higher for men, which was a pattern replicated in previous research into Treatment Credibility (using a self report instrument described in Chapter \ref{cha:tcqthesis}).

\begin{figure}
<<optiatgender, echo=FALSE, fig=TRUE>>=
optiatgender <- ggplot(na.omit(Iatandexpmeasures), aes(x=Gender, y=OptIAT.Mean))+geom_boxplot()
print(optiatgender)
@   
  \caption{Optimism IAT by Gender}
  \label{fig:optiatgend}
\end{figure}

 As can be seen from Figure \ref{fig:optiatgend}, there were no significant differences ($t=-0.8234, df=49.761, p=0.4142$) between men and women with regards to their score on the Optimism IAT. 

<<ordtestiatprep, echo=FALSE, results=hide>>=
optblock3 <- optstimblock3[,1:15]
optblock5 <- optstimblock5[,1:15]
tcqblock3 <- tcqstimblock3[,1:17]
tcqblock5 <- tcqstimblock5[,1:17]
optblocks3and5 <-  merge(optblock3, optblock5, by="Participant")
optblocks3and5[,"Me.diff"] <-with(optblocks3and5,Me.x-Me.y )
optblocks3and5[,"Mine.diff"] <-with(optblocks3and5,Mine.x-Mine.y)
optblocks3and5[,"Myself.diff"] <-with(optblocks3and5,Myself.x-Myself.y)
optblocks3and5[,"Theirs.diff"] <-with(optblocks3and5,Theirs.x-Theirs.y)
optblocks3and5[,"Them.diff"] <-with(optblocks3and5,Them.x-Them.y)
optblocks3and5[,"Themselves.diff"] <-with(optblocks3and5,Themselves.x-Themselves.y)
optblocks3and5[,"Better.diff"] <-with(optblocks3and5,Better.x-Better.y)
optblocks3and5[,"Happy.diff"] <-with(optblocks3and5,Happy.x-Happy.y)
optblocks3and5[,"Improving.diff"] <-with(optblocks3and5,Improving.x-Improving.y)
optblocks3and5[,"Happy.diff"] <-with(optblocks3and5,Happy.x-Happy.y)
optblocks3and5[,"Improving.diff"] <-with(optblocks3and5,Improving.x-Improving.y)
optblocks3and5[,"Succeeding.diff"]<-with(optblocks3and5,Succeeding.x-Succeeding.y)
optblocks3and5[,"Disimproving.diff"] <- with(optblocks3and5,Disimproving.x-Disimproving.y)
optblocks3and5[,"Failing.diff"] <-with(optblocks3and5,Failing.x-Failing.y)
optblocks3and5[,"Worse.diff"] <-with(optblocks3and5,Worse.x-Worse.y)
optdiffs <- optblocks3and5[,c(1,30:42)]
tcqblocks3and5 <- merge(tcqblock3, tcqblock5, by="Participant")
tcqblocks3and5[,"Accurate.diff"] <- with(tcqblocks3and5, Accurate.x-Accurate.y)
tcqblocks3and5[,"Actual.diff"] <- with(tcqblocks3and5, Actual.x-Actual.y)
tcqblocks3and5[,"Real.diff"] <- with(tcqblocks3and5, Real.x-Real.y)
tcqblocks3and5[,"Truth.diff"] <- with(tcqblocks3and5, Truth.x-Truth.y)
tcqblocks3and5[,"Fake.diff"] <- with(tcqblocks3and5, Fake.x-Fake.y)
tcqblocks3and5[,"Illusory.diff"] <- with(tcqblocks3and5, Illusory.x-Illusory.y)
tcqblocks3and5[,"Inaccurate.diff"] <- with(tcqblocks3and5, Inaccurate.x-Inaccurate.y)
tcqblocks3and5[,"Lies.diff"] <- with(tcqblocks3and5, Lies.x-Lies.y)
tcqblocks3and5[,"Cream.diff"] <- with(tcqblocks3and5, Cream.x-Cream.y)
tcqblocks3and5[,"Injections.diff"] <- with(tcqblocks3and5, Injections.x-Injections.y)
tcqblocks3and5[,"Surgery.diff"] <- with(tcqblocks3and5, Surgery.x-Surgery.y)
tcqblocks3and5[,"Acupuncture.diff"] <- with(tcqblocks3and5, Acupuncture.x-Acupuncture.y)
tcqblocks3and5[,"FlowerEssence.diff"] <- with(tcqblocks3and5, FlowerEssence.x-FlowerEssence.y)
tcqblocks3and5[,"Homeopathy.diff"] <- with(tcqblocks3and5, Homeopathy.x-Homeopathy.y)
tcqblocks3and5[,"Reiki.diff"] <- with(tcqblocks3and5, Reiki.x-Reiki.y)
tcqdiffs <- tcqblocks3and5[,34:48]
optdiffs.dich <- apply(optdiffs, c(1,2), function (x) ifelse(x>0, 1, 0))
tcqdiffs.dich <- apply(tcqdiffs, c(1,2), function (x) ifelse(x>0, 1, 0))
@ 
<<optiatirt, echo=FALSE, results=hide>>=
optiat.rasch <- RM(na.omit(optdiffs.dich))
optiat.ppar <- person.parameter(optiat.rasch)
optiat.elim <- stepwiseIt(optiat.rasch)
@ 

\begin{figure}
<<optpimap, echo=FALSE, figure=TRUE>>=
print(plotPImap(optiat.rasch))
@   
  \caption{Person Item Map of Difficulty parameters for Optimism IAT}
  \label{fig:optpimap}
\end{figure}


<<optiatrachprint, echo=FALSE, results=tex>>=
optrasch.df <- with(optiat.rasch, as.data.frame(cbind(etapar, se.eta, betapar, se.beta)))
print(xtable(optrasch.df, label="tab:optrasch", caption="Ability Estimates for Rasch Model Analysis of Optimism IAT"))
@ 

Table \ref{tab:optrasch} shows the estimated parameters for a Rasch model of the optimism IAT stimuli. Figure \ref{fig:optpimap} shows the Person Item Map for this model. This map shows that most of the stimuli were equivalent in difficulty, which indicates that this IAT is suitable for measuring implicit optimism in the general population, however, more discriminating stimuli would be necessary if the instrument was to be used in a clinical sample. Additionally, the map shows that the majority of participants showed latent traits of less than zero, suggesting that implicit optimism is rarer than explicit optimism. 


A process of stepwise elimination was carried out to eliminate items which did not fit the model. In this case, the stimulus ``Myself'' was the only one which had significant model misfit. 

<<tcqiatirt, echo=FALSE, results=hide>>=
tcqiat.rasch <- RM(tcqdiffs.dich)

tcqiat.elim <- stepwiseIt(tcqiat.rasch)
tcqiat.ppar <- person.parameter(tcqiat.rasch)
@ 

<<tcqiatability, echo=FALSE, results=tex>>=
tcqrasch.df <- with(tcqiat.rasch, as.data.frame(cbind(etapar, se.eta, betapar, se.beta)))
print(xtable(tcqrasch.df, label="tab:tcqiatrasch", caption="Ability Estimates for Rasch Model of Treatment Credibility IAT"))
@ 

\begin{figure}
<<tcqiatpiplot, echo=FALSE, fig=TRUE>>=
tcqiat.piplot <- plotPImap(tcqiat.rasch)
print(tcqiat.piplot)
@   
  \caption{Person Item Difficulty Map, Treatment Credibility IAT}
  \label{fig:tcqpimap}
\end{figure}

Table \ref{tab:tcqiatrasch}  shows the estimated abilities and their associated standard errors for the Treatment Credibility IAT. Figure \ref{fig:tcqpimap} the estimates of person and item abilities can be seen in graphical form. Again, it can be seen from Figure \ref{fig:tcqpimap} that a majority of the sample had latent traits of less than zero, but that the item estimates of difficulty were approximately equal.


\subsection{Implicit-Explicit Relationships}
\label{sec:impl-expl-relat}

Next, the relationships between the explicit and implicit measures were examined. 

<<corrtestimplexpl, echo=FALSE, results=tex>>=
corr.imp.exp <- corr.test(Iatandexpmeasures[,14:25], method="kendall")[["r"]]
print(xtable(corr.imp.exp, label="tab:corrimpexp", caption="Correlations between Implicit and Explicit Measures"))
@ 

It can be seen from Table \ref{tab:corrimpexp} that the LOTR was only really correlated with the Acupuncture items and with the MAAS, the Conventional Treatment scales correlated within themselves, as did the Alternative treatment scales, while the two IAT measures showed no appreciable correlations with each other. The relationships between the IAT's and explicit measures were small, and surprisingly in the unpredicted direction (negative). Another surprise was that the direction of the correlation between the LOT-R and the MAAS was opposite to that observed in prior research. Possible reasons for these results are considered in the Discussion.  


\subsection{Explicit Measures}
\label{sec:explicit-measures}



<<lotrmaas, echo=FALSE, fig=TRUE>>=
lotrmaas <- ggplot(Iatandexpmeasures, aes(x=LOTR, y=MAAS))+geom_point()+geom_smooth(method="lm")+facet_grid(.~Condition)
print(lotrmaas)
@ 

The plot above in Figure \ref{fig:lotrmaas} shows that optimism and mindfulness were positively correlated with one another. Additionally this correlation appeared to be relatively stable across condition, though it appeared a little weaker in the Deceptive Placebo Group.  This is in contrast to the results found in a much larger scale study carried out earlier in the research. Note that one plausible explanation for this effect is that, in the experiment, the measures were administered in the opposite order - Optimism, followed by Mindfulness. It is possible that the completion of the mindfulness measure affected the way in which participants approached the Optimism measure. This theory is more fully discussed in Chapter \ref{cha:general-discussion}. 


\subsection{Relationships between Experimental Samples and Survey Samples}
\label{sec:relat-betw-exper}

Given the focus of this thesis on the integration of survey and experimental research, the next step was to examine the differences and similarities between the samples collected from the general population via survey and the experimental sample.


\begin{figure}
<<surveyoptimism, echo=FALSE, figure=TRUE>>=
survey.opt.pl <- ggplot(hom.data, aes(x=optimism))+geom_histogram()
print(survey.opt.pl)
@   
  \caption{Histogram of Optimism Scores in the Survey samples}
  \label{fig:surveyoptimism}
\end{figure}


In Figure \ref{fig:surveyoptimism} the distribution of optimism scores in the survey samples can be seen, while Figure \ref{fig:expoptimism} shows the equivalent plot for the experimental sample. It can be seen that the two plots are extremely different, with a much higher average optimism score in the experimental sample. To some extent, this is not unexpected given that the study was described as an investigation of painkilling drugs and there was an opportunity to win a smart-phone, so perhaps students with higher levels of optimism were more likely to agree to participate. 

\begin{figure}
<<experimentoptimism, echo=FALSE, figure=TRUE>>=
exp.opt.pl <- ggplot(expmeasures, aes(x=LOTR))+geom_histogram()
print(exp.opt.pl)
@   
  \caption{Distribution of Optimism Scores in the Experimental Sample}
  \label{fig:expoptimism}
\end{figure}


Next, the differences in mindfulness levels between the two samples were assessed. 

\begin{figure} 
<<surveymindfulness, echo=FALSE, figure=TRUE>>=
surv.mind.pl <- ggplot(hom.data, aes(x=mindfulness))+geom_density()
print(surv.mind.pl)
@  
  \caption{Density Plot for Mindfulness Scores, Survey Sample}
  \label{fig:surveymind}
\end{figure}

As can be seen from Figures \ref{fig:surveymind} and \ref{fig:expmind}, the pattern was quite different for mindfulness levels (as measured by the MAAS) as the levels of mindfulness were higheer in the survey sample. Again, this may be due to the association of mindfulness with introversion, as introverts may have been less likely to respond to the email invitiation(s) to take part in the study. 

\begin{figure}
<<experimentmindfulness, echo=FALSE, figure=TRUE>>=
exp.mind.pl <- ggplot(Iatandexpmeasures, aes(x=MAAS))+geom_density()
print(exp.mind.pl)
@   
  \caption{Density Plot for Mindfulness Scores, Experimental Sample}
  \label{fig:expmind}
\end{figure}


Finally, the treatment credibility questionnaire scores were examined to assess the differences between the survey and experimental samples. 

First, the differences between the two samples in terms of Pill credibility were examined. 

\begin{figure}
<<surveypill, echo=FALSE, figure=TRUE>>=
surv.pill.pl <- ggplot(credtotals, aes(x=Pilltot))+geom_density()
print(surv.pill.pl)
@   
  \caption{Pill Credibility Density Plot, Survey Sample (sample 2)}
  \label{fig:surveypill}
\end{figure}

\begin{figure}
<<experimentpill, echo=FALSE, figure=TRUE>>=
exp.pill.pl <- ggplot(Iatandexpmeasures, aes(x=Pill))+geom_density()
print(exp.pill.pl)
@   
  \caption{Pill Credibility Density Plot, Experimental Sample}
  \label{fig:exppill}
\end{figure}

As can be seen from Figures \ref{fig:surveypill} and \ref{fig:exppill}, the general population sample was higher peaked, with less variation around the peak than was the experimental sample. In fact, the experimental sample seemed to be more variable than the survey sample, which could either be due to a true difference in the distributions or due to a greater uncertainty in the experimental sample due to the smaller sample size. 

Next, the difference between Cream Credibility scores were assessed. 

\begin{figure}
<<surveycream, echo=FALSE, figure=TRUE>>=
surv.cream.pl <- ggplot(credtotals, aes(x=Creamtot))+geom_density()
print(surv.cream.pl)
@   
  \caption{Density Plot for Distribution of Cream Credibility Scores, Survey Sample (sample 2)}
  \label{fig:surveycream}
\end{figure}


\begin{figure}
<<experimentcream, echo=FALSE, figure=TRUE>>=
exp.cream.pl <- ggplot(Iatandexpmeasures, aes(x=Cream))+geom_density()
print(exp.cream.pl)
@   
  \caption{Density Plot for Distribution of Cream Credibility Scores, Experimental Sample}
  \label{fig:expcream}
\end{figure}

As shown in Figures \ref{fig:surveycream} and \ref{fig:expcream}, the survey group tended to have a more positive view of painkilling creams. While the survey group is strongly peaked at the right of the plot, the experimental group were more even distributed, with a peak at the centre of the plot. This is interesting, as one might expect the experimental group to be more positive towards painkilling treatments in general, given that they had agreed to take part in  a study which examined the effects of a new analgesic.

Next, the credibility scores for injection painkilling treatments were examined between the survey and experimental groups. 

\begin{figure}
<<surveyinj, echo=FALSE, figure=TRUE>>=
surv.inj.pl <- ggplot(tcq2, aes(x=Injtot))+geom_density()
print(surv.inj.pl)
@   
  \caption{Injection Credibility Density Plot, Survey Sample (sample two)}
  \label{fig:surveyinj}
\end{figure}


\begin{figure}
<<expinj, echo=FALSE, figure=TRUE>>=
exp.inj.pl <- ggplot(Iatandexpmeasures, aes(x=Inj))+geom_density()
print(exp.inj.pl)
@   
  \caption{Density Plot for Injection Credibility Scores, Experimental Sample}
  \label{fig:expinj}
\end{figure}


Figures \ref{fig:surveyinj} and \ref{fig:expinj} show that the Injection credibility scores were almost identical in their distributions between the two samples. 

Next, the Alternative treatment scores were examined between the two samples.
\begin{figure}
  
<<alttreatmentssurvey, echo=FALSE, figure=TRUE>>=
print(plotmatrix(credtotals[,4:6])+geom_smooth()+geom_jitter())
@   \caption{Density and Scatterplots for Alternative Treatments, Survey Sample}
  \label{fig:altsurvey}
\end{figure}

\begin{figure}
<<alttreatmentsexp, echo=FALSE, figure=TRUE>>=
print(plotmatrix(Iatandexpmeasures[,19:21])+geom_smooth()+geom_jitter())
@   
  \caption{Scatter and Density Plots for Alternative Treatments, Experimental Sample}
  \label{fig:alttreatmentsexp}
\end{figure}

Figures \ref{fig:altsurvey} and \ref{fig:alttreatmentsexp} show scatter and density plots for the survey and experimental samples, respectively. The only credibility score which looks significantly different is those for Homeopathy, which is significantly more bi-modal in the survey sample. 


\subsection{Randomisation Checks}
\label{sec:randomisation-checks}

Next, the comparability of the groups were assessed to ensure that the randomisation process had proved effective. 

<<randcheck1, echo=FALSE, results=tex>>=
tcq.xtab <- xtable(summary(aov(TCQIAT.Mean~Condition, data=Iatandexpmeasures)), label="tab:tcqiatcheck", caption="Summary of Anova of Treatment Credibility Scores by Condition")
opt.xtab <- xtable(summary(aov(OptIAT.Mean~Condition, data=Iatandexpmeasures)), label="tab:optiatcheck", caption="Summary of ANOVA of Optimism IAT scores by Condition")
conv.xtab <- xtable(summary(aov(meanconv~Condition, data=Iatandexpmeasures)))
alt.xtab <- xtable(summary(aov(meanalt~Condition, data=Iatandexpmeasures)))
chisq.gend <- with(Iatandexpmeasures, chisq.test(table(Gender, Condition)))
chisq.gend <- with(Iatandexpmeasures, chisq.test(table(Prime, Condition)))
@ 

<<tcqcheckprint, echo=FALSE, results=tex>>=
print(tcq.xtab)
@ 

<<optcheckprint, echo=FALSE, results=tex>>=
print(opt.xtab)
@ 

As can be seen from Table \ref{tab:tcqiatcheck} and Table \ref{tab:optiatcheck} the scores on the treatment credibility IAT, the optimism IAT did not differ by Condition. 

The results of a chi-square test showed that the gender of participants in each condition were equivalent, (p=\Sexp{chisq.gend[["p.value"]]}).
In addition, the priming manipulation was not significantly different across groups (p=\Sexp{chisq.prime[["p.value"]]}).



<<chisqcondition, echo=FALSE, results=tex>>=
Subsetiatandexp <- Iatandexpmeasures[with(Iatandexpmeasures,Condition!="No Treatment"),]
Subsetiatandexp <- droplevels(Subsetiatandexp)
chisq2 <- with(Subsetiatandexp, chisq.test(table(PlacResp, Condition)))
chisqtest2 <- as.data.frame(cbind(chisq2[["statistic"]], chisq2[["parameter"]], chisq2[["p.value"]], chisq2[["observed"]]))
names(chisqtest2)[1] <- "Chi Square"
names(chisqtest2)[2] <- "df"
names(chisqtest2)[3] <- "p Value"
chisq2.xtab <- xtable(chisqtest2)
print(chisq2.xtab)
@ 

As can be seen, there is no significant effect of condition on placebo response. However, as can also be seen from the table, this is not due to a lower than expected placebo response in the Deceptive Placebo group, but rather due to a higher than expected placebo response in the Open Placebo group. The next step was to examine if this result could be accounted for by the priming mechanism.

<<chisqtestprimeplac, echo=FALSE, results=tex>>=
chisq1 <- with(Iatandexpmeasures, chisq.test(table(Prime, Condition, PlacResp)))
chisqtest1 <- as.data.frame(cbind(chisq1[["statistic"]], chisq1[["parameter"]], chisq1[["p.value"]], chisq1[["observed"]]))
names(chisqtest1)[1] <- "Chi Square"
names(chisqtest1)[2] <- "df"
names(chisqtest1)[3] <- "p Value"
chisq1.xtab <- xtable(chisqtest1, label="tab:primeplacchi", caption="Chi Square for Relationship between Priming, Condition and Placebo Response")
print(chisq1.xtab)
@ 

In Table \ref{tab:primeplacchi} above, it can be seen that priming appears to be the driver of this effect, as the Placebo Response by Condition is extremely significant given the priming manipulation. Most of this improvement occurred in the Open Placebo group, which is an extremely interesting finding, one not reported in the literature before.  

This finding is much more clearly conveyed in Figure \ref{fig:placprimeplot}, where it can be seen that Participants were much more likely to respond to placebo following a priming intervention. Given that priming interventions typically take place outside conscious awareness, this suggests that there is at least some part of the placebo response which is amenable to non-conscious (or implicit) influences. 

\begin{figure}
<<placprimeplot, echo=FALSE, figure=TRUE>>=
plac.prime.pl <- ggplot(Iatandexpmeasures, aes(x=PlacResp))+geom_histogram()+facet_grid(.~Prime)
print(plac.prime.pl)
@   
  \caption{Proportion of Placebo Response in Primed and Non-Primed Conditions}
  \label{fig:placprimeplot}
\end{figure}

\begin{figure}
<<pairsplot, echo=FALSE, Fig=TRUE>>=
print(plotmatrix(iatexp)+geom_smooth(method="lm")+geom_jitter())
@   
  \caption{Scatterplots and Density Plots for Self Report and Implicit Measures}
  \label{fig:pairsplotimpexp}
\end{figure}

In Figure \ref{fig:pairsplotimpexp} the relationships between the self report and implicit measures are shown. It can be seen that the credibility scores break into conventional and alternative groups, while the LOT-R and MAAS do not correlate hugely with any of the other measures (but do correlate quite well with themselves, as noted above).  


\subsection{Pain Ratings}
\label{sec:pain-ratings}

<<survivaldata, echo=FALSE, results=hide>>=
painratings <- vasscores[,c(9:53)]
napainratings <- apply(painratings,1, function (x)  sum(is.na(x)))
lengthsurv <- 46-napainratings
Iatandexpmeasures[,"lengthsurv"] <- lengthsurv
censor <- Iatandexpmeasures[,"Censored"]
censor2 <- ifelse(censor==c("No", "Left"), 1, 0)
Surv.data <- Surv(lengthsurv,censor2)
@ 




<<paints, echo=FALSE, results=hide>>=
painratings <- vasscores[,c(1,2,8:53)]
painratings.temp <- painratings[,2:length(painratings)]
painratings.trans <- t(painratings.temp)
colnames(painratings.trans) <- as.character(t(painratings[,1]))
painratings.trans <- as.data.frame(painratings.trans)
painratings.trans[,"Time"] <- 1:nrow(painratings.trans)
pain.cond <- ddply(painratings, .(Condition), summarise, PainRatings=apply(painratings[,4:48], 2, mean, na.rm=TRUE))
pain.cond.m <- melt(pain.cond, id.vars="Condition")
@ 







\subsection{Analysis of Pain Ratings}
 
<<meanpaingroup, echo=FALSE, results=hide>>=
deceptivepain <- painratings[with(painratings,Condition=="Treatment"),]
placebopain <- painratings[with(painratings,Condition=="Placebo"),]
notreatpain <- painratings[with(painratings,Condition=="No Treatment"),]
meandeceptivepain <- apply(deceptivepain[,4:48], 2, mean, na.rm=TRUE)
meanplacebopain <- apply(placebopain[,4:48], 2, mean, na.rm=TRUE)
meannotreatpain <- apply(notreatpain[,4:48], 2, mean, na.rm=TRUE)
meangrouppainratings <- cbind(meandeceptivepain, meanplacebopain, meannotreatpain)
meangrouppainratings <- as.data.frame(meangrouppainratings)
meangrouppainratings[,"Time"] <- 1:45
meddeceptivepain <- apply(deceptivepain[,4:48], 2, median, na.rm=TRUE)
medplacebopain <- apply(placebopain[,4:48], 2, median, na.rm=TRUE)
mednotreatpain <- apply(notreatpain[,4:48], 2, median, na.rm=TRUE)
medpainratings <- as.data.frame(cbind(meddeceptivepain, medplacebopain, mednotreatpain))
medpainratings[,"Time"] <- 1:45
dec.pain.mean <- apply(deceptipvepain[,4:48], 2, mean, na.rm=TRUE)
open.pain.mean <- apply(placebopain[,4:48], 2, mean, na.rm=TRUE)
notreat.pain.mean <- apply(notreatpain[,4:48], 2, mean, na.rm=TRUE)

painbycond <- data.frame(Deceptive=dec.pain.mean, Open=open.pain.mean, NoTreat=notreat.pain.mean)
painbycond[,"Time"] <- 1:45
painbycond.m <- melt(painbycond, id.vars="Time")
@ 

\begin{figure}
<<tsmeanpainplot, echo=FALSE, fig=TRUE>>=
meanpain.melt <- melt(meangrouppainratings, id="Time")
tspainplot <- ggplot(meanpain.melt, aes(x=Time, y=value, label=variable, colour=variable))+geom_smooth(span=0.2)
print(tspainplot)
@   
  \caption{Plot of Pain Responses by Condition Over Time}
  \label{fig:tsmeanpainplot}
\end{figure}



As can be seen from Figure \ref{fig:tsmeanpainplot}, the placebo group tended to report lower mean pain ratings across time. This was an extremely unexpected finding, and therefore the pain ratings were reanalysed using medians, to lessen the effects that outliers could be having on the results. The curves shown above used a locally weighted smoother (loess, span=0.2) to create the lines, given the substantial non linearity of the results. However, this plot does show that there was a significant difference between the placebo group and the two other conditions. 

\begin{figure}
<<medtspainplot, echo=FALSE, fig=TRUE>>=
medpain.melt <- melt(medpainratings, id="Time")
medtspainplot <- ggplot(medpain.melt, aes(x=Time, y=value, group=variable, colour=variable))+geom_smooth(span=0.5)
print(medtspainplot)
@   
  \caption{Median Pain Ratings Over Time by Condition}
  \label{fig:medpainplot}
\end{figure}


As can be seen from Figure \ref{fig:medpainplot}, the results of the median pain ratings by group show exactly the same pattern as the mean pain ratings. This suggests that there is a real difference here, one that warrants further explanation. Again, a locally weighted smoother (loess, span=0.5) was used to fit the curves. 


\begin{figure}
<<medianpaintscorrelationplots, echo=FALSE, fig=TRUE>>=
par(mfrow=c(2,2))
print(acf(na.omit(with(medpainratings,meddeceptivepain))))
print(acf(na.omit(with(medpainratings,medplacebopain))))
print(acf(na.omit(with(medpainratings,mednotreatpain))), main="Autocorrelation No Treatment Group")
@   
  \caption{Autocorrelation Plots for Median Pain Responses over Time by Condition}
  \label{fig:autocorrpainplot}
\end{figure}


As can be seen above, the autocorrelation plots for the three groups appear to be similiar, which means that a the same ARIMA model can be fit to them. The first three differences are significant, and a process of ARIMA model fitting indicates that an ARIMA(1,3,1) model has the best AIC and likelihood. This is information that needs to be incorportated into an overall model which will be fit to the data.

\begin{figure}
<<meanpaintscorrelationplots, echo=FALSE, fig=TRUE>>=
plot.new()
print(acf(na.omit(with(meangrouppainratings, meannotreatpain))))
print(acf(na.omit(with(meangrouppainratings,  meandeceptivepain))))
print(acf(na.omit(with(meangrouppainratings,meanplacebopain))))
@   
  \caption{Mean Autocorrelation plots for pain ratings over time}
  \label{fig:meanautocorrplot}
\end{figure}


The mean pain ratings were also examined for autocorrelations, and as shown in Figure \ref{fig:meanautocorrplot}, the results were exactly the same as for the median pain ratings, indicating an ARIMA(1,3,1) model was the best fit for the data.


\subsection{Variables impacting the placebo response}

In this section, the covariates associated with response to placebo in this sample are examined, first graphically and then through a process of formal model fitting. 


\begin{figure}
<<ggplothistcond, echo=FALSE, fig=TRUE>>=
plac.resp.hist.pl <- ggplot(Iatandexpmeasures, aes(x=TCQIAT.Mean))+geom_density()+facet_grid(.~PlacResp)
print(plac.resp.hist.pl)
@   
  \caption{TCQIAT.Mean against Pain Responses Over Time}
  \label{fig:histresp}
\end{figure}


From Figure \ref{fig:histresp}, it can be seen that the participants who did respond to placebo had marginally higher Treatment Credibility IAT scores than those who did not. 






\begin{figure}
<<optiatcorrsurv, echo=FALSE, fig=TRUE>>=
optiat.histcond <- ggplot(Iatandexpmeasures, aes(x=OptIAT.Mean))+geom_density()+facet_grid(.~PlacResp)
print(optiat.histcond)
@   
  \caption{Density Plots of Optimism IAT Scores by Condition}
  \label{fig:opthistcond}
\end{figure}


Again, it can be seen from Figure \ref{fig:opthistcond} that those who responded to placebo had higher optimism IAT scores than  those who did not, suggesting that something about the IAT is predictive of placebo response. 

\begin{figure}
<<creamhistcond, echo=FALSE, fig=TRUE>>=
cream.hist.cond <- ggplot(Iatandexpmeasures, aes(x=Cream))+geom_density()+facet_grid(.~PlacResp)
print(cream.hist.cond)
@   
  \caption{Desnity Plot for Mean Cream Credibility Scores by Condition}
  \label{fig:creamhistcond}
\end{figure}


Figure  \ref{fig:creamhistcond} shows that there was a difference in the mean cream credibiliuty scores by whether or not a participant responded to placebo, but the difference was not significant ($t=-0.9545, df=53.766, p=0.3441$). 

\begin{figure}
<<ggplotplacyesno, echo=FALSE, fig=TRUE>>=
placrespyes <- painratings[with(painratings,PlacResp=="Yes"),]
placrespno <- painratings[with(painratings,PlacResp=="No"),]
placresyesmean <- apply(placrespyes[4:48], 2, mean, na.rm=TRUE)
placresnomean <- apply(placrespno[4:48], 2, mean, na.rm=TRUE)
placresyesnopain <- as.data.frame(cbind(placresyesmean, placresnomean))
placresyesnopain$Time <- 1:45
placres.melt <- melt(placresyesnopain, id="Time")
placresplot <- ggplot(placres.melt, aes(x=Time, y=value, group=variable, colour=variable))+geom_line() +geom_smooth(method="loess")
print(placresplot)
@   
  \caption{Pain Ratings of Participants by Response to Placebo Across Time. Straight line is a loess smoother, the jagged line represents the actual pain levels}
  \label{fig:placyesno}
\end{figure}


A number of findings are apparent from the plot above in Figure \ref{fig:placyesno}. The placebo effect was approximately equivalent to a 15\% decrease in pain (read from the graph at the point the no response participants pain reached seven). This is a relatively large effect, and adds confidence to the significant results for modelling reported below. In addition, the participants who responded to placebo tended to remain in the experiment for a longer period of time (which is intuitively obvious). Below, formal model testing for the major hypotheses takes place. 

\subsection{Logistic Regressions on Placebo Response}

In order to examine whether or not the IAT scores were predictive of placebo response, a logistic regression model was used. Logistic regression was chosen for this as the response outcome was binary, and this method extends the linear regression model for binary outcomes. 


<<placmod1, echo=FALSE, results=tex>>=
placmod1 <- glm(PlacResp~TCQIAT.Mean, data=Iatandexpmeasures, family=binomial(link="logit"))
placmod1.xtab <- xtable(summary(placmod1))
print(placmod1.xtab)
@ 

As can be seen above in Table \ref{tab:placmod1}, the treatment credibility IAT was not a significant independent predictor of placebo response.

<<placmod2, echo=FALSE, results=tex>>=
placmod2 <- glm(PlacResp~OptIAT.Mean, data=Iatandexpmeasures, family=binomial(link="logit"))
placmod2.xtab <- xtable(summary(placmod2))
print(placmod2.xtab)
@ 

As shown in Table \ref{tab:placmod2} the Optimism IAT is not an independent significant predictor of placebo response either. 

<<placebolotr, echo=FALSE, results=tex>>=
placmod.lotr<- glm(PlacResp~LOTR, data=Iatandexpmeasures, family=binomial(link="logit"))
placmod.lotr.xtab <- xtable(summary(placmod.lotr))
print(placmod.lotr.xtab)
@ 

In addition, the Life Orientation scores are not a significant predictor of placebo response either, as shown in Table \ref{placebolotr}.

However, when these three variables are placed into the model together, the result is significant.

<<placeboglm, echo=FALSE, results=tex>>=
placmod6<- glm(PlacResp~poly(TCQIAT.Mean,2)*poly(OptIAT.Mean,2)*LOTR, data=Iatandexpmeasures, family=binomial(link="logit"))
placmod.xtab <- xtable(summary(placmod6))
print(placmod.xtab)
@ 

As can be seen from Table \ref{tab:placmodinter} when interactions were allowed and the Life Orientation Test was added to the model, both IAT measures were significantly associated with placebo response, and all of the three variable's interactions were also significant. 

In addition, this model explains approximately 27\% of the variance in placebo response (using a pseudo R-square of 1-(residual deviance/null deviance)).


<<ggplot3wayinter, echo=FALSE, fig=TRUE>>=
iatexpno <- Iatandexpmeasures[Iatandexpmeasures$PlacResp=="No",]
iatexpyes <- Iatandexpmeasures[Iatandexpmeasures$PlacResp=="Yes",]
iatexpno <- na.omit(iatexpno)
iatexpyes <- na.omit(iatexpyes)
iatexpyesno <- rbind(iatexpyes, iatexpno)
lotriatplot <- ggplot(iatexpyesno, aes(x=LOTR, y=TCQIAT.Mean , colour=PlacResp, size=OptIAT.Mean))
lotriatplot2 <- lotriatplot+layer(geom="point")
print(lotriatplot2)
@ 
 The plot above in Figure \ref{fig:3wayinter} indicates that there appears to be a non linear interaction between the three variables included in our final model. It can be seen that extremely high scores on both the treatment credibility questionnaire and the Life Orientation test appear to be associated with not responding to placebo, while moderate levels of all three variables appear to provide the greatest likelihood of placebo response. 

<<lotrtcqsmoothplot, echo=FALSE, fig=TRUE>>=
lotrtcqplot <- ggplot(iatexpyesno, aes(x=LOTR, y=TCQIAT.Mean , colour=PlacResp))
lotrtcqplot2 <- lotrtcqplot+layer(geom="point")
print(lotrtcqplot2)
@  

This is perhaps clearer in Figure \ref{fig:lotrtcqplot} where it can be seen that the majority of placebo response occurs at median levels of both self reported optimism and implicit treatment credibility. 

<<lotroptplot, echo=FALSE, fig=TRUE>>=
lotroptplot <- ggplot(iatexpyesno, aes(x=LOTR, y=OptIAT.Mean , colour=PlacResp))
lotroptplot2 <- lotroptplot+layer(geom="point")
print(lotroptplot2)
@ 

From Figure \ref{fig:lotroptplot} it can be seen that scores of 0 or above on the optimism IAT (reflecting no to small difference in favour of positive stimuli) and high self reported optimism are associated with a greater likelihood of placebo response. 

\subsection{Machine Learning and the Placebo Response}
\label{sec:mach-learn-plac}

Given the confusing results obtained from linear statistical modelling of the placebo response, it was decided to fit a more flexible model, treating the placebo response as a two valued (Yes, No) classification task. A random forest model was used for this purpose. 

<<randomforestCV, echo=FALSE, results=hide>>=
train.ind <- sample(1:54, 40, replace=FALSE)
iatandexpfull <- Iatandexpmeasures[,c("PlacResp", "Age", "Gender", "Prime", "LOTR", "MAAS", "Pill", "Cream", "Inj", "Acu", "Hom", "Rei", "OptIAT.Mean", "OptIAT.Median", "TCQIAT.Mean", "TCQIAT.Median", "meanconv", "meanalt", "convaltcomp", "lengthsurv")]
iatandexpfull <- na.omit(iatandexpfull)
iatandexpfull.train.ind <- with(iatandexpfull,createDataPartition(PlacResp, p=0.8, list=FALSE))
iatandexpfull.train <- iatandexpfull[iatandexpfull.train.ind,]
iatandexpfull.test <- iatandexpfull[-iatandexpfull.train.ind,]
rf.train <- train(PlacResp~TCQIAT.Mean+meanconv+OptIAT.Mean, data=iatandexpfull)
rf.pred <- predict(rf.train, iatandexpfull.test)
test.xtab <- xtable(confusionMatrix(rf.pred, iatandexpfull.test$PlacResp)$table, label="tab:rfplac", caption="Random Forest Accuracy on Placebo Response (Test set)")
var.used.count <- varUsed(rf.train[["finalModel"]])
var.used.count <- as.data.frame(var.used.count)
rownames(var.used.count) <- c("TCQIAT.Mean", "OptIAT.Mean", "meanconv")

## var.used.count.m[,"variable"] <- names(iatandexpfull)
## ggplot(var.used.count.m, aes(x=variable, y=value))+geom_histogram()+coord_flip()

@ 

<<rfTestResults, echo=FALSE, results=tex>>=
print(test.xtab)
@ 

As can be seen from Table \ref{tab:rfplac}, the random forest predicted the unseen data for the placebo response exceptionally well, with an accuracy of 1 ($95CI 0.7684-1$), and was significantly better than a random prediction ($p=0.002059$). This suggests that the major hypothesis of the thesis, that implicit measures would be a useful predictor of the placebo response was accurate. This subject is covered further in the discussion. 

\begin{figure}
<<varImpPlot, echo=FALSE, figure=TRUE>=
print(varImpPlot(rf.train[["finalModel"]]))
@   
  \caption{Variable Importance Plot for Random Forest Model on Placebo Response}
  \label{fig:varimprf}
\end{figure}



\subsection{Analysis of Physiological Data}

<<tsimport, echo=FALSE, results=hide>>=
physfiles <- fileImport("ExperimentDataforR/FullStudy/PhysMeasures/Richie1ps", pattern=".txt$")
phys.mat <- listToDf(physfiles)
physnames <- colnames(phys.mat)
names(phys.mat) <- NULL
phys.df <- as.data.frame(phys.mat)
@


<<GSRcollate, echo=FALSE, results=hide>>=

biologicaldata <- as.data.frame(biologicaldata)
biodata2 <- gsub(pattern="phys", replacement="GSR", x=biodata)
biologicaldata <- biologicaldata[1:31150,1:107]
colnames(biologicaldata) <- biodata2
write.csv(biologicaldata, file="GSRdata.csv")
pbionotna <- apply(biologicaldata, 2, function (x) sum(!is.na(x)))
write.csv(biologicaldata, file="GSRdata.csv")
rm(list=ls(pattern="phys"))
gc()
@ 
<<GSRtrans, echo=FALSE, results=hide>>=
GSRtrans <- matrix(NA, nrow=107, ncol=31150)
for (i in seq_along(biologicaldata)) {
  GSRtrans[i,] <- t(biologicaldata[,i])
  rownames(GSRtrans) <- colnames(biologicaldata)
  }
GSRtrans <- as.data.frame(GSRtrans)
@ 

<<gsrcollate, echo=FALSE, results=hide>>=
x <- paste("Time", as.character(1:31150))
x[31151] <- "Participant"
GSRtrans$Participant <- rownames(GSRtrans)
colnames(GSRtrans) <- x
GSRtrans$survlength <- apply(GSRtrans, 1, function (x) sum(!is.na(x)))
GSRtrans$survlengthdiv <- with(GSRtrans, survlength/600)
GSRtrans$Participant <- gsub(pattern="GSR", replacement="", x=GSRtrans$Participant)
partsurvgsr <- GSRtrans[,c("Participant", "survlength", "survlengthdiv")]
partsurvmin <- Iatandexpmeasures[,c("Participant","Condition", "PlacResp", "lengthsurv")]
GSRtranswithcond <- merge(GSRtrans, partsurvmin, by="Participant")
write.csv(GSRtrans, file="GSRtrans.csv")
@ 

<<gsrbycond, echo=FALSE, results=hide>>=
gsrdeceptive <- GSRtranswithcond[GSRtranswithcond$Condition=="Treatment", ]
gsropen <- GSRtranswithcond[GSRtranswithcond$Condition=="Placebo", ]
gsrnotreat <- GSRtranswithcond[GSRtranswithcond$Condition=="No Treatment", ]
gsrplacyes <- GSRtranswithcond[GSRtranswithcond$PlacResp=="Yes",]
gsrplacno <- GSRtranswithcond[GSRtranswithcond$PlacResp=="No",]
@ 

Before the analysis of GSR data was conducted, the mean and median GSR per group were scaled to ensure that they were directly comparable. Scaling was performed using a z-score method, where each observations value was subtracted from the mean and divided by the standard deviation of all the observations. 


<<gsrmeans, echo=FALSE, results=hide>>=
deceptivemeangsr <- lapply(gsrdeceptive[,2:31150], mean, na.rm=TRUE)
openmeangsr <- lapply(gsropen[,2:31150], mean, na.rm=TRUE)
notreatmeangsr <- lapply(gsrnotreat[,2:31150], mean, na.rm=TRUE)
meangsr <- as.data.frame(cbind(deceptivemeangsr,openmeangsr, notreatmeangsr))
meangsr <- lapply(meangsr, as.numeric )
meangsr <- as.data.frame(lapply(meangsr, scale))
meangsr$Time <- 1:31149
@ 

<<meanplotgsr, echo=FALSE, fig=TRUE>>=
par(mfrow=c(2,2))
plot(as.ts(na.omit(meangsr[,1:3])), main="Mean GSR over time")
@ 

The results shown above in Figure \ref{fig:meangsr} are quite unexpected, but fit with the strange pain ratings observed in this experiment. It can be seen that the Open Placebo group had the lowest GSR over time (middle plot), and that the deceptive pain group seemed to have the highest GSR throughout the experiment. The No Treatment group chart is perhaps the strangest, showing a steady upward trend until about 25 minutes into the experiment, and then falling steadily from there to reach (at 30000, or 45 minutes after the pain was induced) approximately the level which it began. This may have occurred due to habituation to the experimental environment, as they had no experimental manipulation during the course of the study which might have changed their GSR. In contrast, the Open Placebo group show a low GSR starting off which then rises slowly, dips and then rises again. The course of GSR in the Deceptive Placebo group looks like what would have been expected from the No Treatment group; i.e. a slow and steady rise throughout the experiment.

<<gsrmedians, echo=FALSE, results=hide>>=
deceptivemediangsr <- lapply(gsrdeceptive[,2:31150], median, na.rm=TRUE)
openmediangsr <- lapply(gsropen[,2:31150], median, na.rm=TRUE)
notreatmediangsr <- lapply(gsrnotreat[,2:31150], median, na.rm=TRUE)
medgsr <- cbind(deceptivemediangsr, openmediangsr, notreatmediangsr)
medgsr <- lapply(medgsr, as.numeric)
medgsr <- as.data.frame(medgsr)
medgsr <- as.data.frame(lapply(medgsr, scale))
@ 

<<gsrmedianplot, echo=FALSE, fig=TRUE>>=
## plot(as.ts(na.omit(medgsr)), main="Median GSR Over Time", ylab="Time")
@ 

Again, the same pattern in GSR is seen in Figure \ref{fig:mediangsr} which suggests that the mean results shown in Figure \ref{fig:meangsr} are not the result of a small number of anomalous observations. 

<<ggplotgsr, echo=FALSE, fig=TRUE>>=
meangsr.melt <- melt(meangsr, id="Time")
meangsrplot <- ggplot(meangsr.melt, aes(x=Time, y=value, label=variable, colour=variable))
meangsr2 <- meangsrplot+layer(geom="line")
print(meangsr2)
@ 


 


\section{Discussion} 

A number of caveats are in order here. Firstly, neither the optimism IAT or the treatment credibility IAT were independently predictive of placebo response. However, when the model included an interaction between them, all three of these variables were significant (as in the model shown above). This may indicate that there may be some irrelevant (from the conventional scoring perspective) feature of the IAT measures which was predictive of placebo response in this sample. This is a matter which can be teased out by future research. 

Secondly, given the number of models fitted, some were almost certain to come up as significant, and the three way interaction between the two IAT measures and the Life Orientation Test was not a hypothesis of the research. 

It might be questioned why the Condition variable was not included in the model - it was, but it was dropped as its presence caused errors in the model fit. A little thought explains why this is so - placebo response was only possible in 2 of 3 conditions, and Condition acted as a proxy for these, thus causing issues with the model fit (in essence, Condition was collinear with placebo response). The final model shown above was superior to the other models considered, in terms of AIC and other model fit indices. 


%%% Local Variables:
%%% TeX-master: "PlaceboMeasurementByMultipleMethods"
%%% End:
