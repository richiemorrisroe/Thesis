
\section{Introduction}

In this section, the methods used in this thesis will be described, along with the procedures for all of the research carried out, followed by a description of the statistical analyses used in this research.
This researched aimed to assess the differential contributions of implicit and explicit expectancy measures of treatment credibility and optimism to the prediction of the placebo response. 

This chapter will consist of the following sections, representing the core parts of the thesis.

\begin{enumerate}
\item The theoretical model of the thesis will be explained
\item The approach taken towards the development of the IAT(s) will be described, using interviews and repertory grids
\item The methods used for the development and validation of the scales used in the research will be described
\end{enumerate}

\section{Introduction to the theory}

Theories form an indispensible part of science. They represent an attempt to generalise beyond particular forms of evidence and data and to derive some kinds of overall principles which lie behind the oberved events. The major theories behind the placebo and implicit measures were reviewed in  chapter \ref{cha:literature-review}, and in this chapter provides  an attempt to synthesise all of this information into a coherent whole. The major building blocks of this theory are as follows:
\begin{enumerate}
\item The results of implicit measures point towards there being at least two systems of attitude assessment and evaluation of stimuli in the human mind \footnote{perhaps more, but certainly at least two}
\item The placebo effect is typically conceptualised as a conscious phenomenon, in spite of the experimental evidence
\item There appear to be feedback loops between bodily sensations and conscious perception - embodied cognition
\item These feedback loops are evidence against an additive model of drug-placebo interactions
\item Despite the centrality of such conceptions to the placebo effect, no theory has as yet incorporated these findings into their theories
\end{enumerate}

This section will briefly review the evidence in favour of the above propositions, then will elucidate how these could be combined into our theories of placebo and implicit measures, and will provide some testable hypotheses regarding the theory, in the spirit of Popperian falsification.

\subsection{Implicit Measures and Dual Process Models of Mind}

The notion of dual process models of mind is an old one, dating back within psychology to at least the time of Freud , and possibly before. However, the modern conception of dual process models is much more recent, and developed as a result of work with implicit measures and through the findings of cognitive psychology. Essentially, the modern theory suggests that there are two prevalant systems of reasoning inherent to humans, a slow, rational, conscious system, and a fast, frugal and implicit system \cite{Kahneman2002}. 

These two systems activate under different conditions and seem to perform different functions. One of the major hypotheses emerging from this theory is that under conditions of attentional strain, the implicit system takes over. This is, as we have seen in the previous chapter, borne out by much of the research into implicit attitudes. Asendorpf \cite{Asendorpf2002} demonstrated what came to be called the double-dissociation effect, where implicit measures (of shyness, in this case) were more predictive of performance on a spontaneous speaking task (the Trier Social Stress Test), while explicit measures were more predictive of considered, deliberate behaviour. These findings have been further replicated by other authors   Thus, we can take the results of the IAT research and that into other implicit measures as pointers towards the operation of this system. The major point to take from this section is that this system appears to exist, and yet has only been touched upon in one or two articles over the past decade \cite{Geers2005}. 

\subsection{Conscious Conceptions of the Placebo}

The dominant model within placebo research at present is the response expectancy theory of Kirsch \cite{Kirsch1985, Kirsch1997a}. This theory conceptualises the placebo as resulting from response expectancies, which are defined as ``the conscious expectation of a non-volitional response''. This theory has had some success, displacing the then prevalent theory of conditioned placebo responses \cite{Vuodouris1985}. That being said, the very definition of placebo and its nature as occuring as a result of deception and belief that one is getting a real drug would seem to suggest that non-conscious systems must be centrally involved in the mediation between awareness and the documented physical responses. 

Indeed, the Geers et al study cited earlier \cite{Geers2005} demonstrated that semantic priming (by means of a scrambled sentence task) was an independent predictor of the response to a sleep placebo, which given that semantic priming does not effect conscious awareness , implies that such priming (and the implicit system more generally) can affect the response to placebos and indeed biologically active treatments. Another study which points in the same direction is the Shiv et al 2005 \cite{Shiv2005a} study which demonstrated an effect of price of an energy drink effecting the number of puzzles solved by participants in a particular time. This effect disappeared when participants attention was drawn to it, which again implies that implicit systems were involved. Despite this evidence, the dominant theoretical framework remains untouched. In this chapter, I will propose a new model that incorporates both of these systems, and makes a number of predictions that will be either supported or rejected by further research. 

\subsection{Embodied Cognition and Placebo}

Another issue with most of the conceptions of placebo current in today's research is that they are almost exclusively cognitive, a point made most forcefully by anthropology researchers  %Add this citation. 
This seems strange, given that it rests on assumptions regarding the relationship of mind and body which all of the evidence of placebo would seem to argue against. It seems that the theoretical perspective within the field is that the mind may effect the body, but not vice versa. Unortunately, this is an untenable proposition, as recent work on haptic cognition (where judgements made by participants are affected by the sensory input they are receiving at the time), published in Science in 2010 %get this paper too
Indeed, more recent work by Cwir \cite{Cwir2011} suggests that awareness of one's own interioceptive processes appears to be a good predictor of people's ability to predict the emotional states of others. 



Indeed, there has been a resurgance of interest in mind-brain-body feedback loops within psychology and the social sciences more generally of late. It seems that the dominant cognitive model of mind (a kind of splendid isolation for the brain) is being slowly worn down by experimental evidence. An approach such as this was also proposed by Meissner et al in 2009 \cite{Meissner2009} in their meta-analysis which showed large placebo effects in some areas and none in others. They suggested that the larger placebo effects may have occurred in some conditions but not in others as the places in which placebo effects occurred tended to be those systems which have large nervous system connections with the brain, as opposed to communication typically mediated through hormones, which are many orders of magnitude slower. One problem with Meissner's theory is that he posits that placebo effects do not occur in clinical trials when the outcome of interest is a hormone such as cortisol. Howevever, the field of psycho-neuro-immunology has noted that psychological variables (specifically optimism) exert major influences on antibody responses. There is also some emerging evidence that mindfulness based treatments appear to affect antibody responses, at least in cancer patients. This begs the question of why the analysis by Meisnner et al found no such effect. One explanation for these conflicting findings would be that the placebo effect is mostly determined by current state effects, while those effects investigated by psycho-neuro-immunology are the result of certain trait like characteristics of individuals.  

One psychological state which may have an impact on placebo responses, and should if my theory is to hold is that of mindfulness. Mindfulness is often defined as a moment to moment awareness of somatic and mental processes. If, as the results of Geers et al suggest, somatic focus can increase the size of placebo effects, then mindfulness (or another proxy marker for somatic focus) should also moderate the size of observed placebo responses. One problem with this hypothesis is that it is not clear in which direction the relationship should go. One could make an argument that mindfulness could reduce the size of placebo effects, as if the feedback loop is made conscious, then it should lose its power, or one could argue that higher levels of trait mindfulness would allow for more attention to be placed on the somatic sensation, thus increasing the placebo response. This presents a difficulty in the attempt to lay out bold conjectures and then attempt to refute them. 

If attention is conceptualised as a limited resource, then placebo effects should be enhanced by placing participants in conditions of low stimulation while the treatment is applied. However, this hypothesis causes problems when we considered (below) the effects of participant provider interaction, which appear to account for a significant portion of observed placebo effects. 

\subsection{Additive Models of Placebo}

The common approach throughout clinical trials, and the study of placebo effects more generally, is that the effects of drug and placebo are additive. This assumption leads nicely to the principle that placebo effects and drug effects can be seperated precisely. However, not all of the evidence points in this direction, and (apart from statistical convenience) there exists no apriori reason why this should be the case. Indeed, the work of Geers et al on somatic focus would seem to suggest that paying attention to somatic experience can increase the size of placebo effects. This could be occuring because of a feedback loop whereby a treatment is applied, the patient's awareness of the treatment leads them to attend to sensations related to the treatment, which engages the body's own healing systems, which then increase the size of the effect over and above what would have happened without awareness of treatment on the part of the patient. It is perhaps for this reason that drugs which are adminstered by an automated process are less effective \cite{Benedetti2003}. 

Another issue to consider in terms of mathematical models of placebo response is the phenomenon of the active placebo. This is where an active drug is offered as a treatment for which it has no efficacy, and nonetheless this treatment produces larger healing effects than a typical sugar pill placebo. I would argue that this phenomenon occurs because the side-effects of the drug produce  a feedback loop whereby the treatment has a somatic impact, which alerts participants to the treatment, causes them to accept it as more credible, and thus activates the body's own healing systems. This process, over time, could easily create a conditioned response to the original non-effective treatment, and loops such as this could be responsible for the observations regarding the efficacy of conditioned placebo responses. In this sense, I am making the argument that conditioned placebo responses are turned into expectancies over time.   


\subsection{Social Aspects of Placebo}

In addition to the possibility of feedback loops between awareness and sensation contributing to the placebo effect, the role of the provider needs to be emphasised also. In most drug research, the treatment itself (the pill or cream) is only one element of the context in which the healing process takes place. In addition to the internal factors which shape response to treatment (optimism and expectancies more generally), there are also important social and environmental factors. For instance, the classic work of Gracely et al \cite{Gracely1985} demonstrated that the effects of the awareness of the provider can have a large impact on the outcome. In this study, half of the dentists were informed that half of the patients would receive placebo. 

In fact, all of them received the real painkiller. However, compared to the group treated by dentists who had not been told that placebo was a possibility, the other patients reported significantly higher pain. Indeed, a systematic review of healthcare interventions \cite{DiBlasi2001} provided evidence that provider characteristics accounted for a large proportion of the observed placebo effects. More recently \cite{Kaptchuk2008}, a three armed randomised control trial of acupuncture demonstrated that healing rates were greatly increased when the provider spent more time with the patient discussing symptoms and treatment (45 minutes as opposed to 15). This would seem to suggest that one of the reasons so many people use alternative treatments is not the efficacy of the particular form of treatment, but rather the chance to discuss their symptoms in detail and for longer period of time, while the average GP time per patient is currently around 5 minutes in the UK and Ireland. 

Another important feature of the context in which healing takes place is the social context, that is the shared beliefs and rituals that make up a culture. For instance, Valium has a powerful resonance in our culture, immortalised in songs by the Rolling Stones are glorified through media et al. Therefore, even when participants have never experienced the drug itself, they bring pre-conceived notions of what it can do, and apply these to their perception of treatment, which alters its efficacy. However, research using the open-hidden paradigm (discussed previously) would seem to suggest that Valium lacks any efficacy when participants are not aware that they are taking it \cite{benedetti2003}. An additional example of this effect can be seen in the prescription of antibiotics for viral infections. Even though doctors know that they will have no effect, they are still administered to patients. It would be extremely interesting to give people placebo antibiotics and assess its impact on viral infections, relative to the efficacy of true antibiotics. My thesis would suggest that real antibiotics should be slightly more effective, given their obvious side-effects, but that this difference in standardized means would be less than 0.1. 

% A final (in my estimation) variable on placebo response would seem to be the effects of environmental factors. There is some evidence that suggests that a view of nature decreases healing times, and that patients in rooms with sunlight recover faster than those in rooms 
% without a direct view of the sun. It can be argued that this is as a result of environmental influences activating particular implicit cognitions relating to health. It is worth noting that the sun has been consistently associated with health in many cultures across the globe, and that people's mood tends to improve when the weather is nice. 

\subsection{Towards an Embodied Conception of Placebo}

Bearing the previous sections in mind, we can now move forward into proposing a new model for placebo, the embodied placebo model. This model, while not rejecting outright the findings of the expectancy theory, aims to enhance it with more recent research. Indeed, this theory is also compatible with that of conditioned placebo, and also with the motivational concordance approach of Hyland et al \cite{Hyland2007}.  
The essential features of the embodied model of placebo are as follows. Placebo effects are those healing effects which arise from the perception of treatment or caring on the part of the health care provider or from the context surrounding the treatment. They are mediated by four different kinds of factors.


\begin{itemize}
\item They are mediated by implicit cognitions operating extremely quickly
\item They are also mediated by awareness of the treatment and cognitive models of its efficacy
\item In addition, these implicit and explicit attitudes are enhanced or degrenated by somatic sensations
\item They are mediated by the communications exchanged between the participant and the provider
\item They are also mediated by the system of communications surrounding both the participant and the provider
\item Finally, they are mediated by somatic feedback from the surrounding environment.
\end{itemize}
 
In an effort to advance research and to conclusively demonstrate either my own percipience or ignorance, I shall argue that my theory makes a number of key predictions. 

\begin{itemize}
\item First, that placebo effects will be correlated with scores on implicit measures
\item Second, that there will be an interaction effect between explicit and implicit attitudes on placebo response
\item Third, that increased interioceptive awareness (or mindfulness) will increase the size of placebo responses
\item Fourth, that the implicit attitudes of the practitioner will exert a significant impact on the placebo response of the patient \footnote{due to researcher constraints, this hypothesis was not tested in this thesis}
\item Fifth, that adding sensory input to a placebo treatment will increase its effectiveness. 
\item Sixth, that the extent of changes in physiological measures in participants will be correlated (as a lagged variable) with the size of the next reported pain rating.
\end{itemize}

However, in order to properly test this model, it needs to be compared to other plausible models. The first of these is the model of Krisch, noted in his 1985 paper. This model claims that expectancies are the major (indeed only) mediating factor between consciousness and placebo responses. Therefore, this model suggests that there is a direct effect of exxpectancies on placebo response, that physiological outcomes should not be predictive of the placebo response and that any effect of optimism and mindfulness will be mediated through expectancies. This model claims that there will be no direct effects of any other explicit or implicit measure on placebo response, but that they will all be mediated by expectancies. 

Another, equally plausible model is that optimism is the driver of the placebo response, and that the effects of expectancies are mediated by levels of optimism. This model would suggest that both implicit and explicit optimism will have direct effects on the placebo response, and that expectancies (implicit and explicit) shall be mediated by levels of optimism. This model makes no predictions about the effects between physiological response variables and placebo response. 

These three models will be examined using a structural equation modelling approach, which should allow for an efficient and accurate test of my theory, even if the population is not particularly representative. 


\section{Qualitative Research Methodology}

Qualitative research typically relates to the analysis of interviews and other texts derived from people. It differs fundamentally from quantitative analysis in that it aims for a deep understanding of particular individuals, while quantitative analysis aims for a broad understanding of the sample as a whole. 

 The biggest problem with qualitative analysis is that it cannot scale to the level of large scale surveys, as it requires significant amounts of researcher time per participant while quantitative surveys have a cost of development in time, but the marginal cost of administering the survey to a new participant is essentially zero (assuming distribution over the internet).


Qualitative analysis was an essential part of this project.  
It gave insight and data into the development of the IAT's used in the final part of the research project.
 The methods used for qualitative analysis here involved  a thematic analysis \cite{braun2006using} of the interviews conducted was carried out to develop themes both for the repertory grid and for the IAT.


The issue of reflexivity is crucial to qualitative research (and also appears in quantitative research, though rarely as openly) \cite{rosenthal1967covert, rosenthal1969interpersonal}.

Reflexivity refers to the impact of the researcher's prior conceptions and approaches have on the course of the interviews \cite{finlay2002outing}.

 This is extremely obvious in the choice of the major questions to be asked in the interviews, but it can occur in subtle ways during the interviews also (for example in the use of language by the interviewer) and in the quality of communication or rapport experienced by the researcher in the course of the interview. Reflexivity is also critical during the analysis, as the researcher must be aware of their own biases and ensure that this affects the analysis as little as possible, or at least report where the problems arose for them.

\subsection{Thematic Analysis}

The thematic analysis's primary purpose was to look for common patterns in the conceptualisation of health, sickness and treatment. As such, it was felt that the best approach would be to develop the codes from the transcipts themselves. 
This is called an inductive approach to coding of the data \cite{haberman1979analysis}.   Following transcription, each interview was coded line by line by the primary researcher, and codes were developed throughout this process.

After all the interviews had been transcribed, the codes were pruned and amalgamated to reduce redundancy, and this process was repeated. This second coding lead to a number of new codes and insights which had been missed the first time, and the text was again coded for a third time following the development of these new codes.

Then, the document was coded a fourth time, but on this run through the aim was to look at higher level patterns that emerged from the text. Following this coding procedure, a process of chunking of codes was carried out. This involved looking at how codes fit together and grouping them under a number of thematic headings. The original texts and recordings were referred back to at this point to ensure that the themes were representative of the original data, and finally the themes were written up to record the results of this exercise.


\subsection{Repertory Grids}

The use of repertory grids in this research was as a bridge between the qualitative analysis carried out and the quantitative side of the research. 

Repertory grids were developed by George Kelly as an aid to therapy \cite{kelly2003psychology} although it has been used in many diverse situations in the ensuing years. 
Repertory grids were developed out of Kelly's theory of cognitive consistency, an active area of research which fell out of favour following the discovery of cognitive dissonance by Festinger in 1947 \cite{greenwald2002}.

The premise of the technique is simple. Firstly, participants are supplied with a list of important people in their life, such as their mother, an older sibling and a teacher whom they liked or disliked. They write down the names they have chosen for each person, and then they compare the people in groups of 3. For each group (or sort), they are asked to describe how two of them are similiar and also how one of them is different in a word or short phrase. These words or phrases can then be analysed both quantitively or qualitatively.

The primary method of quantitative analysis was through factor analysis.

The approach taken in this project was as follows. In one of the surveys carried out on the UCC population (TCQ version 1) participants were asked to rank the most important people in their life who were related to healthcare. 
This data was then sorted and ranked, and a list of the most common people used was compiled into a health related repertory grid. 
This was then administered to a small sample (N=17) to test the instrument. 
 The results of this testing are described in Chapter~\ref{cha:preliminary-research}, in Section~\ref{cha:preliminary-research-3}.

\subsection{Development of IAT}
\label{sec:development-iat}

The plan for the development of the IAT was to use the constructs obtained from the repertory grids to develop useful stimuli for the IAT. 
Unfortunately, as Chapter \ref{cha:devel-imp-meas} describes, this portion of the research did not lead to a successful outcome, for reasons described in that chapter.

Therefore the IAT was developed from both the important figures which arose from the repertory grid, the qualitative interviews, and to match the explicit measure of treatment credibility. The optimism IAT was developed along similar lines to most other Implicit Association tests, in that the survey for this measure was used as a base. 


\section{Quantitative Research Methodology}
\label{sec:quant-rese-meth}
This section  will describe the methods employed for each part of the thesis and provide a rationale for why these methods were used in the thesis.
A mostly quantitative approach was taken for the following reasons. Firstly, the placebo  is a very noisy phenomenon~\cite{Singer2005}, subject to many sources of error and bias (described in Chapter 2 under the heading of the Concept of the Placebo). Secondly, in order to predict the placebo effect, there needs to be some kind of measure, and these are typically metered in numerical terms. 

This thesis consisted of three main parts. Firstly, following a thorough literature review, the major constructs associated with the placebo effect and implicit measures were identified. These constructs were then administered to large samples of the population from which the experimental participants were drawn. This procedure was carried out for two reasons. In the first case, this was so that the population means could be estimated more precisely and thus the experimental sample compared on these measures.  

The second reason was so that more sophisticated models could be developed for person responses (which typically require larger samples than are common to experimental studies) and could then be applied to the experimental sample. This approach marries two of the strengths of psychological research; the latent variable approach common in psychometric research; and  the use of rigorous experimental design to determine relationships between constructs (through Structural Equation Modeling). This thesis aimed to use both of these strengths in combination to gain insight into the causes underlying the response to placebo in healthy volunteers.

The second major part of the thesis was the development of the implicit association tests (IAT's) and the explicit measure of expectancies (treatment credibility questionnaire) used in the experimental portion of the research. 

The third, and final, part of the thesis was the testing of these measures in an experimental setting using a placebo analgesia design examining the response to ischemic pain in healthy volunteers. 

\subsection{General Statistical Approach}


In this section, the statistical techniques  used to answer the primary research questions shall be discussed. Only methodology used throughout the thesis will be described in this section. Therefore, methods of cross-validation will be described, as will the regression models utilised, followed by the treatment of missing data and finally Structural Equation Modeling shall be discussed. The methods employed only within one chapter are discussed in the appropriate chapter. 

\subsection{Problems of Sample Inference}
\label{sec:probl-sample-infer}
\subsubsection{The Problem}

In every statistical approach, the core is the development of inferential tools to reduce our uncertainty about the events under study\cite{gelman2010philosophy}. Given that we typically lack infinite resources, sampling from populations in a randomised manner is used to approximate the quantities of interest~\cite{venables2002modern}.

However, we are rarely interested in the specific sample we have recruited; we tend to want to infer properties of the population  from which they are drawn.  In non technical terms, given a sample and some analyses, we develop a model which we hope will predict the behaviour of future samples (and indeed the population).

This approach toward inference is often operationalised in the creation of a model, whether based on the results of a linear regression or factor analysis. Typically, we aim to maximise the amount of the response variable  in a sample of size $n$ explained given some number of parameters. It is trivial to see that as the number of parameters ($p$) increases, so does the fit --- in the limit, this would involve the fitting of a model with a seperate parameter for each observation. 

Clearly, such a model will violate the principles of parsimony and clarity that we aim for in our science. However, even when $p$ is less than $n$, we still run the risk of overfitting a model to our data. Overfitting is said to have occurred when we model features of the data that are essentially random~\cite{friedman2009elements}. 

% Because factor analysis is lenient towards mis-specified models and tends to model error as well as signal, many psychometric theories have faltered on the rock of replication\cite{fabrigar1999evaluating}. SEM is often used as a panacaea for such problems. However, a Structural Equation Model is only as good as the data and theory behind it, and if the factor analysis models noise, so too will an SEM on the same data set (to a lesser extent, of course). This may account for the poor replicability of psychological theories based on the results of factor analysis and SEM.

\subsubsection{A Solution}

The typical scientific approach to this problem is simple --- replication. Replication, preferably by independent researchers, is supposed to ensure that models eventually tend towards the minimum of parameters for the maximum of explanatory power.

Indeed, many fit indices penalise complex models over simple models. This suffices for some research, but there are cases where such an approach does not prove useful. Replication can also be fraught with difficulties, as it takes time, effort makes the assumption that population quantities are stable over time. Nonetheless, it is the ideal solution. However, given that replication is not incentivised by the scientific community (and may be unethical in some situations), researchers in the field of machine learning have come up with a novel approach which appears to improve predictive accuracy and can also aid in the development of theoretical understanding~\cite{friedman2009elements}.

\subsubsection{Cross-Validation}

The solution proposed by those machine learning researchers is at once simple and elegant, while also extremely practical. The technique is known as cross-validation, and its application routine in commercial and scientific data-mining settings. However, it does not appear to have found much favour within psychology as of yet (with some notable exceptions ~\cite{dawes1979robust}).

The basic premises of the techniques are:
\begin{itemize}
\item All models are wrong;
\item Models are best tested on independent samples;
\item Independent samples are sometimes hard to come by;
\item Therefore, datasets should be split into training and test sets, where the model is developed on the training set, and its accuracy assessed on the test set.
\end{itemize}

This approach seems to improve predictive accuracy by an order of magnitude, especially when applied to large data sets ~\cite{breiman2001statistical}.  
% These tools can greatly aid in this task, if used with caution and due care \cite{friedman2009elements}.-

The principle of training and test sets has since been generalised to $k$-fold cross validation where the dataset is split into $k$ random pieces, and all but one of these are used to estimate a model, while the other is used as a test. This procedure is repeated $k$ times, and the results are averaged to form the best model (for that sample of data, at least). Some authorities argue that this procedure should be repeated at least $k$ more times, to control for the effects of random sampling\cite{friedman2009elements}.

Another variation on the central approach is leave-one-out cross validation, where given a sample of $n$ observations, fit a model on $n-1$ and test on the other, a total of n times. This approach, while taking the technique to its logical extreme is not of particular usefulness to us at this point, as large inter-personal variability between individual participants typically observed in psychological data would tend to reduce its efficacy\cite{friedman2009elements}. However, given that it is the most efficient means of cross-validation for smaller samples, this method was employed in the experimental portion of the research. 

In essence, cross-validation is an extremely valuable technique which has been mostly ignored in psychology. It is the opinion of this researcher  that this technique is useful, and it will be applied consistently to this research.

\subsubsection{Regression Models}
\label{sec:regress-models}

At the heart of typical psychological modelling practice lies the general linear model.This model underlies such familiar techniques as correlation, regression and analysis of variance (ANOVA)\cite{gelman2007data}. These techniques are based on the idea of fitting a straight line (or plane, in the case of multiple predictor variables) to the observed data and using this line to make inferences about the relationships between variables of interest.

The models are typically fitted by a least squares method. Least squares is a criterion which suggests that in order to fit the best line, the average vertical distance between the points should be minimised. Least squares is the heart of many social and physical science modelling techniques, and is formalised in the Gauss-Markov theorems which prove that if the assumptions of the model are met, then in the limit, the least squares approach is the most efficient unbiased estimator\cite{friedman2009elements}.

The assumptions of the general linear model are as follows:
\begin{enumerate}
\item The residuals of the model (the distances between the predicted line and the observed values) should be approximated by the standard normal distribution
\item The variables should have constant variance across their entire range (homoscedasity)
\item The residuals should be independent of the response variable

\item The residuals should be uncorrelated with one another
\end{enumerate}

The general linear model has been elaborated greatly over the last century, and has been applied to the approximation of relationships that do not meet all of the assumptions noted above\cite{gelman2007data}. The introduction of link functions (non linear functions designed to transform the response variable into a form suitable for the model)  led to the development of generalised linear models, which allow the same computational techniques to be used to fit and test models for data which does not fit the requirements of the standard linear model~\cite{mccullagh1989generalized}.

For example, logistic regression is a technique for prediction of binary
 variables using a link function. Poisson regression is used to model data
 which is bounded by zero and positive infinity. A number of quasi methods
 are available for both of these techniques which allow models to be fitted
 to  data which has an excess of zeros (so called zero inflated models)~\cite{gelman2007data,venables2002modern}. In another direction, the
 requirement for the residuals to be uncorrelated has been relaxed to allow for the development of multilevel or mixed models, which allow particular groups residuals to be correlated with one another~\cite{gelman2007data}. 

A number of major issues arise with the use of the general linear model with psychological data. Firstly, the requirement of normal errors can sometimes be difficult to satisfy. This follows from the manner in which the normal distribution appears to behave. When it was originally discovered (by Gauss)~\cite{stigler1986history} it was used to model the combination of many small, independent variables. It tends to work well as an approximation when there are many independent variables affecting the results of an analysis.

However, when psychological tests (such as self report instruments) are developed, the aim is to remove as many of these small influences as possible so that the measure taps one construct with clarity. This will often lead to a non-normal distribution of errors. Non parametric approaches are an alternative to the General Linear Model, but these often lack the power of their parametric alternatives.The central limit theorem assures us that, in the limit, any distribution of means will converge to a normal, and in practice perhaps as little as 100 observations may suffice for a t-test~\cite{venables2002modern}. 

A more serious problem (in terms of the impact on outcomes) is heteroscedasity, where the response variables (or the predictor) do not possess constant variance across their range\cite{gelman2007data}. This can seriously affect the models built as points with less variance will be much more influential than those with a higher variance. The assumption of homosecdasity can be checked by formal statistical tests, but often graphical tests of this assumption are much more revealing, as they can show where the model fails as well as whether or not it fails.

In this research, linear, logistic and mixed models were utilised throughout all of the quantitative research in order to test hypotheses. In deference to common convention, frequentist hypothesis testing was applied to examine the evidence for particular propositions. 

\subsection{Treatment of Missing Data}


Missing values can often cause a problem with large datasets. The
traditional approach has been to delete either pairwise (dropping
all variables that have missing values for a particular analysis)
or listwise (dropping all variables that have any missing values)~\cite{graham2009missing}.
Both of these methods are flawed. The pairwise method can cause issues
with interpretation in that different analyses will be based on different
samples and degrees of freedom. The list wise method is slightly better,
but it does make the assumption that the missing values are missing
completely at random (MCAR) which is often not tenable~\cite{graham2009missing}.

The primary deficiency in the above methods is their granularity. Both methods discard information in a rather crude way. Another approach towards the treatment of missing data is mean imputation, where any missing value is recoded as the mean for the sample. Predictive mean matching is a similiar approach which substitutes the mean for the respective variable containing missing data instead.

The major issue with mean (or median) imputation methods is that they artificially reduce the variance of the data. As more of the sample tends towards missing, this can lead to artificially centred variables which when used in model building, provide inaccurate standard errors and lead to poor inferences.

A more principled approach to missing data was developed by Donald Rubin, a statistician concerned with the problem of missing data in large public datasets such as the census or longitudinal studies\cite{little1987statistical}. The basic idea is quite simple, and has been generalised far beyond its original goal of filling in data in large representative samples.

The method is multiple imputation, and the process is as follows. Firstly, the missing values in the dataset are predicted given the information available in the non-missing values. Some noise is added (typically Gaussian, though bootstrapping from the observed distribution is often a better approach)~\cite{gelman2007data} in order to prevent the computer from predicting the same values again, and these new values are then used as the starting predictors for the next imputation. This process is done a number of times (3--15, depending on the proportion of missing data)~\cite{graham2009missing,little1987statistical} and then the the analysis is run on each of these datasets seperately, and the estimates are combined at the end of this process. The major advantage of this method is by looking at the variance of the estimated parameters, we can approximate the uncertainty which surrounds our method of imputation. In addition, the repeated draws ensure that chance features of the data do not lead to erronuous conclusions, as could easily be the case if a single imputation method were used.

Throughout this research, multiple imputation was used where the amount of missing data was substantial. Typically, between five and fifteen simulated data sets were created, and models run seperately across all imputed datasets, with inferences combined at the end. The multiple imputations were then analysed and tested to ensure that the simulated data was an accurate reflection of the non-missing data, in line with best practice~\cite{abayomi2008diagnostics}.

\subsubsection{Structural Equation Modelling}
\label{sec:struct-equat-model}

Structural equation modelling is regarded by many as an adjunct technique for evaluating the results of particular factor solutions~\cite{fabrigar1999evaluating}. However, it is actually a far more general techniques to test the relationships between both manifest and latent variables, and even to establish causality in some cases~\cite{pearl1998graphs}. The factor analytic procedure is full of interpretative procedures where no principled choice can be made, and structural equation modelling (hereafter SEM) is an attempt to compensate for some of these deficiences.

SEM was developed by Joreskog in the 1970's~\cite{joreskog1978structural}. It provides a means of testing hypothesised relationships between latent and manifest variables. In practice, the result of a factor analysis is regarded as a measurement model of the data.

This is combined with a structural model (which describes how the latent variables relate to one another and to the manifest variables). The two of these models are then used to construct a covariance matrix which is then compared with the observed data, and a number of indices of model misfit are calculated. Foremost among these is the $\chi^2$, which estimates the degree of model misfit. The desired result is a p-value of greater than 0.05, which shows that the two matrices are not significantly different.

However, the $\chi^2$ is extremely sensitive to sample size, and tends to be rejected in almost every case~\cite{henson2006use}, given that the sample sizes needed for accurate factor analysis and structural equation modelling tend to be quite large. As a result of this, many other fit indices have been developed. Foremost amongst these are the Non Normed Fit Index (NNFI), which is also known as the Tucker Lewis Index~\cite{bentler1990comparative}, the Root Mean Square Error of Approximation (RMSEA)~\cite{rigdon1996cfi} and the Bayesian Information Criterion (BIC)~\cite{schwarz1978estimating} and the Aikike Information Criterion (AIC)~\cite{akaike1974new}. These all have different strengths and weaknesses and are typically used in a complementary way. All of these fit indices incorporate explicit penalisation, which aids in avoiding overly-complex models. The $\chi^2$ it also has some penalisation (based on degrees of freedom) but it is typically not strong enough to prevent over-fitting. Some authors argue that this focus on other fit measures apart from $\chi^2$ is a way to avoid determining better models, but such a view is controversial in the field at present~\cite{barrett2007structural}.

There are also some requirements for SEM models which are typically not met for much psychological and psychometric data. These are as follows:
\begin{itemize}
\item The distribution must be approximated well by the first and second order moments.
\item Sample size is required to be large (>300)
\item The covariance matrix must be strictly positive definite across the entire parameter space.
\end{itemize}

Of these, the multivariate normality assumption  (assumption 1 above) is often difficult to meet in practice. However, there are a number of distribution free methods in SEM, of which the most common is a Weighted Least Squares approach. This proceeds similarly to a Weighted Least Squares approach in linear regression, where points are assigned weights depending on how closely they meet the assumptions of the model. Sample size, by contrast, is typically easy to increase (at least for non-clinical populations).

Identification of the model is one issue in practice, though as Joreskog notes, this can often be achieved by fixing a number of parameters to 0 or 1 (the inter-factor variances are often scaled in this fashion)~\cite{joreskog1978structural}.

Another, more theoretical issue is that no set of data is uniquely determined by an SEM model. This is known as the problem of rotation in factor analysis~\cite{maccallum2000applications}. Given a covariance matrix $W$, and a set of data $D$, there are many solutions which provide the same fit indices of the model to the data. This can lead to a similiar problem as occurs to factor analysis, where the researcher must make a choice between models which are quantitatively identical. One approach for resolving this problem was discussed above, in Section~\ref{sec:probl-sample-infer}.

In this thesis, SEM was applied extensively to test the theorised relationships between variables, and the experimental chapter includes a number of tests of theoretically derived models (c.f. Chapter~\ref{cha:primary-research}). 



% \section{Preliminary Research}

%  Sampling from a population can be difficult, especially as the requirement of randomness needs to be satisfied. However, even if the surveys and measures are sent to a random selection of participants, who responds will almost certainly not be random, as people may only respond to surveys which are salient to them, and ignore the others. This is especially true in a University environment where many surveys are sent out to either random samples or the entire student population regularly. Some of the issues and concerns around sampling for each of the different pieces of research are discussed below.





%%% mode: latex
%%% TeX-master: "PlaceboMeasurementByMultipleMethods"
%%% End:

