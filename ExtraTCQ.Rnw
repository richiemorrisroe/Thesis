\section{Study One}

\subsection{Materials and Methods}

\subsubsection{Participants}

All participants in Study 1 were students at the University of the researchers. 299 began the survey, and 281 completed the analysis in full. These 281 participants are the those on whom the analyses reported here were based. Ages, Gender and other demographic variables about the participants can be found in the Results section, under the heading of Descriptive Statistics. 

\subsubsection{Measures}

The Treatment Credibility Questionnaire was adapted from the Devilly and Borkovec Credibility/Expectancy Questionnaire. This questionnaire consists of six questions, asking about the cognitive and affective responses to the therapy. Given that this research project concerns the use of placebo analgesia, the questionnaires were modified to make them refer to procedures for the relief of pain.
The general format is as follows: 
\begin{quotation}
You have been suffering pain for a number of weeks, you go to the doctor and he suggests that you try X for this pain. Answer the following questions below.   
\end{quotation}

In this case, X represents a pain killing treatment. In order, the ones utilised in this research were Pills, Creams, Injections and Acupuncture. 
There were six questions under each method, giving the scale 24 questions in all. Following the analysis of the results of Study 1, the instrument was modified to include six questions each on Homeopathy and Reiki, another two methods within the field of complementary and alternative medicine.  


 

The questions were as follows:


\begin{enumerate}
	\item How logical does the therapy offered to you seem?
	\item How successful do you think this treatment will be in reducing your symptoms?
 	\item How confident would you be in recommending this treatment to a friend2
	\item How much improvement in your symptoms do you think will occur?
	\item How much do you really \textit{feel} that therapy will help you to reduce your symptoms?
	\item How much improvement in your symptoms do you really \textit{feel} will occur?
\end{enumerate}

The CEQ has had alphas of between 0.75 and 0.86 in various research, and test-retest reliabilities average at about 0.75 \cite{devilly2000psychometric}. 

\subsubsection{Data Collection}

Data were collected online through the use of an online data collection tool. The email request for completion was sent through the moderator of the All Students list to a total of 4551 students. By the date alloted for collection of responses, 299 had been returned, giving a response rate of 6.3\%, which is extremely low. 

The following demographic variables were also assessed: Age, College of Study, Gender, and whether the respondent was an undergraduate or a postgraduate. 

\subsubsection{Data Analysis}

As this was a first draft of the survey, representativeness was not rated as important as other factors. The priority here was to assess the reliability and factor structure of the of instrument, to allow further validation in clinical and non-clinical groups over time.  All data analysis was conducted using R 2.11.0, an open source data analysis environment based on the commercial S Plus language\cite{RDevelopmentCoreTeam2010}. The pysch package was used for all factor and reliability analyses \cite{Revelle2010} while the eRm package was used for the IRT analyses and plots \cite{Mair2010} and the xtable package \cite{Dahl2009} to export R objects for LaTeX  along with the Sweave package to allow R code to processed through LaTeX editors, enabling reproducible research \cite{Leisch2002}. Structural Equation Modelling was carried out using the OpenMx package \cite{Bokerinpress}. All code and data are available from the first author upon request. 

Factor Analysis was carried out using a principal axis method, as normality could not be assumed.In this piece of research, Exploratory Factor Analysis was used, as the researcher had no prior hypotheses on the nature and structure of the underlying latent variables. 
Many researchers recommend utilising a number of different methods of data reduction, as the evidence suggests that a factor structure which remains invariant after multiple different reductions is the most likely solution that can be fitted to the data\cite{costello2005best,henson2006use}. This was the approach taken in this research report. Other research has shown that parallel analysis and the Minimum Average Partial criterion, along with the scree plot are two the most effective means of assessing the number of factors to retain, and both of these criteria were used in this research. Kruskal-Wallis tests were used for assessment of differences between groups, as normality was not assumed (and indeed was not found). 


The College of study of the respondents was also assessed, and the results are shown in Table \ref{tab:tcq1college} below. 

<<gendersummary, echo=FALSE, results=hide>>=
sum.gen<-with(tcq1, summary(Gender))
sum.gen <- as.data.frame(sum.gen)
names(sum.gen) <- "Gender Breakdown"
rownames(sum.gen)[1] <- "No Gender Supplied"
sum.gen.xtab<-xtable(sum.gen, caption="Gender of Participants in Study One", label="tab:tcq1gender")
print(sum.gen.xtab)
@ 

The next demographic variable we will examine is the breakdown between undergraduates and postgraduates in the sample. The results can be seen in Table 3 below. 
<<upgsummary, echo=FALSE, results=tex>>=
sum.ugpg<-with(tcq1, summary(UGPG))
sum.ugpg <- as.data.frame(sum.ugpg)
names(sum.ugpg) <- "Proportion of Under and Post Graduates in the Sample"
xtab.ugpg<-xtable(sum.ugpg, caption="Distribution of Undergraduates and Postgraduate Respondents, TCQ 1", label="tab:tcq1ugpg")
print(xtab.ugpg)
@ 

As we can see from table \ref{tab:tcq1ugpg}, approximately 16\% of the sample are postgraduates, which fits reasonably well with the figures from the population. 

The next demographic variable examined is that of year of study, and the results can be seen in Table \ref{tab:tcq1year} below.

<<agesummary, echo=FALSE, results=hide, eval=FALSE>>=
sum.age<-with(tcq1, summary(Age)) 
sum.age.mat<-as.data.frame(as.matrix(sum.age))
names(sum.age.mat) <- "Age"
xtab.age<-xtable(sum.age.mat, label="tab:tcq1age", caption="Age Distribution of Participants in Study One")
print(xtab.age)
@ 

<<tcqcollege, echo=FALSE, results=tex>>=
sum.coll<-with(tcq1, summary(College)) 
names(sum.coll)[1] <- "No College Supplied"
sum.coll <- as.data.frame(sum.coll)
names(sum.coll) <- "College Breakdown"
xtab.coll<-xtable(sum.coll, label="tab:tcq1college", caption="College of Respondents, Study One")
print(xtab.coll)
@ 

As we can see from Table \ref{tab:tcq1college}, again the breakdown roughly follows the distribution of students in the population. However, there are a few more Medicine and Health students than one would expect, presumably because this survey was somewhat more salient to them, given their field. 

<<yearsummary, echo=FALSE, results=tex>>=
sum.year<-with(tcq1, summary(as.factor(Year)))
mat.year<-as.data.frame(sum.year)
names(mat.year) <- "Year of Study"
xtab.year<-xtable(mat.year, caption="Year of Study, TCQ 1",label="tab:tcq1year")
print(xtab.year)
@ 

As one can see from Table \ref{tab:tcq1year} , the largest number of respondents came from first year, which argues against the representativeness of the sample. However, given that both first year undergraduates and first year postgraduates could have used this response, it may not be that much of a threat to representativeness. 

<<reltcq, echo=FALSE, results=hide>>=
rel.xtab<-xtable(rel.tcq[["total"]],caption="Reliability Statistics for TCQ 1", label="tab:reltcq1short") 
print(rel.xtab)
@ 

<<faparallel, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
sink("tmp.txt")
plot(fa.parallel(na.omit(tcqall)))
## VSS(na.omit(tcqall))
sink(NULL)
@ 

The scree plot seems to suggest that four factors should be retained, but the MAP criterion  suggests that the six factor solution is more appropriate.
As can be seen, the red lines (representing the random values) cut off the blue lines of the actual data somewhere at 4 factors, and the numerical output claims that a four factor solution is most optimal. 
Therefore, 4 factors were retained. The theoretical rationale for accepting this analysis is outlined below. 

Below, in Table \ref{tab:tcq1fact5} the five factor solution is examined.

<<tcqfact5, echo=FALSE, results=tex>>=
tcq.fact.5 <-fa(na.omit(tcqall), 5, rotate='oblimin', fm="pa")
print(FactorXtab(tcq.fact.5, names=c("Acu", "Cream", "Inj", "Pill", "Fact5" ), label="tab:tcq1fact5",caption="Five Factor Solution, TCQ 1 Promax rotation"))
@ 
<<tcq5cor, echo=FALSE, results=tex>>=
print(FactorCor(tcq.fact.5, label="tab:tcq1fact5cor", caption="Five Factor Solution TCQ1 Correlations"))
@ 



Although in Table \ref{tab:tcq1fact5} the oblimin solution is shown, simplimax, varimax and promax rotations were attempted on the data specifying five factors. In no case did any of the items load highest on this factor, so this factor can be regarded as not adding anything to the model. 


<<tcq5sem, echo=FALSE, results=hide, cache=TRUE>>=
Pill <- "Pill"
Cream <- "Cream"
Inj <- "Inj"
Acu <- "Acu"
creamitems.cols <- paste(Cream, 1:6, sep="")
pillitems.cols <- paste(Pill, 1:6, sep="")
Injitems.cols <- paste(Inj, 1:6, sep="")
Acuitems.cols <- paste(Acu, 1:6, sep="")
manifests <- c(pillitems.cols, creamitems.cols, Injitems.cols, Acuitems.cols)
latents <- c("Pills", "Creams", "Injections", "Acupuncture", "Fifth")
pills <- paste(Pill, 1:6, sep="")
creams <- paste(Cream, 1:6, sep="")
inj <- paste(Inj, 1:6, sep="")
Acu <- paste(Acu, 1:6, sep="")
fifth <- c("Pill4", "Pill5", "Pill6", "Cream5", "Cream6", "Inj6")
Tcq5model <- mxModel(name="TCQ5", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Pills", to=pills), 
                      mxPath(from="Creams", to=creams),
                      mxPath(from="Injections", to=inj),
                      mxPath(from="Acupuncture", to=Acu),
                     mxPath(from="Fifth", to=fifth),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.5),
                      mxData(observed=cov(na.omit(tcqall)), type="cov", numObs=264))
tcq5fit <- mxRun(Tcq5model)
tcq5summ <- summary(tcq5fit)
@ 

<<tcqscales, echo=FALSE, results=hide>>=
print(xtable(tcq.scales, caption="Automatic Item Selection Procedure for TCQ 1", label="tab:tcq1aisp"))
convtcq <- as.data.frame(cbind(Pillall, Creamall, Injall))
tcqalt <- Acuall
@ 

<<tcqconvitemord, echo=FALSE, results=hide>>=
print(xtable(tcqconv.item.ord[["violations"]], caption="Item Ordering Assumption Test for TCQ 1 Conventional Scale", label="tab:tcq1itemordconv"), scalebox=0.8)
convtcq <- convtcq[,-2]
@ 

From Table \ref{tab:tcq1itemordconv} 

<<convmonotonicity, echo=FALSE, results=tex>>=
print(xtable(summary(tcqconv.monotonicity), caption="Test of Monotonicity Assumption, TCQ 1 Conventional Scale", label="tab:tcq1convmono"), scalebox=0.8)
@ 

<<tcqaltitemord, echo=FALSE, results=tex>>=
print(xtable(tcqalt.item.ord[["violations"]], caption="Test of Item Ordering Assumptions for TCQ1 Alternative Scale", label="tab:tcq1altitemord"))

@ 

Table \ref{tab:tcq1altitemord} demonstrates that there were no violations of the item ordering assumptions for the acupuncture items.

Next, the assumption of monotonicity was examined for the acupcunture items, and the results are shown in Table \ref{tab:tcq1altmono}. The results indicate that there are no violations of monotonicity for these items. 

<<altmonotonicity, echo=FALSE, results=tex>>=
print(xtable(summary(tcqalt.monotonicity), caption="Test of Monotonicity Assumption for TCQ1 Alternative Scale", label="tab:tcq1altmono"))
@ 

<<tcqconvraschprint, echo=FALSE, results=tex>>=
print(xtable(tcqcoef, label="tab:tcq1convpcmrasch", caption="Coefficients for TCQ1 Partial Credit Model (Rasch)"))
@ 
Even a cursory glance at Table \ref{tab:tcq1convpcmrasch} demonstrates that there are serious problems with this model, as the estimates are not monotonically increasing for each higher category. The  next model to be examined is a one parameter model, where the discrimination parameter is estimated from the data rather than being fixed at one. 

<<tcqconvpcm1pl, echo=FALSE, results=hide, cache=TRUE>>=
tcqconv.pcm.1pl <- gpcm(convtcq, constraint="1PL")
tcqconv1pl.coef <- coef(tcqconv.pcm.1pl)

tcqconv.pcm.fscores.1pl <- factor.scores(tcqconv.pcm.1pl)
tcqconv.pcm.absest.1pl <- getIRTestimates(tcqconv.pcm.fscores.1pl)
@ 
<<tcqconv1plprint, echo=FALSE, results=tex>>=
print(xtable(tcqconv1pl.coef, label="tab:tcqconvpcm1pl", caption="Coefficients for TCQ 1 Partial Credit Model, One Parameter"))
@ 
From Table \ref{tab:tcqconvpcm1pl} it can be seen that the model still has a number of problems with item ordering, especially in the Pill and Injection sections of the questionnaire. Indeed, it appears to be Category 3 which is causing the problems, which may suggest that participants were using this category as a base rather than actually considering the alternatives in a consistent manner. Next, a 2 parameter model will be fitted to assess if allowing individual discrimination parameters will prove to be a better approach. 

<<tcqconvpcm2pl, echo=FALSE, results=tex, cache=TRUE>>=
tcqconv.pcm.gpcm <- gpcm(convtcq, constraint="gpcm")
tcqconv.gpcm.coef <- coef(tcqconv.pcm.gpcm)

tcqconv.pcm.fscores.gpcm <- factor.scores(tcqconv.pcm.gpcm)
tcqconv.pcm.absest.gpcm <- getIRTestimates(tcqconv.pcm.fscores.gpcm)
@ 

<<tcqconv2plprint, echo=FALSE, results=tex>>=
print(xtable(tcqconv.gpcm.coef, caption="Coefficients for TCQ1 Conventional Two Parameter Partial Credit Model", label="tab:tcq1convpcm2pl"))
@ 


Unfortunately, the approach of attempting to allow for a more flexible modelling approach in order to garner more coherent parameters for the model appears to have failed, in that Table \ref{tab:tcq1convpcm2pl} shows that the issues around item ordering have not been resolved by allowing for a two parameter model. 

<<tcqaltpcm, echo=FALSE, results=tex, cache=TRUE>>=
tcqalt.pcm.rasch <- gpcm(tcqalt, constraint="rasch")
tcqaltcoef <- coef(tcqalt.pcm.rasch)

tcqalt.pcm.fscores.rasch <- factor.scores(tcqalt.pcm.rasch)
tcqalt.pcm.absest <- getIRTestimates(tcqalt.pcm.fscores.rasch)
@ 
\begin{figure}
	\centering
<<tcq2aparallel, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
sink("tmp.txt")
tcq2a.para <- fa.parallel(na.omit(tcqall2a))
tcq2a.vss <- VSS(na.omit(tcqall2a))
sink(NULL)
@ 
	\caption{Parallel Analysis and Scree Plot TCQ 2}
	\label{fig:tcq2aparallel}
\end{figure}

The results of factor analysis on the Treatment credibility Questionnaire can be seen in Figure \ref{fig:tcq2aparallel}, below. 

\subsubsection{Beliefs About Medicine Questionnaire}
\label{sec:beli-about-medic}



Next, the beliefs about medicine questionnaire will be examined in terms of factor analysis. 
This questionnaire was developed for use with chronic pain patients. It appears to be the standard in the field, however, it was only analysed using a principal components method and Varimax rotation, neither of which are appropriate for an instrument of this kind. 
The first step is to examine the criteria for the retention of factors. As above, parallel analysis and the minimum average partial criterion were used for this purpose. 

<<bamparallel, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
sink("tmp.txt")
bam.para <- fa.parallel(na.omit(bamall2a))
bam.vss <- VSS(na.omit(bamall2a))
sink(NULL)
@ 

The parallel analysis suggests that there are four factors, while the MAP criterion suggests that only one is useful. In line with previous practice, all four factor solutions will be examined for interpretability and fit indices before being tested on another of the data splits. 

%Insert reliability analyses here

\paragraph{One Factor Solution}
\label{sec:one-factor-solution}


<<bam2afact1, echo=FALSE, results=tex>>=
bam2a.fact1 <- fa(na.omit(bamall2a), 1, fm="pa")
print(FactorXtab(bam2a.fact1, names=c("BAM1"), label="tab:bam2afact1", caption="One Factor Solution, Beliefs About Medicine Questionnaire, Sample Two"))
@ 

As can be seen from Table \ref{tab:bam2afact1}, the one factor solution is extremely poor. Only 11 of the 18 items have loadings above 0.3, which is typically used as a cutoff for the assigning of items to the factor. In addition, the communalities for all of the items are extremely low, all below 0.5 which indicates that the common variance of this solution is quite low. This one factor solution only explains 17\% of the variance and so is somewhat inadequate in all senses. 

\paragraph{Two Factor Solution}
\label{sec:two-factor-solution}



<<bam2afact2, echo=FALSE, results=tex>>=
bam2a.fact2 <- fa(na.omit(bamall2a), 2, rotate="oblimin", fm="pa")
print(FactorXtab(bam2a.fact2, names=c("BAM1", "BAM2"), label="tab:bam2afact2"))
@ 
Again, the communalities in this factor solution are very low (see Table \ref{tab:bam2afact2}, and the amount of variance explained is 23\%, which is again quite poor. In addition, six items have no loadings above 0.3 on either of the factors. 

PA1: "BAM1",  "BAM6",  "BAM7",  "BAM9",  "BAM12", "BAM13", "BAM14", "BAM17" "BAM18".  All of these items appear to relate to the avoidance of medicines (the items which are positive towards medicines have negative loadings), so this factor can be termed Medicine Avoidance. 

PA2: "BAM2",  "BAM7",  "BAM10", "BAM11". These items all appear to relate to natural remedies in constrast to medicines and so this factor can be termed Natural Remedies.

Although there appears to be an interpretable factor structure emerging from this solution, it should be noted that the large number of items not loading on any solution and the low proportion of variance explained caution against over-interpretation of this solution. 


<<bam2afact2cor, echo=FALSE, results=tex>>=
print(FactorCor(bam2a.fact2,label="tab:bam2afact2cor"))
@ 

As can be seen from Table \ref{tab:bam2afact2cor}, the two factors are moderately correlated, supporting the decision to use oblimin rotation. 


\paragraph{Three Factor Solution}
\label{sec:three-fact-solut}



<<bam2afact3, echo=FALSE, results=tex>>=
bam2a.fact3 <- fa(na.omit(bamall2a),  3, rotate="oblimin", fm="pa")
print(FactorXtab(bam2a.fact3, names=c("BAM1", "BAM2", "BAM3"), label="bam2afact3"))
@ 
The three factor solution also has very low communalities, with almost all of them (16) below 0.5. This solution explained 29\% of the variance. The factors are described below. 

PA1: "BAM6",  "BAM7",  "BAM8",  "BAM9",  "BAM12", "BAM13", "BAM14", "BAM17", "BAM18". This factor again relates to less use of medicines, and as above can be termed medicine avoidance. 

PA3: "BAM1",  "BAM3",  "BAM4",  "BAM10". All of these items appear to relate to cutting down or taking a break from medicine (with the exception of Question 1 which has a negative loading). Therefore, this factor will be termed safer use of medicines. 

PA2: "BAM1",  "BAM2",  "BAM7",  "BAM10", "BAM11". These items relate to the  responsible use of medicines, and this is what the factor will be termed. 



<<bam2afact3cor, echo=FALSE, results=tex>>=
print(FactorCor(bam2a.fact3,label="tab:bam2afact3cor"))
@ 

Again, Table \ref{tab:bam2afact3cor} shows that the factors are somewhat correlated, although the correlations of factor 3 with the other factors are quite small. 


<<bam2afact4, echo=FALSE, results=tex>>=
bam2a.fact4 <- fa(na.omit(bamall2a), 4, rotate="oblimin", fm="pa")
print(FactorXtab(bam2a.fact4, names=c("BAM1", "BAM2", "BAM3", "BAM4"), label="tab:bam2afact4"))
@ 

The four factor solution (shown in Table \ref{tab:bam2afact4} explained 33\% of the variance, but again only 3 of the 18 items had communalities which were greater than 0.5, indicating that there is a large amount of unexplained variance in this item set. 

PA1: "BAM6",  "BAM7",  "BAM8",  "BAM9",  "BAM12", "BAM13", "BAM14", "BAM17", "BAM18". Again, this factor has emerged from the rotations, and again it can be termed medicine avoidance. 

PA3: "BAM1",  "BAM3",  "BAM4",  "BAM10". All of these items appear to relate to the effectiveness of medicines, and this factor can then be termed Medicine effectiveness. 

PA2: "BAM1",  "BAM2",  "BAM7",  "BAM10", "BAM11", "BAM16", "BAM18". These items all appear to relate to differences between different forms of medicine, and so this factor will be termed Differences Between Medicines.

PA4: "BAM5". This factor is almost certainly spurious, given that it only has one item on it. This item relates to regular taking of medicines, and so it can be termed Regular Taking of Medicines. 


<<bam2afact4cor, echo=FALSE, results=tex>>=
print(FactorCor(bam2a.fact4,label="tab:bam2afact4cor"))
@ 

As before, Table \ref{tab:bam2afact4cor} shows large correlations between factors 1 and 2, but quite small correlations between factors 3 and 4. 

@ 

\begin{figure}
	\centering
<<tcq2aparallel, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
sink("tmp.txt")
tcq2b.para <- fa.parallel(na.omit(tcqall2b))
tcq2b.vss <- VSS(na.omit(tcqall2b))
sink(NULL)
@ 
	\caption{Parallel Analysis and Scree Plot TCQ 2 (Split B)}
	\label{fig:tcq2bparallel}
\end{figure}

Below can be seen the correlations between factors, in  Table\ref{tab:tcq2bfactorcor5}. 

<<tcq2bfactorcor5, echo=FALSE, results=tex>>=
print(FactorCor(tcq2b.fact.5,label="tab:tcq2bfactorcor5"))
@ 

\subsubsection{Beliefs About Medicine Questionnaire, Split B}
\label{sec:beli-about-medic}



Next, the beliefs about medicine questionnaire will be examined in terms of factor analysis. 
The first step is to examine the criteria for the retention of factors. As above, parallel analysis and the minimum average partial criterion were used for this purpose. 
\begin{figure}
<<bamparallel, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
sink("tmp.txt")
bam.para <- fa.parallel(na.omit(bamall2b))
bam.vss <- VSS(na.omit(bamall2b))
sink(NULL)
@   
  \caption{Parallel Analysis and VSS Criteria for Beliefs About Medicine Scale, Split B}
  \label{fig:bam2bparallel}
\end{figure}


The parallel analysis suggests that there are five factors, while the MAP criterion suggests that only one is useful. In line with previous practice, all five factor solutions will be examined for interpretability and fit indices before being tested on another of the data splits. 

\paragraph{One Factor Solution}
\label{sec:one-factor-solution}



<<bam2bfact1, echo=FALSE, results=tex>>=
bam2b.fact1 <- fa(na.omit(bamall2b), 1, fm="pa")
print(FactorXtab(bam2b.fact1, names=c("BAM1"), label="tab:bam2bfact1", caption="One factor Solution, Beliefs About Medicine Questionnaire, Split 2B"))
@ 

As can be seen from Table \ref{tab:bam2bfact1}, the one factor solution is extremely poor. That being said, it performs somewhat better than did the one factor solution on Split A. The loadings are higher across the board, but the communalities are still extremely low.It does explain 22\% of the variance, which is again higher than Split A.  

\paragraph{Two Factor Solution}
\label{sec:two-factor-solution}



<<bam2bfact2, echo=FALSE, results=tex>>=
bam2b.fact2 <- fa(na.omit(bamall2b), 2, rotate="oblimin", fm="pa")
print(FactorXtab(bam2b.fact2, names=c("BAM1", "BAM2"), label="tab:bam2bfact2", caption="Two factor Solution, Beliefs About Medicine Questionnaire, TCQ2, Split B"))
@ 
The results of the two factor solution are shown in Table \ref{tab:bam2bfact2}. Again, the communalities in this factor solution are very low, and the amount of variance explained is 30\%, which is again quite poor. In addition, two items have no loadings above 0.3 on either of the factors. It is however, a much better fit than the two factor solution was on Split A. 

PA1: "BAM3",  "BAM4",  "BAM6",  "BAM7",  "BAM8",  "BAM9",  "BAM10", "BAM11", "BAM12", "BAM13", "BAM14", "BAM17", "BAM18". This factor, which consists of most of the scale, can be termed Medicine Avoidance.

PA2: "BAM1",  "BAM2",  "BAM11", "BAM16", "BAM18". These items relate to the responsible use of medicines, and thus this factor gets that name. 


<<bam2bfact2cor, echo=FALSE, results=tex>>=
print(FactorCor(bam2b.fact2,label="tab:bam2bfact2cor", caption="Factor Correlations for Two Factor Solution, Beliefs About Medicine Questionnaire, Split B"))
@ 

As can be seen from Table \ref{tab:bam2bfact2cor}, the two factors are almost entirely uncorrelated, which is quite different from what is shown in Table \ref{tab:bam2afact2cor}. 

\paragraph{Three Factor Solution}
\label{sec:three-fact-solut}



<<bam2bfact3, echo=FALSE, results=tex>>=
bam2b.fact3 <- fa(na.omit(bamall2b), 3, rotate="oblimin", fm="pa")
print(FactorXtab(bam2b.fact3, names=c("BAM1", "BAM2", "BAM3"), label="tab:bam2bfact3", caption="Three factor solution, Beliefs About Medicine Questionnaire, TCQ2, Split B"))
@ 


The three factor  solution (shown in Table \ref{tab:bam2bfact3} explained 34\% of the variance in the data. The factors broke down as follows:

PA1: "BAM3",  "BAM4",  "BAM6",  "BAM7",  "BAM8",  "BAM9",  "BAM10", "BAM11", "BAM13", "BAM18". This factor was apparent in the two factor solution earlier, and again can be termed Medicine Avoidance. 

PA3: "BAM13", "BAM14", "BAM17". This factor can perhaps best be termed Medicine Trust. 

PA2: "BAM1",  "BAM2",  "BAM11", "BAM16", "BAM18". Again, this factor can best be termed responsible use of medicines. 


<<bam2bfact3cor, echo=FALSE, results=tex>>=
print(FactorCor(bam2b.fact3,label="tab:bam2bfact3cor", caption="Factor Correlations, Three Factor Solution, Beliefs About Medicine Questionnaire, TCQ2, Split B"))
@ 

Again, Table \ref{tab:bam2bfact3cor} shows that two of the factors are somewhat correlated, but the third is not.

\paragraph{Four Factor Solution}
\label{sec:four-factor-solution}



<<bam2bfact4, echo=FALSE, results=tex>>=
bam2b.fact4 <- fa(na.omit(bamall2b), 4, rotate="oblimin", fm="pa")
print(FactorXtab(bam2b.fact4, names=c("BAM1", "BAM2", "BAM3", "BAM4"), label="tab:bam2bfact4", caption="Four Factor Solution, Beliefs About Medicine Questionnaire, TCQ 2, Split B"))
@ 

The four factor structure is shown in Table \ref{tab:bam2bfact4}. 


PA3: "BAM12", "BAM13", "BAM14", "BAM17". These items almost all relate to doctors and medicine, and so this factor is termed Doctors and Medicine. 

PA4: "BAM3",  "BAM4",  "BAM6",  "BAM7",  "BAM10", "BAM11", "BAM15". These items have clustered together in almost all the solutions, and again are termed  Avoidance of Medicines.

PA2: "BAM1",  "BAM2",  "BAM5",  "BAM16", "BAM18". Again, these items have tended to cluster together, and can best be termed as Responsible Use of Medicines. 

PA1: "BAM6",  "BAM8",  "BAM9",  "BAM18". These items all relate to safety or danger of medicines, and thus this factor will be termed Medicine Safety.



<<bam2bfact4cor, echo=FALSE, results=tex>>=
print(FactorCor(bam2b.fact4,label="tab:bam2bfact4cor", caption="Factor Correlations, Beliefs About Medicine Questionnaire Four Factor Solution, TCQ 2, Split B"))
@ 

As before, Table \ref{tab:bam2afact4cor} shows large correlations between factors all of the factors save 3, which appears to be relatively uncorrelated with all of the other factors. 

\paragraph{Five Factor Solution}
\label{sec:five-factor-solution}



<<bam2bfact5, echo=FALSE, results=tex>>=
bam2b.fact5 <- fa(na.omit(bamall2b), 5, rotate="oblimin", fm="pa")
print(FactorXtab(bam2b.fact5, names=c("BAM1", "BAM2", "BAM3", "BAM4", "BAM5"), label="tab:bam2bfact5", caption="Five Factor Solution, Beliefs About Medicine Questionnaire, TCQ 2, Split B"))
@ 

Table \ref{tab:bam2bfact5} shows the five factor solution for the Beliefs About Medicine Questionnaire. 

PA3: "BAM13", "BAM14", "BAM17". Again, these items can best be subsumed as a factor called Doctors and Medicines. 

PA4: "BAM3",  "BAM4",  "BAM6",  "BAM7",  "BAM10", "BAM11", "BAM15". Again, this factor can best be termed Medicine Avoidance. 

PA2:"BAM2", "BAM5". These items relate to the best way in which to take medicines, and can thus be termed Effective Medicine Usage.

PA1: "BAM6",  "BAM11", "BAM18". These items all relate to the safety of medicines and thus this factor can be termed Safety and Medicines. 

PA5: "BAM8",  "BAM9",  "BAM15". These items relate to the dangers associated with medicines, and thus the factor can best be termed Danger and Medicines. 

<<bam2bfact5cor, echo=FALSE, results=tex>>=
print(FactorCor(bam2b.fact5,label="tab:bam2bfact5cor", caption="Factor Correlations, Beliefs About Medicine Five Factor Solution, TCQ 2, Split B"))
@ 

As can be seen from Table \ref{tab:bam2bfact5cor}, all of the factors are moderately correlated with one another. 


\begin{figure}
	\centering
<<tcq2cparallel, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
sink("tmp.txt")
tcq2c.para <- fa.parallel(na.omit(tcqall2c))
tcq2c.vss <- VSS(na.omit(tcqall2c))
sink(NULL)
@ 
	\caption{Parallel Analysis and Scree Plot TCQ 2 (Split C)}
	\label{fig:tcq2cparallel}
\end{figure}

Figure \ref{fig:tcq2cparallel} shows the results of parallel analysis on Split C for the Treatment Credibility Questionnaire. 

The below were the results of a varimax rotation on Split C. 
% PA2:"Pill1"  "Pill2"  "Pill3"  "Pill4"  "Pill5"  "Pill6"  "Cream1" "Cream2" "Cream3" "Cream4" "Cream5" "Cream6" "Inj1"   "Inj2"   "Inj3"   "Inj4"   "Inj5"   "Inj6". This factor consists of extremely high loadings on the Pill and Injection items, and moderate ($0.3-0.4$) loadings on the Cream items. It can therefore best be referred to as the Conventional treatments factors.

% PA1: "Hom1" "Hom2" "Hom3" "Hom4" "Hom5" "Hom6" "Rei1" "Rei2" "Rei3" "Rei4" "Rei5" "Rei6". This factor appears to have small loadings on all of the alternative items, pointing towards this factor representing variance all these items had in common. This factor is therefore termed Alternative Treatments. 

% PA5: "Hom1" "Hom3" "Hom4" "Hom5" "Hom6" "Rei1" "Rei2" "Rei3" "Rei4" "Rei5" "Rei6". This factor consists of moderate loadings on Homeopathy and large loadings on Reiki. This factor can probably best be termed Reiki and Alterntative Treatments. 

% PA3: "Acu1" "Acu2" "Acu3" "Acu4" "Acu5" "Acu6". This factor maps exactly to the Acupuncture items and so retains that name. 

% PA4: "Cream1" "Cream2" "Cream3" "Cream4" "Cream5" "Cream6". This factor again maps exactly to the Creams items, and is therefore termed Cream. This factor solution was from a varimax rotation, note the interesting differences between it and the others. 


Next, the beliefs about medicine questionnaire will be examined in terms of factor analysis. 

\subsubsection{Beliefs About Medicine Questionnaire}
\label{sec:beli-about-medic}


\begin{figure}
<<bam2cparallel, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
sink("tmp.txt")
bam2c.para <- fa.parallel(na.omit(bamall2c))
bam2c.vss <- VSS(na.omit(bamall2c))
sink(NULL)
@   
  \caption{Parallel Analysis and VSS Criteria for Beliefs About Medicine Scale, Split C}
  \label{fig:bam2cparallel}
\end{figure}


The parallel analysis criterion suggests three factors here, while the MAP criterion suggests one, previous practice will be followed and the solutions with one, two and three factors will be extracted and examined. 

\paragraph{One Factor Solution}
\label{sec:one-factor-solution}



<<bam2cfact1, echo=FALSE, results=tex>>=
bam2c.fact1 <- fa(na.omit(bamall2c), 1, fm="pa")
print(FactorXtab(bam2c.fact1, names=c("BAM1"),label="tab:bam2cfact1", caption="One Factor Solution, Beliefs About Medicine Questionnaire, TCQ2, Split C"))
@ 

The loadings and communalities are uniformly low (shown in Table \ref{tab:bam2cfact1} for this solution, and ther proportion of variance explained was 20\%. 

\paragraph{Two Factor Solution}
\label{sec:two-factor-solution}


<<bam2cfact2, echo=FALSE, results=tex>>=
bam2c.fact2 <- fa(na.omit(bamall2c), 2, rotate="oblimin", fm="pa")
                                                  print(FactorXtab(bam2c.fact2,names=c("BAM1", "BAM2"), label="tab:bam2cfact2", caption="Two factor Solution, Beliefs About Medicine Questionnaire, TCQ2, Split C"))
@ 
As can be seen from Table \ref{tab:bam2cfact2} the listings of items which loaded on factors below, some of the items did not load on any factor, which is normally an indicator of a poor factor solution. 


PA1: "BAM2",  "BAM6",  "BAM8",  "BAM9",  "BAM10", "BAM13", "BAM14", "BAM17", "BAM18". All of these items appear to relate to the problems with medications, suggesting that this factor should be termed Medication Avoidance. 

PA2: "BAM2",  "BAM3",  "BAM7",  "BAM10", "BAM11", "BAM16". These items all appear to relate to the safe use of medicines, and so this factor is termed Safe Use of Medicines. 

<<bam2cfact2cor, echo=FALSE, results=tex>>=
print(FactorCor(bam2c.fact2,label="tab:bam2cfact2cor", caption="Factor Correlations, Two Factor Solution, Beliefs About Medicine Questionnaire, Split C"))
@ 

As can be seen from Table \ref{tab:bam2cfact2cor}, the two factors are moderately correlated, in contrast to Split B ( Table \ref{tab:bam2bfact2cor}), but like Split A (Table \ref{tab:bam2afact2cor}). 

<<bam2cfact3, echo=FALSE, results=tex>>=
bam2c.fact3 <- fa(na.omit(bamall2c), 3, rotate="oblimin", fm="pa")
print(FactorXtab(bam2c.fact3, names=c("BAM1", "BAM2", "BAM3"), label="tab:bam2cfact3", caption="Three Factor Solution, Beliefs About Medicine Questionnaire, TCQ2, Split C"))
@ 

Table \ref{tab:bam2cfact3} shows the structure of the three factor solution in this split. 


PA1: "BAM13", "BAM14", "BAM17". All of these items relate to doctors and so this factor can best be termed Doctors and Medicines. 

PA3: "BAM3",  "BAM6",  "BAM7",  "BAM8",  "BAM9",  "BAM10", "BAM18". All these items appear to relate to the safety of medicines, and so this factor is named thusly. 

PA2: "BAM2",  "BAM3",  "BAM11", "BAM16". These items refer to different types of medicines, and so this factor is termed Specific Use of Medicines. 

<<bam2cfact3cor, echo=FALSE, results=tex>>=
print(FactorCor(bam2c.fact3,label="tab:bam2cfact3cor", caption="Factor Correlations, Three Factor Solution, Beliefs About Medicine Questionnaire, Split C"))
@ 

The correlations shown in Table \ref{tab:bam2cfact3cor} are quite similiar to those found in the other three factor solutions, with two of the factors having moderate correlations while a third is not really correlated with this pair. 

\begin{figure}
	\centering
<<tcq2dparallel, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
sink("tmp.txt")
par(mfrow=c(1,2))
tcq2d.para <- fa.parallel(na.omit(tcqall2d))
tcq2d.vss <- VSS(na.omit(tcqall2d))
sink(NULL)
@ 
	\caption{Parallel Analysis and Scree Plot TCQ 2 (Split D)}
	\label{fig:tcq2dparallel}
\end{figure}

\subsubsection{Beliefs About Medicine Questionnaire, Split D}
\label{sec:beli-about-medic}



Next, the beliefs about medicine questionnaire will be examined in terms of factor analysis. 

\begin{figure}
<<bam2dparallel, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
sink("tmp.txt")
bam2d.para <- fa.parallel(na.omit(bamall2d))
bam2d.vss <- VSS(na.omit(bamall2d))
sink(NULL)
@   
  \caption{Parallel Analysis Scree Plot for Beliefs About Medicine Questionnaire, Split D}
  \label{fig:bam2dparallel}
\end{figure}


The parallel analysis criterion suggests three factors here (shown in Figure \ref{fig:bam2dparallel}, while the MAP criterion suggests one, previous practice will be followed and the solutions with one, two and three factors will be extracted and examined. 

\paragraph{One Factor Solution}
\label{sec:one-factor-solution}



<<bam2dfact1, echo=FALSE, results=tex>>=
bam2d.fact1 <- fa(na.omit(bamall2d), 1, fm="pa")
print(FactorXtab(bam2d.fact1, names=c("BAM1"), label="tab:bam2dfact1",caption="One Factor Solution, Beliefs About Medicine Questionnaire, TCQ 2 Split D"))
@ 

As can be seen from Table \ref{tab:bam2dfact1}, the factor solution has a number of items (5, 11, 12, 15 \& 16) which do not load on it. This solution explained about 21\% of the variance which is quite poor, though in line with what we have seen in other splits for a one factor solution.  

\paragraph{Two Factor Solution}
\label{sec:two-factor-solution}



<<bam2dfact2, echo=FALSE, results=tex>>=
bam2d.fact2 <- fa(na.omit(bamall2d), 2, rotate="oblimin", fm="pa")
print(FactorXtab(bam2d.fact2,names=c("BAM1", "BAM2"), label="tab:bam2dfact2", caption="Two Factor Solution, Beliefs About Medicine Questionnaire, Split D"))
@ 

Table \ref{tab:bam2dfact2} shows the coefficients for the two factor solution in Split D. 

PA2: "BAM3",  "BAM4",  "BAM6",  "BAM7",  "BAM8",  "BAM9",  "BAM10", "BAM11", "BAM18". These items all relate to the dangers surrounding medicines, and reasons to avoid using them, and so this factor can best be termed Safe use of Medicines. 

PA1: "BAM2",  "BAM6",  "BAM13", "BAM14", "BAM17". Most of these items relate to doctors and their use of medicines, and so this factor can best be termed Doctors and Medicines. 

<<bam2dfact2dcor, echo=FALSE, results=tex>>=
print(FactorCor(bam2d.fact2, label="tab:bam2dfact2dcor", caption="Factor Correlations Two Factor Solution, Beliefs About Medicine Questionnaire, Split D"))
@ 

It can be seen from Table \ref{tab:bam2dfact2dcor} that the two factors are moderately correlated, similarly to the previous splits. 


\paragraph{Three Factor Solution}
\label{sec:three-fact-solut}





<<bam2dfact3, echo=FALSE, results=tex>>=
bam2d.fact3 <- fa(na.omit(bamall2d), 3, rotate="oblimin", fm="pa")
print(FactorXtab(bam2d.fact3, names=c("BAM1", "BAM2", "BAM3"), label="tab:bam2dfact3", caption="Three Factor Solution, Beliefs About Medicine Questionnaire, Split D"))
@ 

Table \ref{tab:bam2dfact3} shows the structure of the three factor solution in Split D. 

PA1: "BAM2",  "BAM13", "BAM14", "BAM17". Most of these items relate to doctors, and so this factor can best be termed Doctors and Medicines. 

PA3: "BAM1",  "BAM3",  "BAM6",  "BAM8",  "BAM18". These items all relate to the dangers surrounding medicines, and so this factor can best be termed Dangers of Medicines. 

PA2: "BAM7",  "BAM9",  "BAM10", "BAM11". These items all appear to relate to the dangers and avoidance of medicines, and so this factor can best be termed avoidance of medicines. 


<<bam2dfact3cor, echo=FALSE, results=tex>>=
print(FactorCor(bam2d.fact3, label="tab:bam2dfact3cor", caption="Factor Correlations, Three factor solution, Beliefs About Medicine, Questionnaire, Split D"))
@ 

It can be seen from Table \ref{tab:bam2dfact3cor} that all of the factors correlate moderately with one another, supporting the use of oblique rotations for this split. 

Next, the fits of the Beliefs about Medicine Questionnaire from Split A will be tested on the out of sample data. 

<<bam1notAsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- c(bamitems.cols)
latents <- c("Beliefs About Medicine", "NoLoad")
Bamq <- paste(Bam, c(3,4,6,7,9,10,12,13,14,17), sep="")
bamnoload <- paste(Bam, c(1,2,5,8,11,15,16, 18), sep="")
Bam1modelnotA<- mxModel(name="Bam1notA", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Beliefs About Medicine", to=Bamq),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotA)), type="cov", numObs=524))
Bam1fitnotA <- mxRun(Bam1modelnotA)
Bam2asumm1 <- summary(Bam1fitnotA)
@ 

<<bam2notAsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Medicine Avoidance", "NoLoad", "Natural Remedies" )
medavoid <- paste(Bam, c(1,6,7,9,12,13,14,17,18), sep="")
natrem <- paste(Bam, c(2,7,10,11), sep="")
bamnoload <- paste(Bam, c(3,4,5,8,15,16), sep="")
Bam2modelnotA<- mxModel(name="Bam2notA", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Medicine Avoidance", to=medavoid),
                      mxPath(from="Natural Remedies", to=natrem),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotA)), type="cov", numObs=524))
Bam2fitnotA <- mxRun(Bam2modelnotA)
Bam2asummnotA <- summary(Bam2fitnotA)
@ 


<<bam3notAsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Medicine Avoidance", "NoLoad", "Safer Medicines","Responsible Use of Medicines"  )
medavoid <- paste(Bam, c(6,7,8,9,12,13,14,17,18), sep="")
safemed <- paste(Bam, c(1,3,4,10), sep="")
respmed <- paste(Bam, c(1,2,7,10,11), sep="")
bamnoload <- paste(Bam, c(5,15,16), sep="")
Bam3modelnotA<- mxModel(name="Bam3notA", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Medicine Avoidance", to=medavoid),
                      mxPath(from="Safer Medicines", to=safemed),
                        mxPath(from="Responsible Use of Medicines", to=respmed),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotA)), type="cov", numObs=524))
Bam3fitnotA <- mxRun(Bam3modelnotA)
Bam3asummnotA <- summary(Bam3fitnotA)
@ 


<<bam4notAsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Medicine Avoidance", "NoLoad", "Medicine Effectiveness","Differences between Medicines", "Regular Taking of Medicines")
medavoid <- paste(Bam, c(6,7,8,9,12,13,14,17,18), sep="")
medeffect <- paste(Bam, c(1,3,4,10), sep="")
diffmed <- paste(Bam, c(1,2,7,10,11,16, 18), sep="")
regmed <- paste(Bam, 5, sep="")
bamnoload <- paste(Bam, 15, sep="")
Bam4modelnotA<- mxModel(name="Bam4notA", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Medicine Avoidance", to=medavoid),
                      mxPath(from="Medicine Effectiveness", to=medeffect),
                        mxPath(from="Differences between Medicines", to=diffmed),
                        mxPath(from="Regular Taking of Medicines", to=regmed),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotA)), type="cov", numObs=524))
Bam4fitnotA <- mxRun(Bam4modelnotA)
Bam4asummnotA <- summary(Bam4fitnotA)
@ 

<<bamnotAsemcompare, echo=FALSE, results=tex>>=
bamsemcompare.notA <- mxCompare(Bam1fitnotA, c(Bam2fitnotA, Bam3fitnotA, Bam4fitnotA))
print(xtable(bamsemcompare.notA, label="tab:bamnotAsemcompare", captio="Comparison of Beliefs About Medicine Factor Solutions from Split A Tested on Splits B, C and D"))
@ 

As can be seen from Table \ref{tab:bamnotAsemcompare}, the four factor solution appears to replicate best on the out of sample data. 

Next, the fits of the Beliefs about Medicine Questionnaire from Split B will be tested on the out of sample data (that is, Splits A, C and D). 

<<bam1notBsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- c(bamitems.cols)
latents <- c("Beliefs About Medicine", "NoLoad")
Bamq <- paste(Bam, c(3,4,6,7,8,9,10,12,13,14,17, 18), sep="")
bamnoload <- paste(Bam, c(1,2,5,11,15,16), sep="")
Bam1modelnotB<- mxModel(name="Bam1notB", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Beliefs About Medicine", to=Bamq),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotB)), type="cov", numObs=512))
Bam1fitnotB <- mxRun(Bam1modelnotB)
Bam1asumm.notB <- summary(Bam1fitnotB)
@ 

<<bam2notBsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Medicine Avoidance", "NoLoad", "Responsible Use of Medicines")
medavoid <- paste(Bam, c(3,4,6,7,8,9,10,11,12,13,14,17,18), sep="")
respmed <- paste(Bam, c(1,2,11,16,18), sep="")
bamnoload <- paste(Bam, c(5,15), sep="")
Bam2modelnotB <- mxModel(name="Bam2notB", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Medicine Avoidance", to=medavoid),
                      mxPath(from="Responsible Use of Medicines", to=respmed),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotB)), type="cov", numObs=512))
Bam2fitnotB <- mxRun(Bam2modelnotB)
Bam2asummnotB <- summary(Bam2fitnotB)
@ 


<<bam3notBsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Medicine Avoidance", "NoLoad", "Safer Medicines","Responsible Use of Medicines"  )
medavoid <- paste(Bam, c(6,7,8,9,12,13,14,17,18), sep="")
safemed <- paste(Bam, c(1,3,4,10), sep="")
respmed <- paste(Bam, c(1,2,7,10,11), sep="")
bamnoload <- paste(Bam, c(5,15,16), sep="")
Bam3modelnotB<- mxModel(name="Bam3notB", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Medicine Avoidance", to=medavoid),
                      mxPath(from="Safer Medicines", to=safemed),
                        mxPath(from="Responsible Use of Medicines", to=respmed),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotB)), type="cov", numObs=524))
Bam3fitnotB <- mxRun(Bam3modelnotB)
Bam3asummnotB <- summary(Bam3fitnotB)
@ 


<<bam4notBsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Medicine Avoidance", "NoLoad", "Medicine Effectiveness","Differences between Medicines", "Regular Taking of Medicines")
medavoid <- paste(Bam, c(6,7,8,9,12,13,14,17,18), sep="")
medeffect <- paste(Bam, c(1,3,4,10), sep="")
diffmed <- paste(Bam, c(1,2,7,10,11,16, 18), sep="")
regmed <- paste(Bam, 5, sep="")
bamnoload <- paste(Bam, 15, sep="")
Bam4modelnotB<- mxModel(name="Bam4notB", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Medicine Avoidance", to=medavoid),
                      mxPath(from="Medicine Effectiveness", to=medeffect),
                        mxPath(from="Differences between Medicines", to=diffmed),
                        mxPath(from="Regular Taking of Medicines", to=regmed),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotB)), type="cov", numObs=524))
Bam4fitnotB <- mxRun(Bam4modelnotB)
Bam4asummnotB <- summary(Bam4fitnotB)
@ 

<<bamnotBsemcompare, echo=FALSE, results=tex>>=
bamsemcompare.notB <- mxCompare(Bam1fitnotB, c(Bam2fitnotB, Bam3fitnotB, Bam4fitnotB))
print(xtable(bamsemcompare.notB, label="tab:bamnotBsemcompare", caption="Beliefs About Medicine Questionnaire Split B Models Tested Against Splits A, C and D"))
@ 

It can be seen from Table \ref{tab:bamnotBsemcompare} that the two factor model provided the best fit to the out-of-sample data in  this case. 

Next, the fits of the Beliefs about Medicine Questionnaire from Split B will be tested on the out of sample data (that is, Splits A, C and D). 

<<bam1notCsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- c(bamitems.cols)
latents <- c("Beliefs About Medicine", "NoLoad")
Bamq <- paste(Bam, c(3,4,6,7,8,9,10,12,13,14,17, 18), sep="")
bamnoload <- paste(Bam, c(1,2,5,11,15,16), sep="")
Bam1modelnotC<- mxModel(name="Bam1notC", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Beliefs About Medicine", to=Bamq),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotC)), type="cov", numObs=512))
Bam1fitnotC <- mxRun(Bam1modelnotC)
Bam1asumm.notC <- summary(Bam1fitnotC)
@ 

<<bam2notCsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Medicine Avoidance", "NoLoad", "Safe Use of Medicines")
medavoid <- paste(Bam, c(2,6,8,9,10,13,14,17,18), sep="")
safemed <- paste(Bam, c(2,3,7,10,11,16), sep="")
bamnoload <- paste(Bam, c(1,4,5,12,15), sep="")
Bam2modelnotC <- mxModel(name="Bam2notC", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Medicine Avoidance", to=medavoid),
                      mxPath(from="Safe Use of Medicines", to=safemed),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotC)), type="cov", numObs=512))
Bam2fitnotC <- mxRun(Bam2modelnotC)
Bam2asummnotC <- summary(Bam2fitnotC)
@ 


<<bam3notCsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Doctors and Medicines", "NoLoad", "Safer Medicines","Specific Use of Medicines")
docmed <- paste(Bam, c(13,14,17), sep="")
safemed <- paste(Bam, c(3,6,7,8,9,10,18), sep="")
specmed <- paste(Bam, c(2,3,11,16), sep="")
bamnoload <- paste(Bam, c(1,4,5,12,15), sep="")
Bam3modelnotC<- mxModel(name="Bam3notC", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Doctors and Medicines", to=docmed),
                      mxPath(from="Safer Medicines", to=safemed),
                        mxPath(from="Specific Use of Medicines", to=specmed),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotC)), type="cov", numObs=524))
Bam3fitnotC <- mxRun(Bam3modelnotC)
Bam3asummnotC <- summary(Bam3fitnotC)
@ 


<<bamnotCsemcompare, echo=FALSE, results=tex>>=
bamsemcompare.notC <- mxCompare(Bam1fitnotC, c(Bam2fitnotC, Bam3fitnotC))
print(xtable(bamsemcompare.notC, label="tab:bamnotCsemcompare", caption="Beliefs About Medicine Questionnaire Models from Split C tested against Splits A, B and D"))
@ 

It can be seen from Table \ref{tab:bamnotCsemcompare} that the one factor solution fits the out of sample data best in this case. 

Next, the fits of the Beliefs about Medicine Questionnaire from Split D will be tested on the out of sample data (that is, Splits A, B and C). 

<<bam1notDsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- c(bamitems.cols)
latents <- c("Beliefs About Medicine", "NoLoad")
Bamq <- paste(Bam, c(1,2,3,4,6,7,8,9,10,13,14,17, 18), sep="")
bamnoload <- paste(Bam, c(5,11,12,15,16), sep="")
Bam1modelnotD<- mxModel(name="Bam1notD", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Beliefs About Medicine", to=Bamq),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotD)), type="cov", numObs=512))
Bam1fitnotD <- mxRun(Bam1modelnotD)
Bam1asumm.notD <- summary(Bam1fitnotD)
@ 

<<bam2notDsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Doctors and Medicines", "NoLoad", "Safe Use of Medicines")
safemed <- paste(Bam, c(3,4,6,8,9,10,11), sep="")
docmed <- paste(Bam, c(2,6,13,14,17), sep="")
bamnoload <- paste(Bam, c(1,5,7,12,15,16), sep="")
Bam2modelnotD <- mxModel(name="Bam2notD", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Doctors and Medicines", to=medavoid),
                      mxPath(from="Safe Use of Medicines", to=respmed),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotD)), type="cov", numObs=512))
Bam2fitnotD <- mxRun(Bam2modelnotD)
Bam2asummnotD <- summary(Bam2fitnotD)
@ 


<<bam3notDsem, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Doctors and Medicines", "NoLoad", "Dangers of Medicines","Avoidance of Medicines")
docmed <- paste(Bam, c(2,13,14,17), sep="")
dangermed <- paste(Bam, c(1,3,6,8,18), sep="")
medavoid <- paste(Bam, c(7,9,10,11), sep="")
bamnoload <- paste(Bam, c(4,5,7,12,15,16), sep="")
Bam3modelnotD<- mxModel(name="Bam3notD", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Doctors and Medicines", to=docmed),
                      mxPath(from="Dangers of Medicines", to=dangermed),
                        mxPath(from="Avoidance of Medicines", to=medavoid),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotD)), type="cov", numObs=524))
Bam3fitnotD <- mxRun(Bam3modelnotD)
Bam3asummnotD <- summary(Bam3fitnotD)
@ 


<<bamnotDsemcompare, echo=FALSE, results=tex>>=
bamsemcompare.notD <- mxCompare(Bam1fitnotD, c(Bam2fitnotD, Bam3fitnotD))
print(xtable(bamsemcompare.notD, label="tab:bamnotDsemcompare", caption="Beliefs About Medicine Questionnaire Models from Split D, tested against Splits A, B and C"))
@ 

It can be seen from Table \ref{tab:bamnotDsemcompare} that the one factor solution fits the out of sample data best in the case of the Split D models tested on the out of sample data. 

<<bam4notAsemAll, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Medicine Avoidance", "NoLoad", "Medicine Effectiveness","Differences between Medicines", "Regular Taking of Medicines")
medavoid <- paste(Bam, c(6,7,8,9,12,13,14,17,18), sep="")
medeffect <- paste(Bam, c(1,3,4,10), sep="")
diffmed <- paste(Bam, c(1,2,7,10,11,16, 18), sep="")
regmed <- paste(Bam, 5, sep="")
bamnoload <- paste(Bam, 15, sep="")
Bam4modelnotA.all<- mxModel(name="Bam4notAAll", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Medicine Avoidance", to=medavoid),
                      mxPath(from="Medicine Effectiveness", to=medeffect),
                        mxPath(from="Differences between Medicines", to=diffmed),
                        mxPath(from="Regular Taking of Medicines", to=regmed),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamall2)), type="cov", numObs=671))
Bam4fitnotA.all <- mxRun(Bam4modelnotA.all)
Bam4asummnotA.all <- summary(Bam4fitnotA.all)
@ 

<<bam2notBsemAll, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- bamitems.cols
latents <- c("Medicine Avoidance", "NoLoad", "Responsible Use of Medicines")
medavoid <- paste(Bam, c(3,4,6,7,8,9,10,11,12,13,14,17,18), sep="")
respmed <- paste(Bam, c(1,2,11,16,18), sep="")
bamnoload <- paste(Bam, c(5,15), sep="")
Bam2modelnotB.all <- mxModel(name="Bam2notBAll", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Medicine Avoidance", to=medavoid),
                      mxPath(from="Responsible Use of Medicines", to=respmed),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamall2)), type="cov", numObs=671))
Bam2fitnotB.all <- mxRun(Bam2modelnotB.all)
Bam2asummnotB.all <- summary(Bam2fitnotB.all)
@ 

<<bam1notCsemAll, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- c(bamitems.cols)
latents <- c("Beliefs About Medicine", "NoLoad")
Bamq <- paste(Bam, c(3,4,6,7,8,9,10,12,13,14,17, 18), sep="")
bamnoload <- paste(Bam, c(1,2,5,11,15,16), sep="")
Bam1modelnotC.all<- mxModel(name="Bam1notCAll", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Beliefs About Medicine", to=Bamq),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamall2)), type="cov", numObs=671))
Bam1fitnotC.all <- mxRun(Bam1modelnotC.all)
Bam1asumm.notC.all <- summary(Bam1fitnotC.all)
@ 

<<bam1notDsemAll, echo=FALSE, results=hide, cache=TRUE>>=
Bam <- "BAM"
bamitems.cols <- paste(Bam, 1:18, sep="")
manifests <- c(bamitems.cols)
latents <- c("Beliefs About Medicine", "NoLoad")
Bamq <- paste(Bam, c(1,2,3,4,6,7,8,9,10,13,14,17, 18), sep="")
bamnoload <- paste(Bam, c(5,11,12,15,16), sep="")
Bam1modelnotD.all<- mxModel(name="Bam1notDAll", 
                      type="RAM",
                      manifestVars=manifests,
                      latentVars=latents,
                      mxPath(from="Beliefs About Medicine", to=Bamq),
                      mxPath(from="NoLoad", to=bamnoload, free=FALSE, values=0.0),
                      mxPath(from=manifests, arrows=2),
                      mxPath(from=latents, arrows=2, free=FALSE, values=0.4),
mxData(observed=cov(na.omit(bamnotD)), type="cov", numObs=671))
Bam1fitnotD.all <- mxRun(Bam1modelnotD.all)
Bam1asumm.notD.all <- summary(Bam1fitnotD.all)
@

<<bamallsemcompare, echo=FALSE, results=tex>>=
bamall.semcompare <- mxCompare(Bam4fitnotA.all, c(Bam2fitnotB.all, Bam1fitnotC.all, Bam1fitnotD.all))
print(xtable(bamall.semcompare, label="tab:bamallsemcompare", caption="Best Model from Each Split tested against one another on the full dataset, Beliefs About Medicine Questionnaire"))
@ 

As can be seen from Table \ref{tab:bamallsemcompare}, the two factor model from Split B provided the best fit to all of the data, striking a balance between the complexity of the four factor model and the over simplicity of the one factor model. 

Next, the beliefs about medicine questionnaire was examined in terms of item response theory.

<<bam2ascales, echo=FALSE, results=tex>>=
bam2a.scales <- aisp(na.omit(bamall2a))
print(xtable(bam2a.scales, label="tab:bam2ascales", caption=" Item Scale Analysis  for Beliefs About Medicine Questionnaire, IRT scale, Split A"))
@ 

It can be seen from Table ~\ref{tab:bam2ascales} that many items on the beliefs about medicine questionnaire do not appear to be part of any scale (indicated by the zeros next to the item number). The algorithm suggests that there are two scales.

The first is made up of BAM6, BAM7, BAM9, BAM13, BAM14 and BAM17.
The second is made up of BAM4 and BAM10. This second scale appears to be less than useful, as some of the other tests of assumptions require at least three items per scale. The approach taken here will be to eliminate all but the first scale and conduct our analyses on that set of six items.

<<bam2areduce, echo=FALSE, results=hide, cache=TRUE>>=
bam2ascale <- bamall2a[,c("BAM6","BAM7","BAM9","BAM13","BAM14","BAM17")]
## bam2ascale.other <- bamall2a[,!c("BAM6","BAM7","BAM9","BAM13","BAM14","BAM17")]
@ 

The next step is to check the assumption of invariant item ordering. This is less important here, but is checked for the sake of completeness. 

<<bam2aiio, echo=FALSE, results=tex>>=
bam2a.iio <- check.iio(na.omit(bam2ascale))
print(xtable(bam2a.iio$violations, label="tab:bam2aiio", caption="Item Ordering Assumption Check for Reduced Beliefs About Medicine Questionnaire, Split A"))
@ 

As can be seen from Table ~\ref{tab:bam2aiio}, no items violated the invariant item ordering assumption, and so are are retained until the next stage. The next step is to check the assumption of monotonicity.

<<bam2acheckmono, echo=FALSE, results=tex>>=
bam2a.mono <- check.monotonicity(na.omit(bam2ascale))
print(xtable(summary(bam2a.mono), label="tab:bam2amono", caption="Monotonicity Check, Beliefs About Medicine Questionnaire, Split A"))
@ 

Table \ref{tab:bam2amono} shows that there were no violations of monotonicity in this split for the reduced set of items. 

The next step in our analysis plan is to fit a rasch model to the beliefs about medicine scale. 

<<bam2agpcm, echo=FALSE, results=hide, cache=TRUE>>=
bam2a.gpcm.rasch <- gpcm(bam2ascale, constraint="rasch")
bam2a.gpcm.1PL <- gpcm(bam2ascale, constraint="1PL")
bam2a.gpcm.gpcm <- gpcm(bam2ascale, constraint="gpcm")
@ 

<<bam2arasch, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2a.gpcm.rasch)), label="tab:bam2arasch", caption="Coefficients for Beliefs About Medicine Questionnaire, Rasch partial credit model"))
@ 

As can be seen from Table ~\ref{tab:bam2arasch}, this model shows problems typical to the PCM of the middle category having a lower estimated ability threshold than do the categories to either side. Nonetheless, it can be seen that BAM9, ``It is better to do without medicines'' has the highest thresholds, followed by 17, ``Doctors use too many medicines'', which makes sense as these questions are more absolutist than many of the others. 

We next examine the fit of a one paramater generalised partial credit model with a discrimination parameter estimated from the data. 

<<bam2a1PL, echo=FALSE, results=tex>>=

print(xtable(coef2mat(coef(bam2a.gpcm.1PL)), label="tab:bam2a1PL", caption="Coefficients for Beliefs About Medicine Questionnaire, One parameter Generalised Partial Credit Model"))
@ 

Again, Table \ref{tab:bam2a1PL} makes it very clear that the one parameter GPCM provides little advantage over the Rasch model, in that the estimated difficulties are very similar and the discrimination parameter has not moved very much. 

Next, the fit of a two parameter GPCM to this scale was examined. 

<<bam2agpcm, echo=FALSE, results=tex>>=

print(xtable(coef2mat(coef(bam2a.gpcm.gpcm)), label="tab:bam2agpcm", caption="Coefficients for Beliefs About Medicine Questionnaire, Split A, Two Parameter Generalised Partial Credit Model"))
@ 
It can be clearly seen from Table ~\ref{tab:bam2agpcm} that the two parameter GPCM provides a more interesting picture. Again, 7 is the most difficult, but has a very low discrimination parameter, suggesting that it is relatively poor at clustering high and low scorers on the scale. However, 17 has lowered its difficulties, but shows much better discrimination. 

In line with previous practice, the next models fit were the one and two parameter graded response models. 

<<bam2agrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2a.grm.1pl <- grm(na.omit(bam2ascale), constrained=TRUE)
bam2a.grm.2pl <- grm(na.omit(bam2ascale), constrained=FALSE, Hessian=TRUE)
@ 

<<bam2agrm1pl, echo=FALSE, results=tex>>=

bam2acoef.mat <- coef2mat(coef(bam2a.grm.1pl))
print(xtable(bam2acoef.mat, label="tab:bam2agrm1pl", caption="Coefficients for Beliefs About Medicine Questionnaire, Split A, One parameter Graded Response Model"))
@ 

It can be seen from Table \ref{tab:bam2agrm1pl} that the fit of this model is much better that the fit of any of the partial credit models. 

The next step is to fit a two parameter GRM, and examine the differences in fit between the two models. 

<<bam2agrm2pl, echo=FALSE, results=tex>>=

bam2acoef.mat <- coef2mat(coef(bam2a.grm.2pl))
print(xtable(bam2acoef.mat, label="tab:bam2agrm2pl", caption="Coefficients for Beliefs About Medicine Questionnaire, Split A, Two parameter Graded Response Model"))
@ 

It can be seen from Table \ref{tab:bam2agrm2pl} that this model reveals some interesting features of the items. BAM13 and BAM17 have the highest discrimination parameters, but the ability estimates of their extremities have moved down to compensate. 

A likelihood ratio test carried out between the two models suggested that the two parameter model was significantly better than the one parameter model, ($p\le 0.001$). Again, this is a tentative result until the performance of the model on new data is examined. In any case, while both the AIC and the LR test favoured the two parameter model, the BIC was lower for the one parameter model indicating that according to this criterion, the one parameter model was superior. 

Next, the performance of all the Beliefs About Medicine Models was assessed on unseen data (Splits B, C and D). 

<<bampcmtest, echo=FALSE, results=tex, cache=TRUE>>=
bamnota.irt <-  tcq2nota[,c("BAM6","BAM7","BAM9","BAM13","BAM14","BAM17")]
bam2a.pcm.rasch.done <- testIRTModels(bam2a.gpcm.rasch, bamnota.irt, gpcmconstraint="rasch", grmconstraint=NULL)
bam2a.pcm.1pl.done <- testIRTModels(bam2a.gpcm.1PL, bamnota.irt, gpcmconstraint="1PL", grmconstraint=NULL)
bam2a.pcm.gpcm.done <- testIRTModels(bam2a.gpcm.gpcm, bamnota.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
bam2a.pcm.modcomp <- rbind(bam2a.pcm.rasch.done, bam2a.pcm.1pl.done, bam2a.pcm.gpcm.done)
rownames(bam2a.pcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")

@ 
<<bam2apcmmodcompprint, echo=FALSE, results=tex>>=
bam2a.pcm.modcomp.xtab <- xtable(bam2a.pcm.modcomp, caption="Partial Credit Models for BAM Scale from Split A Performance on Heldout Data", label="tab:bam2apcmmodcomp")
print(bam2a.pcm.modcomp.xtab)
@ 
From Table \ref{tab:bam2apcmmodcomp} it can be seen that the rasch model provided the best performance on unseen data. 

Next, the performance of the graded response models on unseen  data was assessed. 

<<bam2agrmtest, echo=FALSE, results=tex, cache=TRUE>>=
## bam2a.test <- bamnota.irt[,2:length(bamnota.irt)]
## bam2a.grm.1pl.done <- testIRTModels(bam2a.grm.1pl, bam2a.test)
@ 
%fix split A levels problem

The same model fitting procedure will now be repeated for the Beliefs About Medicine Questionnaire in this split. 

<<bam2baisp, echo=FALSE, results=tex>>=
bam2b.aisp <- aisp(na.omit(bamall2b))
print(xtable(bam2b.aisp, label="tab:bam2baisp", caption="Item Selection Procedure for Beliefs About Medicine Questionnaire, Split B"))
@ 

As shown in Table \ref{tab:bam2baisp}, some items do not load on any scales, and there is one two item scale (BAM1 and BAM2), along with one larger scale. As two items are not enough to form a useful scale, the larger scale will be the only one which is analysed. 

The scale that will be analysed consists of BAM3, BAM4, BAM6, BAM9, BAM10, BAM11, BAM13, BAM14 and BAM17. This is a larger scale than was observed with Split A. 

<<bamscale2b,echo=FALSE, results=hide>>=
bamscale2b <- bamall2b[,c("BAM3","BAM4","BAM6","BAM9","BAM10","BAM11","BAM13","BAM14", "BAM17")]
@ 

The first step is to examine the invariant item ordering assumption.

<<bam2checkiio, echo=FALSE, results=tex>>=
bam2b.iio <- check.iio(na.omit(bamscale2b))
print(xtable(bam2b.iio$violations, label="tab:bam2checkiio", caption="Item Ordering Assumption Check for Beliefs About Medicine Scale, Split B"))
@ 

In line with the results of Split A, no items were in violation of this assumption. 

The next assumption which needs to be checked is the monotonicity assumption. 

<<bam2bcheckmono, echo=FALSE, results=tex>>=
bam2b.mono <- check.monotonicity(na.omit(bamscale2b))
print(xtable(summary(bam2b.mono), label="tab:bam2bcheckmono", caption="Monotonicity Check, Beliefs About Medicine Scale, Split B"))
@ 

Table \ref{tab:bam2bcheckmono} shows clearly that there were no violations of the monotonicity assumption in this sample. 

The final preliminary model check consists of a plot displaying the number of Guttman errors for each participant.
\begin{figure}
<<bam2bguttman, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
bam2b.guttman <- check.errors(na.omit(bamscale2b))
bam2b.guttplot <- ggplot(as.data.frame(bam2b.guttman), aes(x=bam2b.guttman))+geom_histogram(binwidth=2)
print(bam2b.guttplot)
@   
  \caption{Plot of Guttman errors for Beliefs about Medicine Scale, Split B}
  \label{fig:bam2bguttmanplot}
\end{figure}

As can be seen from Figure \ref{fig:bam2bguttmanplot}, the number of guttman errors was much higher for this scale than was observed in the previous split. This suggests that some of the respondents were not answering the questions in a consistent fashion, and will be investigated further when the person fit statistics are examined on a per model basis. 

The first step in modelling the Beliefs about Medicines questionnaire is to attempt to fit a Rasch partial credit model.

<<bam2bgpcm, echo=FALSE, results=hide, cache=TRUE>>=
bam2b.gpcm.rasch <- gpcm(bamscale2b, constraint="rasch")
bam2b.gpcm.1PL <- gpcm(bamscale2b, constraint="1PL")
bam2b.gpcm.gpcm <- gpcm(bamscale2b, constraint="gpcm")
@ 





The estimated parameters for the Rasch model are shown  in Table \ref{tab:bam2bgpcmrasch}. 


<<bam2bgpcmrasch, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2b.gpcm.rasch)), label="tab:bam2bgpcmrasch", caption="Coefficients for Beliefs About Medicine Questionnaire, Split B, Rasch generalised Partial Credit Model"))
@ 

It can be seen from Table \ref{tab:bam2bgpcmrasch} that the Rasch PCM has thresholds in line with those of the conventional item TCQ, and that Q6 is regarded as the most difficult, which is not surprising given the content of the item ``Medicines often do more harm than good''. 

Next, the coefficients are examined for a one parameter PCM on this scale. 


<<bam2bgpcm1pl, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2b.gpcm.1PL)), label="tab:bam2bgpcm1pl", caption="Coefficients for Beliefs About Medicine Questionnaire, Split B, One Parameter Generalised Partial Credit Model"))
@ 

Table \ref{tab:bam2bgpcm1pl} shows the estimated coefficients for this model. It can be seen that there are no major changes from the Rasch model, the discrimination parameter has lowered, but the ability thresholds have risen slightly, most noticeably in the case of BAM6. 


Finally, the fit of a two parameter PCM was examined.

<<bam2bgpcmgpcm, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2b.gpcm.gpcm)), label="tab:bam2bgpcm2pl", caption="Coefficients for Beliefs About Medicine Questionnaire, Split B, Two Parameter Generalised Partial Credit Model"))
@ 

Table \re{tab:bam2bgpcm2pl} shows the results of this fit. It can be seen that the discrimination parameters of items 6, 13,14 and 17 have markedly increased, while those of the other items have lowered slightly. 

The next step in the process of modelling was to fit one and two parameter Graded Response Models. 

<<bam2bgrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2b.grm.1pl <- grm(bamscale2b, constrained=TRUE)
bam2b.grm.2pl <- grm(bamscale2b, constrained=FALSE)
@ 

<<bam2bgrm1sum, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2b.grm.1pl)), label="tab:bam2bgrm1sum", caption="Coefficients for Beliefs About Medicine Questionnaire, Split B, One Parameter Graded Response Model"))
@ 

Table \ref{tab:bam2bgrm1sum} shows no signs of problems with monotonicity, and the fit appears acceptable. Next, the two parameter GRM was examined.

<<bam2bgrm2sum, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2b.grm.2pl)), label="tab:bam2bgrm2sum", caption="Coefficients for Beliefs About Medicine Questionnaire, Two parameter Graded Response Model"))
@ 

Table \ref{tab:bam2bgrm2sum} shows that the fit of the two parameter model is equally unproblematic. 

<<bam2banovagrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2bgrm.anova <- anova(bam2b.grm.1pl, bam2b.grm.2pl)
@ 

A likelihood ratio test suggests that the two parameter model provides a significantly better fit ($p \le 0.001$) than does the one parameter model. 


Finally, the performance of each of the different types of IRT models on unseen data was assessed. 

<<bam2bpcmmodtest, echo=FALSE, results=tex, cache=TRUE>>=
bamnotb.irt <- tcq2notb[,c("BAM3", "BAM4", "BAM6", "BAM9", "BAM10", "BAM11", "BAM13", "BAM14", "BAM17")]
bam2b.gpcm.rasch.done <- testIRTModels(bam2b.gpcm.rasch,  bamnotb.irt, gpcmconstraint="rasch", grmconstraint=NULL)
bam2b.gpcm.1PL.done <- testIRTModels(bam2b.gpcm.1PL, bamnotb.irt, gpcmconstraint="1PL", grmconstraint=NULL)
bam2b.gpcm.gpcm.done <- testIRTModels(bam2b.gpcm.gpcm, bamnotb.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
bam2b.gpcm.modcomp <- rbind(bam2b.gpcm.rasch.done, bam2b.gpcm.1PL.done, bam2b.gpcm.gpcm.done)

@ 
<<bam2bgpcmmodcompprint, echo=FALSE, results=tex>>=
bam2b.gpcm.modcomp.xtab <- xtable(bam2b.gpcm.modcomp, caption="Performance of Beliefs About Medicine IRT Scale from Split B on Splits A, C and D", label="tab:bam2bpcmmodcomp")
print(bam2b.gpcm.modcomp.xtab)
@ 
As can be seen from Table \ref{tab:bam2bpcmmodcomp}, the Rasch PCM provided the best performance on unseen data.

Next, the same procedure was applied to the Graded Response Models. 

<<bam2bgrmtest, echo=FALSE, results=tex, cache=TRUE>>=
#bam2b.grm.1pl.done <- testIRTModels(bam2b.grm.1pl, bamnotb.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
@


% figure out what to do with the different response patterns in grade response models 

Next, the beliefs about medicine questionnaire was examined in this split. 

<<bam2caisp, echo=FALSE, results=tex>>=
bam2c.aisp <- aisp(na.omit(bamall2b))
print(xtable(bam2c.aisp, label="tab:bam2caisp", caption="Item Selection Procedure, Beliefs About Medicine Questionnaire, Split C"))
@ 

As seen in previous splits, BAM1 and BAM2 were partitioned into their own scale, and many items did not fit any scale. As a two item scale is too small to examine effectively, all further analyses were carried out on the reduced scale (1). Table \ref{tab:bam2caisp} shows these results. In contrast to Split A, the scale had 9 items, and these were the same items as were selected by the scale splitting algorithm in Split B. 

<<bamscale2c,echo=FALSE, results=hide, cache=TRUE>>=
bamscale2c <- bamall2b[,c("BAM3","BAM4","BAM6","BAM9","BAM10","BAM11","BAM13","BAM14", "BAM17")]
@ 

The first assumption to be checked was the invariant item ordering assumption, and the results are shown in Table \ref{tab:bam2checkiio}. 

<<bam2ccheckiio, echo=FALSE, results=tex>>=
bam2c.iio <- check.iio(na.omit(bamscale2c))
print(xtable(bam2c.iio$violations, label="tab:bam2checkiio", caption="Item Ordering Assumption Check, Beliefs About Medicine Questionnaire, Split C"))
@ 

As can be seen from Table \ref{tab:bam2checkiio}, no items violated this assumption and therefore all of them were retained. 


<<bam2ccheckmono, echo=FALSE, results=tex>>=
bam2c.mono <- check.monotonicity(na.omit(bamscale2c))
print(xtable(summary(bam2c.mono), label="tab:bam2ccheckmono", caption="Monotonicity Check, Beliefs About Medicine Questionnaire, Split C"))
@ 

Following the check of the IIO assumption, the next step in assumption checking was a monotonicity check. The results of this check are shown in Table \ref{tab:bam2ccheckmono}. This shows that no items violated this assumption (though the ItemH coefficients are close to the cutoff of 0.3). 

\begin{figure}
<<bam2cguttman, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
bam2c.guttman <- check.errors(na.omit(bamscale2c))
bam2c.guttplot <- ggplot(as.data.frame(bam2c.guttman), aes(x=bam2c.guttman))+geom_histogram(binwidth=2)
print(bam2c.guttplot)
@   
  \caption{Plot of Guttman errors for Beliefs about Medicine Scale, Split C}
  \label{fig:bam2cguttmanplot}
\end{figure}

Next, the guttman errors in the split were examined and checked across this sample of items. Similiarly to the TCQ items in this split, the level of guttman errors was much higher, with a mode at approximately 10. This is worrying, and needs to be investigated further. 


<<bam2cgpcm, echo=FALSE, results=hide, cache=TRUE>>=
bam2c.gpcm.rasch <- gpcm(bamscale2c, constraint="rasch")
bam2c.gpcm.1PL <- gpcm(bamscale2c, constraint="1PL")
bam2c.gpcm.gpcm <- gpcm(bamscale2c, constraint="gpcm")
@ 

Firstly, three generalised partial credit models were fit (Rasch, one parameter and two parameter). The results are shown below. 


<<bam2cgpcmrasch, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2c.gpcm.rasch)), label="tab:bam2cgpcmrasch", caption="Beliefs About Medicine Questionnaire Split C, Rasch generalised partial credit model"))
@ 

Table \ref{tab:bam2cgpcmrasch} shows the coefficient estimates for the Rasch model fitted to the BAM scale. It can be seen that the estimated thresholds are in line with the ranges from the conventional items, while it might have been expected that they would be more along the lines of the alternative items (given the overlap between negativity towards conventional medicines and positivity towards alternative treatments). 
% % . Although the problems of non-monotonic coefficient estimates are less severe than in previous splits, they are still there (BAM9,11, 13, 14, 17). This indicates that the model does not do a good job on this scale. The same problems occurred for both the one parameter and two parameter models, and so these coefficient estimates are not reported.

Next, the fit of a one parameter PCM was examined on this scale.

<<bam2cpcm1plprint, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2c.gpcm.rasch)), label="tab:bam2cgpcmrasch", caption="Coefficient Estimates for BAM Scale, One Parameter PCM, Split C"))
@ 

Table \ref{tab:bam2cgpcmrasch} shows the estimated coefficients for this model. Interestingly enough, the discrimination parameter has lowered for all of the items. This suggests that these items are less good than would be expected at discriminating between high and low ability participants. 

Finally, the fit of the two parameter PCM was examined on this scale.

<<bam2cgpcmgpcmprint, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2c.gpcm.gpcm)), label="tab:bam2cgpcmgpcm", caption="Coefficient Estimates, BAM Scale, Two Parameter PCM, Split C"))
@ 

Table \ref{tab:bam2cgpcmgpcm} shows the estimated coefficients for the two parameter PCM. It can be seen that Q6, 14 and 17 are the most discrimination question, and that 3,4, 9 and 10 appear to have been the drivers of the discrimination parameter being below 1 in the one parameter model. 

Next, the fit of one and two parameter graded response models were examined. 

<<bam2cgrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2c.grm.1pl <- grm(bamscale2c, constrained=TRUE)
bam2c.grm.2pl <- grm(bamscale2c, constrained=FALSE)
@ 

<<bam2cgrm1sum, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2c.grm.1pl)), label="tab:bam2cgrm1sum", caption="Coefficients for Beliefs About Medicine Questionnaire, One Parameter Graded Response Model (Split C)"))
@ 

Table \ref{tab:bam2cgrm1sum} shows that there are no monotonicity problems with the one parameter GRM. The estimated discrimination parameter is 1.523, and BAM6 appears to be the most difficult item in the scale (as no participants gave the highest response category to it, across all of the splits).




<<bam2cgrm2sum, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2c.grm.2pl)), label="tab:bam2cgrm2sum", caption="Coefficients for Beliefs About Medicine Questionnaire, Split C, Two parameter Graded Response Model"))
@ 

Next, the fit of the two parameter  GRM was examined, and is displayed in Table \ref{tab:bam2cgrm2sum}. Note that BAM13 appears to be the most discriminating item, and that BAM3 is the most difficult item (with the exception of BAM6, as noted above). 

<<bam2canovagrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2cgrm.anova <- anova(bam2c.grm.1pl, bam2c.grm.2pl)
@ 

An anova was carried out between the two graded response models, and the LR test showed that the two parameter model was significanly ($p \le 0.001$) better fit than the one parameter model. However, this was contradicted by both the BIC and AIC, which indicated that the one parameter model provided a better fit to the data. 

Next the performance of the IRT models developed was assessed on unseen data. 

<<bam2cpcmtest, echo=FALSE, results=tex, cache=TRUE>>=
bamnotc.irt <- tcq2notc[,c("BAM3", "BAM4", "BAM6",  "BAM9",  "BAM10", "BAM11", "BAM13",  "BAM14", "BAM17")]
bam2c.gpcm.rasch.done <- testIRTModels(bam2c.gpcm.rasch, bamnotc.irt, gpcmconstraint="rasch", grmconstraint=NULL)
bam2c.gpcm.1pl.done <- testIRTModels(bam2c.gpcm.1PL, bamnotc.irt, gpcmconstraint="1PL", grmconstraint=NULL)
bam2c.gpcm.gpcm.done <- testIRTModels(bam2c.gpcm.gpcm, bamnotc.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
bam2c.pcm.modcomp <- rbind(bam2c.gpcm.rasch.done, bam2c.gpcm.1pl.done, bam2c.gpcm.gpcm.done)
rownames(bam2c.pcm.modcomp) <- c("Rasch PCM", "One Parameter PCM", "Two Parameter PCM")

@ 
<<bam2cpcmmodcompprint, echo=FALSE, results=tex>>=
bam2c.gpcm.modcomp.xtab <- xtable(bam2c.pcm.modcomp, caption="Results of BAM Split C Partial Credit Models on Splits A, B and D", label="tab:bam2cpcmmodcomp")
print(bam2c.gpcm.modcomp.xtab)
@ 
As can be seen from Table \ref{tab:bam2cpcmmodcomp}, the Rasch model for the Beliefs About Medicine Questionnaire provided the best fit to unseen data. 

%% Next, we examine the performance of the Graded Response Models on unseen data. 

<<bam2cgrmtest, echo=FALSE, results=tex, eval=FALSE, cache=TRUE>>=
bam2c.grm.1pl.done <- testIRTModels(bam2c.grm.1pl, bamnotc.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
@ 

Next, the assumptions underlying the use of IRT modelling were applied to the Beliefs About Medicine Questionnaire. 

<<bam2daisp, echo=FALSE, results=tex>>=
bam2d.aisp <- aisp(na.omit(bamall2d))
print(xtable(bam2d.aisp, label="tab:bam2daisp", caption="Item Selection Procedure, Beliefs About Medicine Questionnaire, Split D"))
@ 

It can be seen from Table \ref{tab:bam2daisp} that again BAM1 and BAM2 form their own scale, while some of the other items do not appear on any scale. In line with previous practice, the small scale was not analysed, and so all analyses from this point on were carried out on the reduced scale (consisting of the items on scale 1 in Table \ref{tab:bam2daisp}).


<<bamscale2d,echo=FALSE, results=hide, cache=TRUE>>=
bamscale2d <- bamall2d[,c("BAM3","BAM6","BAM7","BAM9","BAM10","BAM13","BAM14", "BAM17")]
@ 



<<bam2dcheckiio, echo=FALSE, results=tex>>=
bam2d.iio <- check.iio(na.omit(bamscale2d))
print(xtable(bam2d.iio$violations, label="tab:bam2dheckiio", caption="Item Ordering Assumption Check, Beliefs About Medicine Questionnaire, Split D"))
@ 

Firstly, the invariant item ordering assumption was checked, and the results are shown in Table \ref{tab:bam2dheckiio}. As can be seen from this Table, there were no violations or issues with the IIO assumption.



<<bam2dcheckmono, echo=FALSE, results=tex>>=
bam2d.mono <- check.monotonicity(na.omit(bamscale2d))
print(xtable(summary(bam2d.mono), label="tab:bam2dcheckmono", caption="Monotonicity Check, Beliefs About Medicine Questionnaire, Split D"))
@ 

Next, the assumption of monotonicity was tested. The results of this test are shown in Table \ref{tab:bam2dcheckmono}, and it can be seen that there were no violations of this assumption, but the ItemH coefficients are quite low, suggesting that this scale is not entirely unproblematic. 


\begin{figure}
<<bam2dguttman, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
bam2d.guttman <- check.errors(na.omit(bamscale2d))
bam2d.guttplot <- ggplot(as.data.frame(bam2d.guttman), aes(x=bam2d.guttman))+geom_histogram(binwidth=2)
print(bam2d.guttplot)
@   
  \caption{Plot of Guttman errors for Beliefs about Medicine Scale, Split D}
  \label{fig:bam2dguttmanplot}
\end{figure}

Next, the scales were checked for guttman errors, and these were plotted in a histogram, shown in Figure \ref{fig:bam2dguttmanplot}. It can be seen from this plot that there were some participants who had quite a few guttman errors, as the distribution has a mode of approximately 10. However, the maximum number of Guttman errors was much lower than in Split C, where one participant had over 200 scaling errors. Again, this feature of the dataset needs to be investigated, and this will be carried out when person and item fit are assessed below.  

<<bam2dgpcm, echo=FALSE, results=hide, cache=TRUE>>=
bam2d.gpcm.rasch <- gpcm(bamscale2d, constraint="rasch")
bam2d.gpcm.1PL <- gpcm(bamscale2d, constraint="1PL")
bam2d.gpcm.gpcm <- gpcm(bamscale2d, constraint="gpcm")
@ 

Next, three generalised partial credit models were fitted to the scale, and the results of the Rasch fit are shown below. 


<<bam2dgpcmrasch, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2d.gpcm.rasch)), label="tab:bam2dgpcmrasch", caption="Coefficients for Beliefs About Medicine Questionnaire (Split D), Rasch Generalised Partial Credit Model"))
@ 

As can be seen from Table \ref{tab:bam2dgpcmrasch}, it can be seen that the majority of the categories have relatively low thresholds, with the exception of category 4. 

Next, a one parameter PCM was fitted to this scale. 

<<bam2dpcm1plprint, echo=FALSE, results=tex>>=
print(xtable(coef(bam2d.gpcm.1PL), label="tab:bam2dpcm1pl", caption="Coefficient Estimates for BAM Scale, One Parameter PCM, Split D"))
@ 

Table \ref{tab:bam2dpcm1pl} shows the estimated coefficients for the one parameter model. It can be seen that similarly to the Split C scale, the discrimination parameters have lowered in this model, while the estimated thresholds have risen slightly. 

Finally, a two parameter PCM was fitted to this scale.

<<bam2dpcm2plprint, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2d.gpcm.gpcm)), label="tab:bam2dpcm2pl", caption="Coefficient Estimates for BAM Scale, Two Parameter PCM, Split D"))
@ 

As can be seen from Table \ref{tab:bam2dpcm2pl}, the same pattern as was seen in Split C gas emerged, with some of the questions having quite high discrimination parameters, while others have rather low discriminations. Note in particular Q3, which has the huighest estimated threshold along with very low discrimination. 

<<bam2dgrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2d.grm.1pl <- grm(bamscale2d, constrained=TRUE)
bam2d.grm.2pl <- grm(bamscale2d, constrained=FALSE)
@ 

Next, two graded response models (one and two parameter) were fit to the data. 
<<bam2dgrm1sum, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2d.grm.1pl)), label="tab:bam2dgrm1sum", caption="Coefficients for Beliefs About Medicine Questionnaire (Split D), One Parameter Graded Response Model"))
@ 

Table \ref{tab:bam2dgrm1sum} shows the estimated coefficients and (averaged) discrimination parameter for the one parameter graded response model. This model appears to not have any problems with non-monotonicity, and the estimated discrimination parameter and thresholds are quite similar to those in previous splits. Again, BAM3 has the highest estimated threshold (with the exception of BAM6, where no participant picked the highest response alternative). 

Next, the two parameter GRM was fit to the Beliefs About Medicine Questionnaire. The results are shown in Table \ref{tab:bam2dgrm2sum}. The two parameter model is quite similiar to the one parameter model, the tradeoff between the discrimination parameter and the difficulty estimates can clearly be seen, as BAM3 has a lower discrimination parameter in this fit, but a much higher threshold. Most of the items appear to have made the opposite trade-off, with lower threshold values but a much higher discrimination parameter. 

<<bam2dgrm2sum, echo=FALSE, results=tex>>=
print(xtable(coef2mat(coef(bam2d.grm.2pl)), label="tab:bam2dgrm2sum", caption="Coefficients for Beliefs About Medicine Questionnaire, (Split D), Two Parameter Graded Response Model"))
@ 

After this process, an ANOVA was fit to the two graded response models, to determine which of them fit the data better. The LR test indicated that the two parameter model fit the data significanly better ($p\le0.001$), but the AIC indicated that the one parameter model was a better fit. This will be examined by looking at each of the models\' performance on unseen data. 

<<bam2danovagrm, echo=FALSE, results=hide, cache=TRUE>>=
bam2dgrm.anova <- anova(bam2d.grm.1pl, bam2d.grm.2pl)
@

Next, the performance of each of these models on unseen data was assessed. 

<<bam2dpcmmodtest, echo=FALSE, results=tex, cache=TRUE>>=
bamnotd.irt <- tcq2notd[,c("BAM3","BAM6","BAM7","BAM9","BAM10","BAM13","BAM14", "BAM17")]
bam2d.gpcm.rasch.done <- testIRTModels(bam2d.gpcm.rasch, bamnotd.irt, gpcmconstraint="rasch", grmconstraint=NULL)
bam2d.gpcm.1PL.done <- testIRTModels(bam2d.gpcm.1PL, bamnotd.irt, gpcmconstraint="1PL", grmconstraint=NULL)
bam2d.gpcm.gpcm.done <- testIRTModels(bam2d.gpcm.gpcm, bamnotd.irt, gpcmconstraint="gpcm", grmconstraint=NULL)
bam2d.pcm.modcomp <- rbind(bam2d.gpcm.rasch.done, bam2d.gpcm.1PL.done, bam2d.gpcm.gpcm.done)

@ 
<<bam2dpcmmodcompprint, echo=FALSE, results=tex>>=
print(xtable(bam2d.pcm.modcomp, caption="Performance of Split D Beliefs About Medicine Scale on Splits A, B and C", label="tab:bam2dpcmmodcomp"))

@ 
As can be seen from Table \ref{tab:bam2dpcmmodcomp}, the one parameter Partial Credit Model performed best on the unseen data. 

Next, the perfomance of the graded response models on unseen data was assessed. 

<<bam2dgrmmodtest, echo=FALSE, results=tex, cache=TRUE>>=
bam2d.grm.1pl.done <- testIRTModels(bam2d.grm.1pl, bamnotd.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
bam2d.grm.2pl.done <- testIRTModels(bam2d.grm.2pl, bamnotd.irt, gpcmconstraint=NULL, grmconstraint=TRUE)
bam2d.grm.modcomp <- rbind(bam2d.grm.1pl.done, bam2d.grm.2pl.done)

@ 
<<bam2dgrmmodcomp, echo=FALSE, results=tex>>=
print(xtable(bam2d.grm.modcomp, captio="Performance of Split D Beliefs About Medicine Scale (Graded Response Model) on Splits A, B and C", label="tab:bam2dgrmmodcomp"))
@ 

As can be seen from Table \ref{tab:bam2dgrmmodcomp}, the one parameter Graded Response Model performed best on the unseen data. 

\begin{figure}
<<splitApairs, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
tcq2.nota.tot <- tcq2nota[,71:77]
tcq2.nota.pairs <- pairs.panels(na.omit(tcq2.nota.tot))
@   
  \caption{Scatterplot Matrix for TCQ not A split. The upper diagonal has the correlations between the variables, the diagonal has a histogram of the values with density lines overlaid, and the lower diagonal has scatterplots for each pair of variables, with an overlaid locally weighted smoother regression line}
  \label{fig:splitApairs}
\end{figure}

Figure \ref{fig:splitApairs} shows the scatterplot matrix for the totals in Split A. It can clearly be seen that the conventional variables correlate well with one another, as do the alternative variables. Some evidence of convergent validity is also seen, as the Beliefs About Medicine Questionnaire correlates negatively with the conventional forms of treatment, and positively with the alternative forms of treatment, as predicted. 

Next, the relationships of the demographic variables with the totals were examined. 

<<tcq2notAdemo, echo=FALSE, results=hide, cache=TRUE>>=
tcq2.nota.demo <- tcq2nota[,2:16]
@ 

One examination of the data which was of interest was the relationship between the conventional and alternative scores and demographic variables. A mean was calculated for both the conventional and alternative items, and this was plotted against gender. The results are shown in Figure \ref{fig:convaltmeangender}. As can be seen, the patterns differ for men and women, though the effect is small and the error bars are quite large. For men, higher scores on the conventional forms of treatment tend to be associated with higher scores on the alternative forms of treatment, while for women, the opposite is true. 

\begin{figure}
<<convaltmeans, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE, eps=TRUE, pdf=TRUE, png=TRUE>>=
p <- ggplot(na.omit(tcq2nota), aes(x=ConvMean, y=AltMean, group=Gender))
p2 <- p+geom_smooth(method="lm")+facet_grid(.~Gender)
## p3 <- p2+facet_grid(.~Gender)
print(p2)
@   
  \caption{Regression line of Conventional treatment mean scores against Alternative treatment mean scores, stratified by Gender (regression line is a least squares fit)}
  \label{fig:convaltmeangender}
\end{figure}



\begin{figure}
<<ggplotconvaltcollege, echo=FALSE,fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
p <- ggplot(na.omit(tcq2nota), aes(x=ConvMean, y=AltMean))
p2 <- p+geom_smooth(method="lm")
p3 <- p2+facet_grid(.~College)
print(p3)
@   
  \caption{Conventional Means Regressed against Alternative treatment means, stratified based on College of study or work}
  \label{fig:convaltmeancollege}
\end{figure}


Figure \ref{fig:convaltmeancollege} shows a regression of alternative  treatment mean scores against conventional treatment mean scores, stratified based on college. It can be seen that for Arts, Science and Business and Law, increased scores on the alternative treatments were associated with increased scores on the conventional treatments, while for medicine and health, the reverse was true - which suggests that either these participants had a different relationship to these forms of treatment, or that their course of study had altered their perceptions. As can be seen from Figure \ref{fig:medhealthyear}, the second alternative appears to be the case, given that the relationship is positive in Year 1, but then turns sharply negative. 

\begin{figure}
<<medhealthyear, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
medhealth <- tcq2[with(tcq2, College=="Medicine and Health"),]
medyearplot <- ggplot(na.omit(medhealth), aes(x=ConvMean, y=AltMean))+geom_smooth(method="lm")+facet_grid(.~Year)
print(medyearplot)
@ 
  
  \caption{Relationship between Conventional and Alternative Treatment Scores in Medicine and Health Students}
  \label{fig:medhealthyear}
\end{figure}

\begin{figure}
<<ggplotpillincome, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
p <- ggplot(na.omit(tcq2nota), aes(x=ConvMean, y=AltMean))
p2 <- p+layer(geom="smooth", method="lm")
p3 <- p2+facet_grid(.~Health)
print(p3)
@   
  \caption{Regression of Alternative Treatment means against conventional treatment means, stratified by health status (where 1 is worst health and 5 is best health)}
  \label{fig:convaltmeanhealth}
\end{figure}

Figure \ref{fig:convaltmeanhealth} shows the regression of conventional treatment mean scores against alternative  treatment mean scores, stratified by Health status. It can be seen that for moderate levels of self rated health (2-4), higher scores on the conventional treatments were associated with higher scores on the alternative treatment. However, for participants who rated their health as ``Excellent'', the opposite pattern emerged. 



Next, summary scores for experience with conventional treatments and alternative treatments were calculated, and the relationships of these two variables to demographic variables were examined.

\begin{figure}
<<expconvaltgender, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
p <- ggplot(tcq2nota, aes(x=Expconv, y=Expalt))
p2 <- p+geom_smooth(method="lm")+facet_grid(.~Gender)
print(p2)
@   
  \caption{Experience with Alternative Treatments Regressed against Experience with Conventional Treatments, Stratified by Gender}
  \label{fig:expconvaltgender}
\end{figure}

\begin{figure}
<<expconvaltgender, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
p <- ggplot(tcq2nota, aes(x=Expconv, y=Expalt))
p2 <- p+layer(geom="smooth", method="lm")
p3 <- p2+facet_grid(.~College)
print(p3)
@ 
  \caption{Experience with Alternative Treatments Regressed against Experience with Conventional Treatments, Stratified by College}
  \label{fig:expconvaltgender}
\end{figure}


\begin{figure}
<<expconvaltgender, echo=FALSE, fig=TRUE, pdf=TRUE, png=TRUE, eps=TRUE>>=
p <- ggplot(tcq2nota, aes(x=Expconv, y=Expalt))
p2 <- p+geom_smooth(method="lm")+facet_grid(.~Health)
print(p2)
@ 
  \caption{Experience with Alternative Treatments Regressed against Experience with Conventional Treatments, Stratified by College}
  \label{fig:expconvaltgender}
\end{figure}

Following on from the graphical exploration of the relationships between the variables, the next step was to fit a linear model on this data, eliminate variables based on the decrease in AIC, and test the model on the held out data. 
